---
title: "XCulture_paper_analyses"
author: "Rose M. Schneider"
date: "3/27/2019"
output: html_document
---

# Setup
```{r, include = FALSE}
rm(list = ls())
require("knitr")
# opts_knit$set(root.dir = "~/Documents/Projects/xculture/HK_SLO/") #this is specific to RMS, change accordingly
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)
library(memisc)
'%!in%' <- function(x,y)!('%in%'(x,y))

productivity.pal <- c("#666666","#00b8e6")

india.pal <- c("#E7298A","#66A61E","#E6AB02", "#D95F02")
```

# Load data
Data is stored in separate CSVs; cleaned separately, and then binded. Done in a separate file to keep analysis script a little shorter. Warnings are suppressed because SIDs are coerced from factor to character.
```{r, warning = FALSE}
source_rmd <- function(file, local = FALSE, ...){
  options(knitr.duplicate.label = 'allow')

  tempR <- tempfile(tmpdir = ".", fileext = ".R")
  on.exit(unlink(tempR))
  knitr::purl(file, output=tempR, quiet = TRUE)

  envir <- globalenv()
  source(tempR, local = envir, ...)
}

source_rmd("xculture_data_cleaning.Rmd")
#this results in a cleaned .csv, re-compiled every time from original data
```

Now load the data as all.data and hc.df
```{r}
all.data <- read.csv("../Data/Cleaned_data/cleaned_data.csv")
hc.df <- read.csv("../Data/Cleaned_data/cleaned_hc_data.csv")
```

---

# Classifications
Data manipulations

## CP or subset-knower
Children are classified as subset-knowers if they got all 4 numbers requested correct (on either the first or the second try).
```{r}
cp.df <- all.data %>%
  filter(Task == "GiveN")%>%
  group_by(SID)%>%
  summarise(sum_correct = sum(Correct, na.rm = TRUE))%>%
  mutate(Knower.level = ifelse(sum_correct >= 4, "CP-knower", "Subset-knower"))%>%
  dplyr::select(-sum_correct)

all.data <- full_join(all.data, cp.df, by = "SID")
```

## WPPSI score
WPPSI score is just the total correct items by participant, excluding feedback/training trials
```{r}
 #get sum per SID, add to sf and wcn for CROSS-LINGUISTIC models
 wppsi.sid <- all.data %>%
  filter(Task == "WPPSI")%>%
  filter(Exclude_trial != 1)%>%
  mutate(Trial_number = factor(Trial_number))%>%
  filter(Trial_number != "sample item A", #remove training trials
         Trial_number != "sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != '1', 
         Trial_number != '2', 
         Trial_number != '7', 
        Trial_number != '8')%>%
   group_by(SID)%>%
   summarise(sum_wppsi = sum(Correct, na.rm = TRUE))

all.data <- full_join(all.data, wppsi.sid, by = "SID")
```


## Resilience
Children are classified as Resilient if they are able to count at least 2 decades higher than an error without making more than 3 errors along the way, OR if they are able to count to 140 without making an error.
```{r}
##make a data frame for running prod. function on
hc.df %<>%
  mutate(Last_successful = ifelse(Last_successful == "Is quiet", "IDK", Last_successful))%>%
  filter(Exclude != 1)%>%
  filter(SID != "CH-VC-1", 
         SID != "SR-8-MP", 
         SID != "CH-MV-14", 
         SID != 'GV-21-SB', 
         SID != 'RT09', 
         SID != 'SK-M-4-GJ')#excluding these kids because they break productivity function; these are kids who have language-specific errors

#simplify above df
hc <- hc.df %>% 
  dplyr::select(SID, Last_successful, IHC, FHC, Language) %>%
  mutate_at(c('Last_successful','IHC','FHC'),
            function(col) as.integer(str_replace_all(col,'\\D',''))) %>% # some of these included '?', so i remove any char thats not a digit
  mutate(Last_successful = ifelse(is.na(Last_successful), 140, Last_successful))%>%
  mutate(SID = as.character(SID))

# function for determining productivity
is.productive = function(subject){
  # takes as input the data for a single subject
  # RULES:
  # - counts to 140 unaided = productive
  # - after making first error, counts >= 20 higher, with no more than 3 errors on way
  if(subject$IHC[1] >= 140){
    # if they get to 140 on first try, = productive
    return("Productive")
  } else if(subject$FHC[1] == 140 & nrow(subject) < 4) {
    return("Productive")
  } else if(subject$FHC[1] < 140 & nrow(subject) == 1 
            & subject$FHC[1] == subject$IHC[1]) {
    return("Nonproductive")
  } else if((subject$FHC[1] - subject$IHC[1]) >= 20){
    # if their final is >= 20 larger than their intial...
    if(nrow(subject) < 4){
      # and they've made 3 or fewer total errors, = productive
      return("Productive")
    } 
    else {
      for(i in 1:nrow(subject)){ # start at row 2
        # check if they ever made it >= 20 counts & <= 3 errors after an error
        runLength = 0 # they just made an error, so no post-error successes yet
        numErrors = 0 # first row was an error if it's not finalCount == 140
        prev = subject$Last_successful[i]
        for (j in i+1:nrow(subject)){ # from current row until end...
          numErrors = numErrors + 1 # new row means new error
          runLength = runLength + (subject$Last_successful[j] - prev)
          # ^ add difference between current count and last count to run length
          prev = subject$Last_successful[j] # update last count
          if(runLength >= 20 & numErrors < 4){
            # if at any point the productivity conditions are met...
            return("Productive") # = productive
          }
        }
      }
      # productivity conditions were never met (because we got to this point) so...
      return("Nonproductive") # != productive
    }
  } else {
    # highest is not >= 20 greater than initial
    return("Nonproductive")
  }
}
# 
#get unique SIDs
unique_SIDs <- as.vector(unique(hc.df$SID))

#now run productivity function on the above unique SIDs
class_prod <- function(vector) {
  temp_data <- data.frame()
  for (i in vector) {
    prod.class <- data.frame(i, is.productive(subset(hc, SID == i)))
    # print(i) # for debugging
    names(prod.class) <- c("SID", "productive")
    prod.class %<>%
      mutate(SID = as.character(SID), 
             productive = as.character(productive))
    
    temp_data <- bind_rows(temp_data, prod.class)
  }
  temp_data %<>%
    mutate(productive = as.character(productive))
  return(temp_data)
}
# 

productive <- class_prod(unique_SIDs)

#manually add child who broke productivity code: CH-VC-1, IHC 20, FHC 56, nonproductive, 
#SR-8-MP, IHC = 19, FHC = 39, Nonproductive
#CH-MV-14, IHC = 48, FHC = 68, Nonproductive
#GV-21-SB, IHC = 20, FHC = 40, nonproductive
#RT09, IHC = 20, FHC = 43, Nonproductive
#SK-M-4-GJ, IHC = 20, FHC = 44, Nonproductive

#remove last successful so we can add this to all.data
hc %<>%
  dplyr::select(-Last_successful)

#join hc data with productivity data
productive <- full_join(productive, hc, by = "SID")%>%
  distinct(SID, IHC, FHC, productive)%>%
  dplyr::rename(Productive = productive)

#manually add back in kids who break the code; formula is SID, IHC, FHC, prod
productive <- rbind(productive, c('CH-VC-1', 20, 56, 'Nonproductive'))
productive <- rbind(productive, c('SR-8-MP', 19, 39, 'Nonproductive'))
productive <- rbind(productive, c('CH-MV-14', 48, 68, 'Nonproductive'))
productive <- rbind(productive, c("GV-21-SB", 20, 40, 'Nonproductive'))
productive <- rbind(productive, c('RT09', 20, 43, 'Nonproductive'))
productive <- rbind(productive, c('SK-M-4-GJ', 20, 44, 'Nonproductive'))

#Finally! Merge back with all.data
all.data <- full_join(all.data, productive, by = "SID")%>%
  dplyr::mutate(IHC = as.integer(IHC), 
         FHC = as.integer(FHC))%>%
  filter(!is.na(Productive))

###UPDATED - rename "Productive" as "Resilient"
all.data %<>%
  mutate(Productive = ifelse(Productive == "Productive", "Resilient", "Non-Resilient"))

 
# # for sanity checks - trying to make sure we're not leaving people out
# unique.sid <- all.data %>%
#   distinct(SID)
# 
# unique.hc <- hc.df %>%
#   distinct(SID)
# 
# tmp <- unique.sid %>% 
#   filter(SID %!in% unique.hc$SID)
# 
# l <- unique.sid %>%
#   filter(SID %!in% tmp$SID)
# 
# 
# tmp <- unique.hc %>%
#   filter(SID %in% unique.sid$SID)
```

### Sanity check for Productivity
Does anyone have a FHC higher than 130 and is Nonproductive?
```{r}
hc.check <- all.data %>%
  distinct(SID, Language, Productive, IHC, FHC)%>%
  filter(FHC > 130, 
         Productive == "Non-Resilient")

if(length(hc.check$SID) != 0) {
  print("WARNING: CHECK PRODUCTIVITY")
}#no errors! We're okay!
```

## Highest Contiguous NN
Highest Contiguous NN is a measure of productivity. This is the highest number for which a child was correct on the Next Number task, provided that all the previous numbers had also been correct.
```{r}
#first, get unique ids
unique.nn <- all.data %>%
  filter(Task == "NN")%>%
  droplevels() %>%
  distinct(SID)

#push unique SIDs and next number items into vectors for function below
unique.nn <- as.vector(unique.nn$SID)
nextnums <- as.vector(c(5, 7, 16, 24, 52, 71, 105, 107, 116, 224, 252, 271))

#this is a function that pulls out the largest number for which a participant had a correct consecutive
get_contiguous <- function(){
  contig <- data.frame()
  for (sub in unique.nn) {
    tmp <- all.data %>%
      filter(Task == "NN", 
             SID == sub, 
             Correct == 0)%>%
      mutate(Task_item = as.integer(as.character(Task_item)))%>%
      mutate(Task_item = sort(as.integer(as.character(Task_item))))
    if (length(tmp$SID) == 0) { #if no incorrect trials, hcnn = 271
      highest_contig = 271
      sub_contig <- data.frame(sub, highest_contig)
       sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    } else if (sub %in% failed.nn.sids) { #if they failed first item (1), then hcnn = 0
      highest_contig = 0
      sub_contig <- data.frame(sub, highest_contig)
      sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    } else if (length(tmp$Task_item) > 0 & min(as.integer(as.character(tmp$Task_item))) == 5) { #if they got more than one trial incorrect, and min of incorrect trials = 5, then hcnn = 1
      highest_contig = 1
      sub_contig <- data.frame(sub, highest_contig)
       sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    } else { #otherwise, get the min nn
      min.nn <- min(as.integer(as.character(tmp$Task_item)))
      prev_correct <- nextnums[nextnums < min.nn]
      highest_contig <- as.character(max(prev_correct))
    
      sub_contig <- data.frame(sub,
                             highest_contig)
      sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    }
  }
  contig %<>%
    mutate(highest_contig = as.character(highest_contig))
  return(contig)
}

highest_contiguous_nn <- get_contiguous()%>%
  dplyr::rename(SID = sub)

#add this to df 
all.data <- full_join(all.data, highest_contiguous_nn, by = "SID")

all.data %<>%
  mutate(highest_contig = as.integer(highest_contig))

# #how many kids don't have a highest contiguous NN? 
# all.data %>%
#   filter(is.na(Language))
#   filter(is.na(highest_contig))%>%
#   distinct(Language, SID)%>%
#   group_by(Language)%>%
#   summarise(n = n())%>%
#   kable()

#Check - does anyone have NA for HCNN? Yes, these are kids who were excluded from NN
# all.data %>%
#   filter(is.na(highest_contig))
```

## Within/outside count range
Each trial on the Unit or WCN task was determined to be either within or outside a child's unprompted count range (IHC).
```{r}
all.data %<>%
  mutate(count_range = ifelse((Task == "SF" | Task == "NN") & 
                                as.numeric(as.character(Task_item)) <= IHC, "Within", "Outside"))
```


--- 

## Memory checks - NAs to 1
Some participants have NAs rather than 1 for their first memory check. Also, if first mem check is a 0, and second is NA, change that second one to 1.
```{r}
all.data %<>%
  mutate(Task = factor(Task))%>%
  mutate(Mem_check_1 = ifelse(Task == "SF" & is.na(Mem_check_1), 1, Mem_check_1))%>%
  mutate(Mem_check_2 = ifelse(Task == "SF" & is.na(Mem_check_2) & Mem_check_1 == 0, 1, Mem_check_2))
```

---

# Demographics
## Overall, by language
```{r}
all.data %>%
  distinct(SID, Language, Age)%>%
  group_by(Language)%>%
  summarise(n = n(),
            Mean_age = round(mean(Age, na.rm = TRUE), 2), 
            SD_age = round(sd(Age, na.rm = TRUE), 2), 
            med_age = round(median(Age, na.rm = TRUE), 2))%>%
  kable()
```

## By sex, language
```{r}
#manually add forgotten sex info back in 
all.data %<>%
  mutate(Sex = ifelse(SID == "081018-KF", "F", as.character(Sex)), 
         Sex = ifelse(SID == "080318-RG", "M", as.character(Sex)), 
         Sex = ifelse(SID == "080718-ER", "F", as.character(Sex)),
         Sex = ifelse(SID == "101618-WD", "M", as.character(Sex)))

all.data %>%
  distinct(SID, Age, Language, Sex)%>%
  group_by(Language, Sex)%>%
  summarise(n = n(), 
            mean_age = round(mean(Age),2), 
            sd_age = round(sd(Age),2))%>%
  group_by(Language)%>%
  mutate(total.n = sum(n))%>%
  kable()
```

## Knower level by language
```{r}
all.data %>%
  distinct(SID, Language, Age, Productive, Knower.level)%>%
  group_by(Language, Knower.level)%>%
  summarise(n = n())%>%
  kable()
```
  
---

# Highest Count
Productivity, prompts, errors
## Productivity descriptives by language
### Overall
```{r}
#IHC, FHC by language
all.data %>%
  filter(!is.na(Language))%>%
  mutate(Productive = factor(Productive, levels = c("Resilient", "Non-Resilient")))%>%
  distinct(SID, Age, Language, IHC, FHC)%>%
  group_by(Language)%>%
  summarise(n = n(),
            mean_IHC = round(mean(IHC)), 
            sd_IHC = round(sd(IHC), 2), 
            mean_FHC = round(mean(FHC)), 
            sd_FHC = round(sd(FHC), 2))%>%
  kable()
```

### By Language and Resilience
```{r}
#IHC, FHC by language, productiviity
all.data %>%
  filter(!is.na(Language))%>%
  mutate(Productive = factor(Productive, levels = c("Resilient", "Non-Resilient")))%>%
  distinct(SID, Age, Productive, Language, IHC, FHC)%>%
  group_by(Language, Productive)%>%
  summarise(n = n(),
            mean_IHC = round(mean(IHC)), 
            sd_IHC = round(sd(IHC), 2), 
            mean_FHC = round(mean(FHC)), 
            sd_FHC = round(sd(FHC), 2))%>%
  kable()
```


### Descriptive: How many children counted at least a little past their IHC?
```{r}
##make df
distinct_counts <- all.data %>%
  distinct(SID, Language, Productive, IHC, FHC)

#how many children were able to count at least a little beyond their IHC
distinct_counts %>%
  filter(IHC != 140)%>% #filter out kids who reached 140
  mutate(Exp = ifelse((Language == "Cantonese" | Language == "English (US)" | 
                         Language == "Slovenian"), 1, 2))%>%
  mutate(delta = FHC-IHC, 
         delta.gain = ifelse(delta == 0, "no gain", "gain"))%>%
  group_by(Exp, Language, delta.gain)%>%
  summarise(n = n())%>%
  group_by(Exp, delta.gain)%>%
  summarise(total.n = sum(n))%>%
  group_by(Exp)%>%
  mutate(prop = total.n/sum(total.n))
```

### Analysis: What is the correlation between IHC and FHC in all languages?
```{r}
##Correlation between FHC and IHC in all languages

##HK
cor.test(subset(distinct_counts, Language == "Cantonese")$IHC, 
         subset(distinct_counts, Language == "Cantonese")$FHC)

##Slovenian
cor.test(subset(distinct_counts, Language == "Slovenian")$IHC, 
         subset(distinct_counts, Language == "Slovenian")$FHC)

##US English
cor.test(subset(distinct_counts, Language == "English (US)")$IHC, 
         subset(distinct_counts, Language == "English (US)")$FHC)

##Indian English
cor.test(subset(distinct_counts, Language == "English (India)")$IHC, 
         subset(distinct_counts, Language == "English (India)")$FHC)

##Hindi
cor.test(subset(distinct_counts, Language == "Hindi")$IHC, 
         subset(distinct_counts, Language == "Hindi")$FHC)

##Gujarati
cor.test(subset(distinct_counts, Language == "Gujarati")$IHC, 
         subset(distinct_counts, Language == "Gujarati")$FHC)
```


## Errors in HC
#### Set up data frame
```{r}
#how many prompts do productive and nonproductive counters need? and what kind of errors do they make?
#bind productive and hc.df 
productive %<>% 
  dplyr::select(SID, Productive)

##rename for resilient
productive %<>%
  mutate(Productive = ifelse(Productive == "Productive", "Resilient", "Non-Resilient"))

#Make a df just for errors
error.freq <- full_join(hc.df, productive, by = "SID")%>%
  filter(!is.na(Last_successful), 
         IHC != 140)%>% #filter out kids who made it to 140, these don't count as errors
  mutate(Error_type = ifelse((Language == "Cantonese" | 
                                Language == "Slovenian" |
                                Language == "English (India)" |
                                Language == "English (US)") & Last_successful %% 10 == 9 , "Decade end", 
                             ifelse(Last_successful %% 10 == 0, "Decade beginning",
                                    ifelse(Last_successful %% 10 == 8 & (Language == "Hindi" | Language == "Gujarati"), "Hindi/Gujarati pre-decade transition", "Mid-decade"))))
```

### How many participants used all 14 prompts?
```{r}
#how many participants used at least 5 prompts?
hc.df %>%
  group_by(SID, Language)%>%
  filter(Last_successful != 140)%>% #filter out 140 because it's the last number reached, not a prompt
  summarise(n = n())%>%
  filter(n >= 5)%>%
  group_by()%>%
  mutate(total.n = length(unique(SID)))%>%
  kable()
 
#get mode function
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

#mean, median, and mode of prompts
hc.df %>%
  group_by(SID, Language)%>%
  filter(Last_successful != 140)%>%
  summarise(n = n())%>%
  group_by()%>%
  summarise(mean = mean(n), 
            median = median(n), 
            mode = getmode(n))
```

### How many prompts on average by language, productivity?
```{r}
#by productivity
error.freq %>%
  mutate(Productive = factor(Productive, levels = c("Resilient", "Non-Resilient")))%>%
  filter(Last_successful != 140)%>% #filter out kids who got to 140
  group_by(SID, Language, Productive)%>%
  summarise(n = n())%>%
  group_by(Language, Productive)%>%
  summarise(mean_prompts = round(mean(n, na.rm = TRUE), 2),
            sd_prompts = round(sd(n, na.rm = TRUE), 2))

###Prompts by language, overall

error.freq %>%
  filter(Last_successful != 140)%>% #filter out kids who got to 140
  group_by(SID, Language)%>%
  summarise(n = n())%>%
  group_by(Language)%>%
  summarise(mean_prompts = round(mean(n, na.rm = TRUE), 2),
            sd_prompts = round(sd(n, na.rm = TRUE), 2))
```

---

#Task Visualizations 
## Highest Count
####  Set up data frame for below visualizations
```{r}
#make a df for IHC and FHC
initial_final <- all.data %>%
  filter(!is.na(Productive))%>%
  distinct(SID, Language, IHC, FHC, Productive, Dataset)%>%
  mutate(IHC = as.numeric(IHC), 
         FHC = as.numeric(FHC))
```

### Scatterplot of IHC and FHC - now with density distributions
```{r}
library(ggstance)
library(ggjoy)
library(cowplot)
####Cantonese####
hk_initial <- initial_final %>%
  filter(Language == "Cantonese")

pmain.hk <- ggplot(hk_initial, aes(x = IHC, y = FHC, color = Productive, shape = Productive)) + 
  geom_point(size = 1.3, alpha = .9, position = position_jitter()) + 
  # geom_jitter() + 
  scale_color_brewer(palette = "Paired") + 
  coord_fixed() + 
  theme_bw(base_size = 10) +
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        plot.title = element_text(hjust = 0.5, size = 9, face = "bold"), 
        axis.title = element_text(size = 8),
        legend.position = c(.75, 0.2), 
        legend.text = element_text(size = 6), 
        legend.title = element_blank(), 
        axis.text = element_text(size = 7)) + 
  labs(x = "Initial Highest Count", y = "Final Highest Count", 
       title = "Cantonese") + 
  xlab('')

xdens.hk <- axis_canvas(pmain.hk, axis = "x") + 
  # geom_ridgeline(data = us_initial, aes(x = IHC, y = 0, height=..density.., 
  #                                       fill = Productive), 
  #                stat = 'xdensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = hk_initial, aes(x = IHC, y = ..density.., fill = Productive), 
               alpha=.7, adjust = .5) + 
  scale_fill_brewer(palette = "Paired") 

ydens.hk <- axis_canvas(pmain.hk, axis = "y", coord_flip = TRUE) + 
  # geom_vridgeline(data = us_initial, aes(y = FHC, x = 0, width=..density.., 
  #                                       fill = Productive), 
  #                stat = 'ydensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = hk_initial, aes(x = FHC, y = ..density.., fill = Productive), 
               alpha=.7, adjust = .5) +
  coord_flip() +
  scale_fill_brewer(palette = "Paired") 

p5 <- insert_xaxis_grob(pmain.hk, xdens.hk, grid::unit(.2, "null"), position = "top")
hk_dens <- insert_yaxis_grob(p5, ydens.hk, grid::unit(.2, "null"), position = "right")
# ggdraw(p6)
# png(filename = "hk_density.png")
# ggdraw(p6)
# dev.off()
```

```{r}
#####SLO####
slo_initial <- initial_final %>%
  filter(Language == "Slovenian")

pmain.slo <- ggplot(slo_initial, aes(x = IHC, y = FHC, color = Productive, shape = Productive)) + 
  geom_point(size = 1.3, alpha = .9, position = position_jitter()) + 
  geom_jitter() + 
  scale_color_brewer(palette = "Paired", guide = "none") + 
  coord_fixed() + 
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) +
  theme_bw(base_size = 10) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        plot.title = element_text(hjust = 0.5, size = 9, face = "bold"), 
        legend.position = "none",
        axis.title = element_text(size = 8),
        legend.text = element_text(size = 5), 
        legend.title = element_text(size = 6), 
         axis.text = element_text(size = 7)) + 
  labs(x = "Initial Highest Count", y = "Final Highest Count", 
       title = "Slovenian") + 
  ylab('')

xdens.slo <- axis_canvas(pmain.slo, axis = "x") + 
  # geom_ridgeline(data = us_initial, aes(x = IHC, y = 0, height=..density.., 
  #                                       fill = Productive), 
  #                stat = 'xdensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = slo_initial, aes(x = IHC, y = ..density.., fill = Productive), 
               alpha=.7, adjust = .5) + 
  scale_fill_brewer(palette = "Paired") 

ydens.slo <- axis_canvas(pmain.slo, axis = "y", coord_flip = TRUE) + 
  # geom_vridgeline(data = us_initial, aes(y = FHC, x = 0, width=..density.., 
  #                                       fill = Productive), 
  #                stat = 'ydensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = slo_initial, aes(x = FHC, y = ..density.., fill = Productive), 
               alpha=.7, adjust = .5) +
  coord_flip() +
  scale_fill_brewer(palette = "Paired") 

p5 <- insert_xaxis_grob(pmain.slo, xdens.slo, grid::unit(.2, "null"), position = "top")
slo_dens <- insert_yaxis_grob(p5, ydens.slo, grid::unit(.2, "null"), position = "right")
# ggdraw(p6)
# png(filename = "slo_density.png")
# ggdraw(p6)
# dev.off()
```

```{r}
#####US####
us_initial <- initial_final %>%
  filter(Language == "English (US)")

pmain.us <- ggplot(us_initial, aes(x = IHC, y = FHC, color = Productive, shape = Productive)) + 
  geom_point(size = 1.3, alpha = .9, position = position_jitter()) + 
  geom_jitter() + 
  scale_color_brewer(palette = "Paired") + 
  coord_fixed() + 
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) +
  theme_bw(base_size = 10) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        plot.title = element_text(hjust = 0.5, size = 9, face = "bold"),
        axis.title = element_text(size = 8),
        legend.position = "none", 
        legend.text = element_text(size = 5), 
        legend.title = element_text(size = 6), 
         axis.text = element_text(size = 7)) +
  labs(x = "Initial Highest Count", y = "Final Highest Count", 
       title = "English (US)") + 
  ylab('') + 
  xlab('')

xdens.us <- axis_canvas(pmain.us, axis = "x") + 
  # geom_ridgeline(data = us_initial, aes(x = IHC, y = 0, height=..density.., 
  #                                       fill = Productive), 
  #                stat = 'xdensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = us_initial, aes(x = IHC, y = ..count.., fill = Productive), 
               alpha=.7, adjust = .5) + 
  scale_fill_brewer(palette = "Paired") 

ydens.us <- axis_canvas(pmain.us, axis = "y", coord_flip = TRUE) + 
  # geom_vridgeline(data = us_initial, aes(y = FHC, x = 0, width=..density.., 
  #                                       fill = Productive), 
  #                stat = 'ydensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = us_initial, aes(x = FHC, y = ..count.., fill = Productive), 
               alpha=.7, adjust = .5) +
  coord_flip() +
  scale_fill_brewer(palette = "Paired") 

p5 <- insert_xaxis_grob(pmain.us, xdens.us, grid::unit(.2, "null"), position = "top")
us_dens <- insert_yaxis_grob(p5, ydens.us, grid::unit(.2, "null"), position = "right")
# ggdraw(p6)
# png(filename = "us_density.png")
# ggdraw(p6)
# dev.off()
```

##Get all of these scatterplots together in a single plot
###HK/SLO/US
```{r}
cowplot::plot_grid(ggdraw(hk_dens), ggdraw(slo_dens), 
                   ggdraw(us_dens), ncol = 3)
ggsave("HKSLOUS_dens.png")
```

```{r}
#####HINDI####
hindi_initial <- initial_final %>%
  filter(Language == "Hindi")

pmain.hindi <- ggplot(hindi_initial, aes(x = IHC, y = FHC, color = Productive, shape = Productive)) + 
  geom_point(size = 1.3, alpha = .9, position = position_jitter()) + 
  geom_jitter() + 
  scale_color_brewer(palette = "Paired") + 
  coord_fixed() + 
  scale_x_continuous(breaks = seq(0, 140, 10), limits = c(0, 140)) + 
  scale_y_continuous(breaks = seq(0, 140, 10), limits = c(0, 140)) +
  theme_bw(base_size = 10) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        plot.title = element_text(hjust = 0.5, size = 9, face = "bold"), 
        axis.title = element_text(size = 8),
        legend.position = c(.75, 0.2), 
        legend.text = element_text(size = 6), 
        legend.title = element_blank(), 
        axis.text = element_text(size = 7)) +
  labs(x = "Initial Highest Count", y = "Final Highest Count", 
       title = "Hindi") + 
  xlab('')

xdens.hindi <- axis_canvas(pmain.hindi, axis = "x") + 
  # geom_ridgeline(data = us_initial, aes(x = IHC, y = 0, height=..density.., 
  #                                       fill = Productive), 
  #                stat = 'xdensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = hindi_initial, aes(x = IHC, y = ..density.., fill = Productive), 
               alpha=.7, adjust = .5) + 
  scale_fill_brewer(palette = "Paired") 

ydens.hindi <- axis_canvas(pmain.hindi, axis = "y", coord_flip = TRUE) + 
  # geom_vridgeline(data = us_initial, aes(y = FHC, x = 0, width=..density.., 
  #                                       fill = Productive), 
  #                stat = 'ydensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = hindi_initial, aes(x = FHC, y = ..density.., fill = Productive), 
               alpha=.7, adjust = .5) +
  coord_flip() +
  scale_fill_brewer(palette = "Paired") 

p5 <- insert_xaxis_grob(pmain.hindi, xdens.hindi, grid::unit(.2, "null"), position = "top")
hind_dens <- insert_yaxis_grob(p5, ydens.hindi, grid::unit(.2, "null"), position = "right")
# ggdraw(p6)
# png(filename = "hindi_density.png")
# ggdraw(p6)
# dev.off()
```

```{r}
#####Gujarati####
gujarati_initial <- initial_final %>%
  filter(Language == "Gujarati")

pmain.gujarati <- ggplot(gujarati_initial, aes(x = IHC, y = FHC, color = Productive, shape = Productive)) + 
  geom_point(size = 1.3, alpha = .9, position = position_jitter()) + 
  geom_jitter() + 
  scale_color_brewer(palette = "Paired", guide = "none") + 
  coord_fixed() + 
  scale_x_continuous(breaks = seq(0, 140, 10), limits = c(0, 140)) + 
  scale_y_continuous(breaks = seq(0, 140, 10), limits = c(0, 140)) +
  theme_bw(base_size = 10) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        plot.title = element_text(hjust = 0.5, size = 9, face = "bold"),
        axis.title = element_text(size = 8),
        legend.position = "none", 
        legend.text = element_text(size = 5), 
        legend.title = element_text(size = 6), 
         axis.text = element_text(size = 7)) + 
  labs(x = "Initial Highest Count", y = "Final Highest Count", 
       title = "Gujarati") + 
  ylab('')

xdens.gujarati <- axis_canvas(pmain.gujarati, axis = "x") + 
  # geom_ridgeline(data = us_initial, aes(x = IHC, y = 0, height=..density.., 
  #                                       fill = Productive), 
  #                stat = 'xdensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = gujarati_initial, aes(x = IHC, y = ..count.., fill = Productive), 
               alpha=.7, adjust = .5) + 
  scale_fill_brewer(palette = "Paired") 

ydens.gujarati <- axis_canvas(pmain.gujarati, axis = "y", coord_flip = TRUE) + 
  # geom_vridgeline(data = us_initial, aes(y = FHC, x = 0, width=..density.., 
  #                                       fill = Productive), 
  #                stat = 'ydensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = gujarati_initial, aes(x = FHC, y = ..count.., fill = Productive), 
               alpha=.7, adjust = .5) +
  coord_flip() +
  scale_fill_brewer(palette = "Paired") 

p5 <- insert_xaxis_grob(pmain.gujarati, xdens.gujarati, grid::unit(.2, "null"), position = "top")
gujarati_dens <- insert_yaxis_grob(p5, ydens.gujarati, grid::unit(.2, "null"), position = "right")
# ggdraw(p6)
# png(filename = "gujarati_density.png")
# ggdraw(p6)
# dev.off()
```

```{r}
ind.eng_initial <- initial_final %>%
  filter(Language == "English (India)")

pmain.ind.eng <- ggplot(ind.eng_initial, aes(x = IHC, y = FHC, color = Productive, shape = Productive)) + 
  geom_point(size = 1.3, alpha= .9, position = position_jitter()) + 
  geom_jitter() + 
  scale_color_brewer(palette = "Paired", guide = "none") + 
  coord_fixed() + 
  scale_x_continuous(breaks = seq(0, 140, 10), limits = c(0, 140)) + 
  scale_y_continuous(breaks = seq(0, 140, 10), limits = c(0, 140)) +
   theme_bw(base_size = 10) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        plot.title = element_text(hjust = 0.5, size = 9, face = "bold"),
        axis.title = element_text(size = 8),
        legend.position = "none", 
        legend.text = element_text(size = 5), 
        legend.title = element_text(size = 6), 
         axis.text = element_text(size = 7)) + 
  labs(x = "Initial Highest Count", y = "Final Highest Count", 
       title = "English (India)") + 
  xlab('') + 
  ylab('')

xdens.ind.eng <- axis_canvas(pmain.ind.eng, axis = "x") + 
  # geom_ridgeline(data = us_initial, aes(x = IHC, y = 0, height=..density.., 
  #                                       fill = Productive), 
  #                stat = 'xdensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = ind.eng_initial, aes(x = IHC, y = ..count.., fill = Productive), 
               alpha=.7, adjust = .5) + 
  scale_fill_brewer(palette = "Paired") 

ydens.ind.eng <- axis_canvas(pmain.ind.eng, axis = "y", coord_flip = TRUE) + 
  # geom_vridgeline(data = us_initial, aes(y = FHC, x = 0, width=..density.., 
  #                                       fill = Productive), 
  #                stat = 'ydensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = ind.eng_initial, aes(x = FHC, y = ..count.., fill = Productive), 
               alpha=.7, adjust = .5) +
  coord_flip() +
  scale_fill_brewer(palette = "Paired") 

p5 <- insert_xaxis_grob(pmain.ind.eng, xdens.ind.eng, grid::unit(.2, "null"), position = "top")
ind_dens <- insert_yaxis_grob(p5, ydens.ind.eng, grid::unit(.2, "null"), position = "right")
# ggdraw(p6)
# png(filename = "indeng_density.png")
# ggdraw(p6)
# dev.off()
```

##Get all of these scatterplots together in a single plot
###Hindi/Gujarati/Ind. Eng
```{r}
cowplot::plot_grid(ggdraw(hind_dens), ggdraw(gujarati_dens), 
                   ggdraw(ind_dens), ncol = 3)
ggsave("india_dens.png")
```

---

##Unit Task
### Descriptive statistics  
```{r}
all.data %>%
  filter(Task == "SF")%>%
  group_by(SID, Language)%>%
  summarise(mean_sub = mean(Correct, na.rm = TRUE))%>%
  group_by(Language)%>%
  summarise(n = n(),
            mean = round(mean(mean_sub, na.rm = TRUE), 2), 
            sd = round(sd(mean_sub, na.rm = TRUE), 2))%>%
  kable()
```

### Visualization of Unit performance by language
```{r}
#HK/SLO/US
all.data %>%
  filter(Task == "SF", 
         Language != "English (India)")%>%
  mutate(Language = factor(Language, levels = c("Cantonese", "Slovenian", "English (US)", 
                                                "Gujarati", "Hindi")))%>%
  group_by(SID, Language)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  # stat_summary(fun.y = mean, position = position_dodge(width = .95), 
  #                     geom="violin", width = 1, alpha = .5, colour = "black", 
  #              show.legend = FALSE) +
  geom_violin(aes(x = Language, y = mean), alpha = .1, size = .7,
              show.legend = FALSE)  +
  geom_point(aes(x = Language, y = mean, colour = Language),
               position=position_jitter(width=0.15,height=0.02),
               size=2,
             alpha = .5,
               show.legend=FALSE, 
             inherit.aes = FALSE) +
  guides(shape = "none") + 
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, size = 1, 
               show.legend = FALSE) +
  ylab("Mean Unit Task performance") + 
  xlab('Language') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  # ggtitle("Overall mean correct on Unit Task") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  langcog::scale_fill_solarized() + 
  langcog::scale_color_solarized("Language") + 
  guides(size = "none")

ggsave("Figures/Unit_by_language.png", width = 5.5, height = 2.8)
```

---

# Next Number
## Descriptive statistics  
```{r}
all.data %>%
  filter(Task == "NN")%>%
  group_by(SID, Language)%>%
  summarise(mean_sub = mean(Correct, na.rm = TRUE))%>%
  group_by(Language)%>%
  summarise(n = n(),
            mean = round(mean(mean_sub, na.rm = TRUE), 2), 
            sd = round(sd(mean_sub, na.rm = TRUE), 2))%>%
  kable()

##Do English US/India differ?
#No significant difference in mean NN performance
nn.ms <- all.data %>%
  filter(Task == "NN")%>%
  group_by(SID,Language)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(subset(nn.ms, Language == "English (US)")$mean, 
       subset(nn.ms, Language == "English (India)")$mean, var.equal = TRUE)
```

## Visualization of Next Number performance by language
```{r}
all.data %>%
  filter(Task == "NN")%>%
  mutate(Language = factor(Language, levels = c("Cantonese", "Slovenian", "English (US)", "English (India)", 
                                                "Gujarati", "Hindi")))%>%
  group_by(SID, Language)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  # stat_summary(fun.y = mean, position = position_dodge(width = .95), 
  #                     geom="violin", width = 1, alpha = .5, colour = "black", 
  #              show.legend = FALSE) +
  geom_violin(aes(x = Language, y = mean), alpha = .1, size = .7,
              show.legend = FALSE)  +
  geom_point(aes(x = Language, y = mean, colour = Language),
               position=position_jitter(width=0.15,height=0.02),
               size=2,
             alpha = .5,
               show.legend=FALSE, 
             inherit.aes = FALSE) +
  guides(shape = "none") + 
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, size = 1, 
               show.legend = FALSE) +
  ylab("Mean Next Number performance") + 
  xlab('Language') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  # ggtitle("Overall mean correct on Unit Task") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  langcog::scale_fill_solarized() + 
  langcog::scale_color_solarized("Language") + 
  guides(size = "none")

ggsave("Figures/NN_by_language.png", width = 5.5, height = 2.8)
```

## Unit Task by Highest Contiguous Next Number
```{r}
all.data %>%
  filter(Task == "SF", 
         Language != "English (India)", 
         !is.na(highest_contig))%>%
  mutate(Language = factor(Language, levels = c("Cantonese", "Slovenian", "English (US)", 
                                                "Gujarati", "Hindi")), 
         highest_contig = factor(highest_contig))%>%
  group_by(Language, highest_contig)%>%
  langcog::multi_boot_standard("Correct", na.rm = TRUE) %>%
    ggplot(aes(x = highest_contig, y= mean, color = Language, group = Language)) + 
  geom_point(size = 2.5) + 
  geom_line(show.legend = FALSE) + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  theme_bw(base_size = 13) + 
  theme(panel.grid = element_blank(), 
        legend.text = element_text(size = 6), 
        legend.position = c(.4, 0.06), 
        legend.direction = "horizontal",
        legend.key.size = unit(.5, "cm"), 
        legend.margin=margin(t=0, r=0, b=0, l=0, unit="cm")) + 
  langcog::scale_color_solarized("") + 
  labs(x = 'Highest Contiguous Next Number', y = 'Mean Unit Task performance')

ggsave("Figures/Unit_by_HCNN.png", width = 5.5, height = 2.8)
```

## By-item graph for each lang (SOM, analysis 4)
```{r}
##first SF
all.data %>%
  mutate(exclude = ifelse((Language == "English (India)" & Task == "SF"), 1, 0))%>%
  filter(exclude != 1)%>%
  filter(Task == "SF" | 
           Task == "NN")%>%
  mutate(Language = factor(Language, levels = c("Cantonese", "Slovenian", "English (US)", "Hindi", 
                                                "Gujarati", "English (India)")))%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", 
                                                  "24", "52","71", 
                                                  "105", "107", "116", 
                                                  "224", "252", "271")), 
         Experiment = ifelse((Language == "Cantonese" | Language == "Slovenian" | Language == "English (US)"), "Experiment 1", "Experiment 2"), 
         Task = factor(Task, levels = c("SF", "NN"), labels = c("Unit Task", "Next Number")))%>%
  group_by(Language, Task, Experiment, Task_item)%>%
  multi_boot_standard("Correct", na.rm = TRUE)%>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language, shape = Language)) +
  geom_point(size = 3) + 
  geom_line() +
  geom_linerange(aes(ymin =ci_lower, ymax = ci_upper), 
                width = .1, size = .8) +
  theme_bw(base_size = 13) + 
  facet_grid(Experiment~Task) + 
  scale_color_brewer(palette = "Dark2")+
  theme(legend.position = "right", 
        legend.title = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Number queried", y = "Mean task performance")
ggsave("Figures/unit_nn_item.png", width = 9, height = 5.3)

```

## NN performance by HC: Figures 2 and 4
```{r}
#Make df for all HC data
unique.hc.data <- all.data %>%
  distinct(SID, IHC, FHC, Productive, Language, Dataset)%>%
  gather(IHC_FHC,highest_count, IHC:FHC)%>%
  mutate(highest_count = as.integer(highest_count), 
         IHC_FHC = factor(IHC_FHC, levels = c("IHC", "FHC"), 
                          labels = c("Initial Highest Count", "Final Highest Count")))

#make df for mean NN score
ms.nn <- all.data %>%
  filter(Task == "NN")%>%
  group_by(SID)%>%
  summarise(mean.nn = mean(Correct, na.rm = TRUE))

nn.full <- full_join(ms.nn, unique.hc.data, by = "SID")

##HK/SLO/US - Experiment 1
nn.full %>%
  filter(Language == "Cantonese" |
           Language == "Slovenian" | 
           Language == "English (US)")%>%
  mutate(Language = factor(Language, levels = c("Cantonese", "Slovenian", "English (US)")))%>%
  ggplot(aes(x = highest_count, y = mean.nn, color = Language, group = Language)) +
  geom_count(show.legend = FALSE, alpha = .85) +
  geom_smooth(aes(fill = Language), se = TRUE, size = 1.6, alpha =.16) + 
  facet_grid(~IHC_FHC)+
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2")+
  coord_cartesian(ylim = c(0, 1))+
  theme_bw(base_size = 13) +
  theme(legend.position = "bottom", 
        legend.direction = 'horizontal',
        legend.title = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) + 
  scale_x_continuous(breaks = seq(0, 140, 20)) + 
  labs(x = "Highest Count", y = "Mean Next Number performance")

ggsave("Figures/nn_by_hc_hkSloUS.png")



##Experiment 2
nn.full %>%
  filter(Language == "Hindi" |
           Language == "Gujarati" | 
           Language == "English (US)" |
           Language == "English (India)")%>%
  mutate(Language = factor(Language, levels = c("Hindi", "Gujarati", "English (India)", "English (US)")))%>%
  ggplot(aes(x = highest_count, y = mean.nn, color = Language, group = Language)) +
  geom_count(show.legend = FALSE, alpha = .85) +
  geom_smooth(aes(fill = Language), se = TRUE, size = 1.6, alpha =.16) + 
  facet_grid(~IHC_FHC)+
  scale_color_manual(values = india.pal) +
  scale_fill_manual(values = india.pal)+
  coord_cartesian(ylim = c(0, 1))+
  theme_bw(base_size = 13) +
  theme(legend.position = "bottom", 
        legend.direction = 'horizontal',
        legend.title = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) + 
  scale_x_continuous(breaks = seq(0, 140, 20)) + 
  labs(x = "Highest Count", y = "Mean Next Number performance")
ggsave("Figures/nn_by_hc_india.png")
```




---

# MODELS

### Make model analysis dfs
Note that there is a lot more variability in highest counts and highest contiguous NN than in categorical variables. I am centering & scaling age, and centering and scaling FHC, IHC, and highest contiguous NN (which has the most variability).
```{r, include = FALSE}
##HK##
###UNIT###
sf.hk.within <- all.data%>%
  filter(Task == "SF")%>%
  filter(Language== "Cantonese")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))
###NN###  
wcn.hk.within <- all.data%>%
  filter(Task == "NN")%>%
  filter(Language == "Cantonese")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))

##SLO##
###UNIT###
sf.slo.within <- all.data%>%
  filter(Task == "SF")%>%
  filter(Language == "Slovenian")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))%>%
  filter(!is.na(highest_contig.c))

###NN###
wcn.slo.within <- all.data%>%
  filter(Language == "Slovenian")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))%>%
  filter(!is.na(highest_contig.c))

##US##
###UNIT###
sf.us.within <- all.data%>%
  filter(Task == "SF")%>%
  filter(Language == "English (US)")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))%>%
  filter(!is.na(highest_contig.c))

###NN###
wcn.us.within <- all.data%>%
  filter(Language == "English (US)")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))%>%
  filter(!is.na(highest_contig.c))

##English - India##
###UNIT###
sf.ind.eng.within <- all.data %>%
  filter(Task == "SF")%>%
  filter(Language == "English (India)")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

###NN###
wcn.ind.eng.within <- all.data %>%
  filter(Language == "English (India)")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

##Hindi##
####UNIT###
sf.hindi.within <- all.data %>%
  filter(Task == "SF")%>%
  filter(Language == "Hindi")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

###NN###
wcn.hindi.within <- all.data %>%
  filter(Language == "Hindi")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))


##Gujarati##
###UNIT###
sf.gujarati.within <- all.data %>%
  filter(Task == "SF")%>%
  filter(Language == "Gujarati")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

###NN###
wcn.gujarati.within <- all.data %>%
  filter(Language == "Gujarati")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))
```

***

#UNIT TASK MODELS, WITHIN LANGUAGES
##Hong Kong
```{r}
#base
sf.hk.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
#Productivity
sf.hk.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
#FHC
sf.hk.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
#IHC
sf.hk.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
#Highest contig.
sf.hk.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)

```

### Table
```{r}
library(sjPlot)
mtable.sf.hk <- mtable('Base Model' = sf.hk.within.base,
            'Model 1: Productivity' = sf.hk.within.model1,
            'Model 2: FHC' = sf.hk.within.model2,
            'Model 3: IHC' = sf.hk.within.model3,
            'Model 4: Highest Contig.' = sf.hk.within.model4,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.hk

tab_model(sf.hk.within.base, transform = NULL)
tab_model(sf.hk.within.model1, transform= NULL)
tab_model(sf.hk.within.model2, transform = NULL)
tab_model(sf.hk.within.model3, transform = NULL)
tab_model(sf.hk.within.model4, transform = NULL)
```


### Model comparisons
#### Base v. productivity - NS, Chisq(1) = 0.05. p = .82
```{r}
anova(sf.hk.within.base, sf.hk.within.model1, test = 'LRT') #ns
```

#### Base v. FHC - Sig, Chisq(1) = 11.65, p = 0.0006, AIC = 1616.5
```{r}
anova(sf.hk.within.base, sf.hk.within.model2, test = 'LRT')
```

#### Base v. IHC - Sig, Chisq(1) = 38.91, p < .0001, AIC = 1589.3
```{r}
anova(sf.hk.within.base, sf.hk.within.model3, test = 'LRT')
```

#### Base v. Highest Contiguous NN - Sig, Chisq(1) = 11.8251, p = .0002, AIC = 1616.3
```{r}
anova(sf.hk.within.base, sf.hk.within.model4, test = 'LRT')
```

#### Ranking of predictors from individual models 
1.  IHC - AIC = 1589.3
2.  HCNN - AIC = 1616.3
3.  FHC - AIC = 1616.5
4.  Productivity - 1624.3

### Large model
We have three significant predictors of performance on the Unit task (FHC, IHC, and Highest Contiguous NN). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task.

The simple model with the lowest AIC is IHC, so we will begin with that as our base term. 
```{r}
#Base = IHC
sf.hk.within.plus1 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)

#IHC and Highest Contiguous
sf.hk.within.plus2.hc <- glmer(Correct ~ highest_contig.c + ihc.c+ count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)

#compare
anova(sf.hk.within.plus1, sf.hk.within.plus2.hc, test = 'LRT')# HCNN ns

#IHC and FHC
sf.hk.within.plus2.fhc <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)

#compare
anova(sf.hk.within.plus1, sf.hk.within.plus2.fhc, test = 'LRT') #fhc ns

#IHC and FHC and HCNN
sf.hk.within.plus3 <- glmer(Correct ~ highest_contig.c + fhc.c + ihc.c + count_range + starting_num.c + age.c + 
                              (1|SID), family = "binomial", data = sf.hk.within)


#comparison of 3 (minus HCNN)
anova(sf.hk.within.plus1, sf.hk.within.plus2.fhc, sf.hk.within.plus3, test = 'LRT') 
#comparison of 3 (minus FHC)
anova(sf.hk.within.plus1, sf.hk.within.plus2.hc, sf.hk.within.plus3, test = 'LRT') 

mtable.sf.hk.large <- mtable('IHC alone' = sf.hk.within.plus1,
            'Highest Contig + IHC' = sf.hk.within.plus2.hc,
            'FHC + IHC' = sf.hk.within.plus2.fhc,
            'Highest Contig. + FHC + IHC' = sf.hk.within.plus3,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.hk.large
```

### HK Unit Task within-language results: IHC emerges as best predictor of performance on Unit Task
```{r}
summary(sf.hk.within.plus1)

###Statistics
##Sigma^2 
library(sjstats)
library(sjPlot)
tab_model(sf.hk.within.plus1, transform = NULL)
```

## Slovenian

```{r}
#base
sf.slo.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID) , family = "binomial", 
                           data = sf.slo.within)
#productivity
sf.slo.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
#FHC
sf.slo.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
#IHC
sf.slo.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within)
#highest contiguous NN
sf.slo.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within) 

```

### Table
```{r}
mtable.sf.slo <- mtable('Base Model' = sf.slo.within.base,
            'Model 1: Productivity' = sf.slo.within.model1,
            'Model 2: FHC' = sf.slo.within.model2,
            'Model 3: IHC' = sf.slo.within.model3,
            'Model 4: Highest Contig.' = sf.slo.within.model4,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.slo

tab_model(sf.slo.within.base, transform = NULL)
tab_model(sf.slo.within.model1, transform = NULL)
tab_model(sf.slo.within.model2, transform = NULL)
tab_model(sf.slo.within.model3, transform = NULL)
tab_model(sf.slo.within.model4, transform = NULL)
```

### Model Comparisons
#### Base v. Productivity - sig, Chis(1) = 15.967, p < .0001, AIC = 1422.7
```{r}
anova(sf.slo.within.base, sf.slo.within.model1, test = 'LRT')
```

 
#### Base v. FHC - Sig, Chisq(1) = 25.132, p < .0001, AIC = 1413.6
```{r}
anova(sf.slo.within.base, sf.slo.within.model2, test = 'LRT')
```

#### Base v. IHC - Chisq(1) = 14.585, p = .0001, AIC = 1424.1
```{r}
anova(sf.slo.within.base, sf.slo.within.model3, test = 'LRT')
```

#### Base v. Highest Contiguous NN - Sig, Chisq(1) = 26.227, p < .0001, AIC = 1412.5
```{r}
anova(sf.slo.within.base, sf.slo.within.model4, test = 'LRT')
```

#### Ranking of Productivity predictors from AIC 
1.  HCNN - 1412.46
2.  FHC - 1413.56
3.  Productivity - 1422.72
4.  IHC - 1424.10


### Large model
```{r}
#Base - HCNN
sf.slo.within.plus1 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")

#Now add second-lowest AIC
#HCNN + FHC
sf.slo.within.plus2.fhc <- glmer(Correct ~ fhc.c + highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")

#now compare
anova(sf.slo.within.plus1, sf.slo.within.plus2.fhc, test = 'LRT') ###FHC is significant


##Now add Productivity
#Productive + FHC + HCNN
sf.slo.within.plus3 <- glmer(Correct ~ Productive + fhc.c + highest_contig.c + count_range + starting_num.c + age.c + 
                               (1|SID), family = "binomial", data = sf.slo.within)
#Compare
anova(sf.slo.within.plus2.fhc, sf.slo.within.plus3, test = 'LRT')#NS

##FHC and HCNN best predictors, Productivity does not add anything. Now add IHC
#IHC + FHC + HCNN
sf.slo.within.plus3.ihc <- glmer(Correct ~ ihc.c + fhc.c + highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")

#HCNN and FHC best predictors - now add IHC
anova(sf.slo.within.plus2.fhc, sf.slo.within.plus3.ihc, test = 'LRT') #NS

#what about productivity gradient
sf.slo.within.plus.gain <- glmer(Correct ~ prod.gradient + fhc.c + highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
anova(sf.slo.within.plus1, sf.slo.within.plus.gain, test = 'LRT')

summary(sf.slo.within.plus1)
# summary(sf.slo.within.plus.nn)

```

### Summary, SLO Unit: HCNN + FHC is best predictor
```{r}
summary(sf.slo.within.plus2.fhc)
tab_model(sf.slo.within.plus2.fhc, transform = NULL)
```

## English (US)

```{r}
#base
sf.us.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.us.within)
#productivity
sf.us.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.us.within)
#FHC
sf.us.within.model2 <- glmer(Correct ~ fhc.c + count_range +  starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.us.within)
#IHC
sf.us.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c +  age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.us.within, control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#Highest contiguous
sf.us.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.us.within) 

```

###Table
```{r}
mtable.sf.us <- mtable('Base Model' = sf.us.within.base,
            'Model 1: Productivity' = sf.us.within.model1,
            'Model 2: FHC' = sf.us.within.model2,
            'Model 3: IHC' = sf.us.within.model3,
            'Model 4: Highest Contig.' = sf.us.within.model4,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.us

tab_model(sf.us.within.base, transform = NULL)
tab_model(sf.us.within.model1, transform = NULL)
tab_model(sf.us.within.model2, transform = NULL)
tab_model(sf.us.within.model3, transform = NULL)
tab_model(sf.us.within.model4, transform = NULL)

```

### Model comparisons
#### Base v. Productivity - NS, Chisq(1) = 1.08, p = .27, AIC = 1511.2
```{r}
anova(sf.us.within.base, sf.us.within.model1, test = 'LRT')
```

#### Base v. FHC - Sig, Chisq(1) = 18.17, p < .0001, AIC = 1494.1
```{r}
anova(sf.us.within.base, sf.us.within.model2, test = 'LRT')
```

#### Base v. IHC - Sig, Chisq(1) = 48.78, p < .0001, AIC = 1463.5.3
```{r}
anova(sf.us.within.base, sf.us.within.model3, test = 'LRT')
```

#### Base v. Highest Contig. - Sig, Chisq(1) = 35.66, p < .0001, AIC = 1476.7
```{r}
anova(sf.us.within.base, sf.us.within.model4, test = 'LRT')
```


###Ranking of productivity predictors by AIC 
1.  IHC - 1463.5 
2.  HCNN - 1476.7
3.  FHC - 1494.1
4.  Productivity - 1511.2

###Large model
Base = IHC 
```{r}
#IHC
sf.us.within.plus1 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.us.within, family = "binomial", 
                            control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

#IHC + HCNN
sf.us.within.plus2.highest.contig <- glmer(Correct ~ highest_contig.c + ihc.c + count_range + starting_num.c +  age.c + (1|SID), 
                             data = sf.us.within, family = "binomial", 
                             control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

#compare 
anova(sf.us.within.plus1, sf.us.within.plus2.highest.contig, test = 'LRT') #hcnn significant

#IHC + FHC + HCNN
sf.us.within.plus3 <- glmer(Correct ~ fhc.c + highest_contig.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.us.within, family = "binomial", 
                            control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#compare 3, minus fhc
anova(sf.us.within.plus1, sf.us.within.plus2.highest.contig, sf.us.within.plus3, test = 'LRT') #fhc does not add  
#regression table
# mtable.sf.us.large <- mtable('IHC' = sf.us.within.plus1,
#             'FHC + IHC' = sf.us.within.plus2.fhc,
#             'Highest Contig + IHC' = sf.us.within.plus2.highest.contig,
#             # 'Prod. gradient + IHC' = sf.us.within.plus2.gain,
#             'Highest Contig + FHC + IHC' = sf.us.within.plus3,
#             summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
# mtable.sf.us.large

#exp - prod.gradient + hcnn + ihc
sf.us.within.plus3.pg <- glmer(Correct ~ prod.gradient + highest_contig.c + ihc.c + starting_num.c + count_range + age.c + (1|SID), 
                             data = sf.us.within, family = "binomial", 
                             control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

anova(sf.us.within.plus2.highest.contig, sf.us.within.plus3.pg, test = 'LRT')#ns

summary(sf.us.within.plus2.highest.contig)
```

### US Unit Task within-language results: IHC and HCNN best predictor of performance on Unit Task
```{r}
summary(sf.us.within.plus2.highest.contig)
tab_model(sf.us.within.plus2.highest.contig, transform = NULL)
```

## Hindi

```{r}
#Base
sf.hindi.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
#Productivity
sf.hindi.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c  + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
#FHC
sf.hindi.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
#IHC
sf.hindi.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
#Highest contig
sf.hindi.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
```

##Table
```{r}
mtable.sf.hindi <- mtable('Base Model' = sf.hindi.within.base,
            'Model 1: Productivity' = sf.hindi.within.model1,
            'Model 2: FHC' = sf.hindi.within.model2,
            'Model 3: IHC' = sf.hindi.within.model3,
            'Model 4: Highest Contig.' = sf.hindi.within.model4,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.hindi

tab_model(sf.hindi.within.base, transform = NULL)
tab_model(sf.hindi.within.model1, transform = NULL)
tab_model(sf.hindi.within.model2, transform = NULL)
tab_model(sf.hindi.within.model3, transform = NULL)
tab_model(sf.hindi.within.model4, transform = NULL)
```

### Model comparisons
#### Base v. Productivity - marginal, p = .07
```{r}
anova(sf.hindi.within.base, sf.hindi.within.model1, test = 'LRT')
```

#### Base v. FHC - sig, Chisq(1) = 21.6, p < .0001, AIC = 1325.1
```{r}
anova(sf.hindi.within.base, sf.hindi.within.model2, test = 'LRT')
```

#### Base v. IHC - Sig, chisq(1) = 28.436, p < .0001, AIC = 1318.4
```{r}
anova(sf.hindi.within.base, sf.hindi.within.model3, test = 'LRT')
```

#### Base v. Highest contig. - Sig, Chisq(1) = 27.63, p < .0001, AIC = 1319.1
```{r}
anova(sf.hindi.within.base, sf.hindi.within.model4, test = 'LRT')
```


### Ranking of productivity predictors by AIC
1.  IHC = 1318.4
2.  HCNN = 1319.1
3.  FHC = 1325.1
4.  Productivity = 1343


## Large model

IHC v. FHC v. Highest Contig
```{r}
#IHC
sf.hindi.within.plus1 <- glmer(Correct ~ ihc.c + count_range +  starting_num.c + age.c  + (1|SID), 
                             family = "binomial", 
                           data = sf.hindi.within)
#HCNN + IHC 
sf.hindi.within.plus2.hc <- glmer(Correct ~ highest_contig.c + ihc.c + count_range + starting_num.c + age.c +  (1|SID), 
                            family = "binomial", data = sf.hindi.within)

##compare
anova(sf.hindi.within.plus1, sf.hindi.within.plus2.hc, test = 'LRT') #hcnn significantly adds to the model

#HCNN + FHC + IHC
sf.hindi.within.plus3 <- glmer(Correct ~ fhc.c + highest_contig.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = sf.hindi.within)
#Comparison of 3 minus fhc
anova(sf.hindi.within.plus1, sf.hindi.within.plus2.hc, sf.hindi.within.plus3, test = 'LRT') #FHC does not

#IHC V. prod gradient
sf.hindi.within.plus1.pg <- glmer(Correct ~ prod.gradient + highest_contig.c + ihc.c + count_range +  starting_num.c + age.c  + (1|SID),
                             family = "binomial",
                           data = sf.hindi.within)
anova(sf.hindi.within.plus2.hc, sf.hindi.within.plus1.pg, test = 'LRT')

#SUMMARY of final model
summary(sf.hindi.within.plus2.hc)
# #summary of mean nn model
# summary(sf.hindi.within.plus1.nn)

```

### Hindi Unit Task  within-language results: IHC, and Highest Contig. emerge as best predictor of performance on Unit Task
```{r}
summary(sf.hindi.within.plus2.hc)
tab_model(sf.hindi.within.plus2.hc, transform = NULL)
```

## Gujarati

```{r}
#Base
sf.gujarati.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c +  (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
#Productivity
sf.gujarati.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
#FHC
sf.gujarati.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c +  (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
#IHC
sf.gujarati.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
#Highest contig.
sf.gujarati.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.gujarati.within)

```

### Table
```{r}
mtable.sf.gujarati <- mtable('Base Model' = sf.gujarati.within.base,
            'Model 1: Productivity' = sf.gujarati.within.model1,
            'Model 2: FHC' = sf.gujarati.within.model2,
            'Model 3: IHC' = sf.gujarati.within.model3,
            'Model 4: Highest Contig.' = sf.gujarati.within.model4,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.gujarati

tab_model(sf.gujarati.within.base, transform = NULL)
tab_model(sf.gujarati.within.model1, transform = NULL)
tab_model(sf.gujarati.within.model2, transform = NULL)
tab_model(sf.gujarati.within.model3, transform= NULL)
tab_model(sf.gujarati.within.model4, transform = NULL)
```

### Model comparisons
#### Base v. productivity - NS, p = .4
```{r}
anova(sf.gujarati.within.base, sf.gujarati.within.model1, test = 'LRT')
```

### Base v. FHC - NS, p = .3
```{r}
anova(sf.gujarati.within.base, sf.gujarati.within.model2, test = 'LRT')
```

#### Base v. IHC - p = .19
```{r}
anova(sf.gujarati.within.base, sf.gujarati.within.model3, test = 'LRT') 
```

#### Base v. Highest contig, NS p = .2
```{r}
anova(sf.gujarati.within.base, sf.gujarati.within.model4, test = 'LRT')
```


## Gujarati results: Nothing predicts Unit Task performance
```{r}
summary(sf.gujarati.within.base)
tab_model(sf.gujarati.within.base, transform = NULL)
```

***

# WCN Task- within-language analyses, simple models

## HK: Within-language analyses, Next Number Task
### Build the models
```{r}
#base
wcn.hk.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
#productivity
wcn.hk.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
#FHC
wcn.hk.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
#IHC
wcn.hk.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
```

### Hong Kong: NN task models
```{r}
mtable.wcn.hk <- mtable('Base Model' = wcn.hk.within.base,
            'Model 1: Productivity' = wcn.hk.within.model1,
            'Model 2: FHC' = wcn.hk.within.model2,
            'Model 3: IHC' = wcn.hk.within.model3,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.hk

tab_model(wcn.hk.within.base, transform = NULL)
tab_model(wcn.hk.within.model1, transform = NULL)
tab_model(wcn.hk.within.model2, transform = NULL)
tab_model(wcn.hk.within.model3, transform = NULL)

```

### Model comparisons
#### Base v. Productivity - NS, p = .36
```{r}
anova(wcn.hk.within.base, wcn.hk.within.model1, test = 'LRT')
```

#### Base v. FHC - Sig, Chisq(1) = 34.33, p < .0001, AIC = 1171.2
````{r}
anova(wcn.hk.within.base, wcn.hk.within.model2, test = 'LRT')
````

#### Base v. IHC = Sig, Chisq(1) = 68.63, p < .0001, AIC = 1136.9
```{r}
anova(wcn.hk.within.base, wcn.hk.within.model3, test = 'LRT')
```

#### Exploratory - prod. gradient - Sig, Prod. 
```{r}
anova(wcn.hk.within.base, wcn.hk.within.model.gain, test = 'LRT')
```

### Ranking of HK prod. predictors - WCN by AIC
1.  IHC - 1136.9
2.  FHC - 1171.2
3.  Productivity - 1206.7 (NS)


## Large Model
```{r}
#IHC
wcn.hk.within.plus1 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.hk.within)
#IHC + FHC
wcn.hk.within.plus2 <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = wcn.hk.within)

#compare IHC and FHC
anova(wcn.hk.within.plus1, wcn.hk.within.plus2, test = 'LRT')  #FHC 

#exp - prod.gradient
wcn.hk.within.plus.gain <- glmer(Correct ~ prod.gradient + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.hk.within)
#anova
anova(wcn.hk.within.plus1, wcn.hk.within.plus.gain, test = 'LRT')#prod. gradient NS

mtable.wcn.hk.large <- mtable('IHC alone' = wcn.hk.within.plus1,
            'IHC + FHC' = wcn.hk.within.plus2,
            'Exp: IHC + Gradient' = wcn.hk.within.plus.gain,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.hk.large

summary(wcn.hk.within.plus1)
```

### HK NN Task within-language results: IHC emerge as best predictor of performance on Unit Task
```{r}
summary(wcn.hk.within.plus1)
tab_model(wcn.hk.within.plus1, transform = NULL)
```


## SLO: Within-language analyses, NN Task
### Build the models
```{r}
#Base
wcn.slo.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
#Productivity
wcn.slo.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
#FHC
wcn.slo.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
#IHC
wcn.slo.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
```

### Table
```{r}
mtable.wcn.slo <- mtable('Base Model' = wcn.slo.within.base,
            'Model 1: Productivity' = wcn.slo.within.model1,
            'Model 2: FHC' = wcn.slo.within.model2,
            'Model 3: IHC' = wcn.slo.within.model3,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.slo

tab_model(wcn.slo.within.base, transform = NULL)
tab_model(wcn.slo.within.model1, transform = NULL)
tab_model(wcn.slo.within.model2, transform = NULL)
tab_model(wcn.slo.within.model3, transform = NULL)
```

### Model comparisons
#### Base v. Productivity - Sig, Chisq(1) = 40.26, p < .0001, AIC = 863.31
```{r}
anova(wcn.slo.within.base, wcn.slo.within.model1, test = 'LRT')
```

#### Base v. FHC - Sig, Chisq(1) = 72.93, p < .0001, AIC = 830.63
```{r}
anova(wcn.slo.within.base, wcn.slo.within.model2, test = 'LRT')
```

#### Base v. IHC - Sig, Chisq(1) = 36.19 p < .0001, AIC = 867.38
```{r}
anova(wcn.slo.within.base, wcn.slo.within.model3, test = 'LRT')
```

### Ranking of prod predictors - WCN by AIC
1.  FHC - 830.64
2.  Productivity - 863.01
3.  IHC - 8567.38


### Large Model comparison
```{r}
#FHC
wcn.slo.within.plus1 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.slo.within)
#Prod + FHC
wcn.slo.within.plus2.prod <- glmer(Correct ~ Productive + fhc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)

#compare
anova(wcn.slo.within.plus1, wcn.slo.within.plus2.prod, test = 'LRT')#Prod NS

#IHC + FHC
wcn.slo.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)

#compare
anova(wcn.slo.within.plus1, wcn.slo.within.plus2, test = 'LRT')# IHC NS

summary(wcn.slo.within.plus1)
```

### SLO NN Task (interim) within-language results: FHC emerges as best predictors of performance on Unit Task
```{r}
summary(wcn.slo.within.plus1)
tab_model(wcn.slo.within.plus1, transform = NULL)
```

## US: Within-language analyses, NN Task
### Build the models
```{r}
#base
wcn.us.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)
#productivity
wcn.us.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)
#FHC
wcn.us.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)
#IHC
wcn.us.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)

```

### English (US): NN Task models
```{r}
mtable.wcn.us <- mtable('Base Model' = wcn.us.within.base,
            'Model 1: Productivity' = wcn.us.within.model1,
            'Model 2: FHC' = wcn.us.within.model2,
            'Model 3: IHC' = wcn.us.within.model3,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.us

tab_model(wcn.us.within.base, transform = NULL)
tab_model(wcn.us.within.model1, transform = NULL)
tab_model(wcn.us.within.model2, transform = NULL)
tab_model(wcn.us.within.model3, transform = NULL)
```

### Model comparisons
#### Base v. Productivity - Sig, Chisq(1) = 14.74, p = .0001, AIC = 1041.8
```{r}
anova(wcn.us.within.base, wcn.us.within.model1, test = 'LRT')
```

#### Base v. FHC - Sig, Chisq(1) = 43.93, p < .0001, AIC = 1012.6
```{r}
anova(wcn.us.within.base, wcn.us.within.model2, test = 'LRT')
```

#### Base v. IHC - Sig, Chisq(1) = 30.49, p < .0001, AIC = 1026.1
```{r}
anova(wcn.us.within.base, wcn.us.within.model3, test = 'LRT')
```

### Ranking of prod predictors - WCN by AIC
1.  FHC - 1013
2.  IHC - 1026.5
3.  Productivity - 1042.3

### Large Model comparison
```{r}
#FHC
wcn.us.within.plus1 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.us.within)
#IHC + FHC
wcn.us.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + starting_num.c + 
                               age.c + (1|SID), 
                            family = "binomial", data = wcn.us.within)
#compare
anova(wcn.us.within.plus1, wcn.us.within.plus2, test = 'LRT') #IHC marginal

#Prod + FHC
wcn.us.within.plus2.prod <- glmer(Correct ~ Productive + fhc.c + count_range + starting_num.c + 
                                    age.c + (1|SID), 
                            family = "binomial", data = wcn.us.within)
#compare
anova(wcn.us.within.plus1, wcn.us.within.plus2.prod, test = 'LRT') #Prod NS
```

### US NN Task (interim) within-language results: FHC emerges as best predictor of performance on Unit Task
```{r}
summary(wcn.us.within.plus1)
tab_model(wcn.us.within.plus1, transform = NULL)
```


## Hindi: Within-language analyses, NN
### Build the models
```{r}
#Base Model
wcn.hindi.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c  + (1|SID), family = "binomial", 
                            data = wcn.hindi.within)
#Productivity
wcn.hindi.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c +(1|SID), family = "binomial", 
                            data = wcn.hindi.within)
#FHC
wcn.hindi.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c +(1|SID), family = "binomial", 
                            data = wcn.hindi.within)
#IHC
wcn.hindi.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.hindi.within)
```

##Hindi: NN Task models 
Summary
```{r}
mtable.hindi <- mtable('Base Model' = wcn.hindi.within.base,
            'Model 1: Productivity' = wcn.hindi.within.model1,
            'Model 2: FHC' = wcn.hindi.within.model2,
            'Model 3: IHC' = wcn.hindi.within.model3,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.hindi

tab_model(wcn.hindi.within.base, transform= NULL)
tab_model(wcn.hindi.within.model1, transform = NULL)
tab_model(wcn.hindi.within.model2, transform = NULL)
tab_model(wcn.hindi.within.model3, transform = NULL)
```

### Model comparisons
#### Base v. Productivity - sig, Chisq(1) = 4.5, p = .03, AIC = 850.45
```{r}
anova(wcn.hindi.within.base, wcn.hindi.within.model1, test = 'LRT')
```

#### Base v. FHC - sig, Chisq(1) = 27.4, p < .0001, AIC = 827.62
```{r}
anova(wcn.hindi.within.base, wcn.hindi.within.model2, test = 'LRT')
```

#### Base v. IHC - Sig, Chisq(1) = 33.41, p < .0001, AIC = 821.6
```{r}
anova(wcn.hindi.within.base, wcn.hindi.within.model3, test = 'LRT')
```

#### Base v. Prod. gradient - Sig, Chisq(1) = 10.03, p = .001, AIC = 844.97
```{r}
anova(wcn.hindi.within.base, wcn.hindi.within.model.gain, test = 'LRT')
```

### Ranking of NN predictors, HIndi, by AIC
1.  IHC - 821.6
2.  FHC - 827.6
3.  Productivity - 850


### Large Model
```{r}
#IHC
wcn.hindi.within.plus1 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.hindi.within)
#FHC + IHC
wcn.hindi.within.plus2 <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = wcn.hindi.within)

#compare
anova(wcn.hindi.within.plus1, wcn.hindi.within.plus2, test= 'LRT')#FHC NS

#Prod + IHC
wcn.hindi.within.plus2.prod <- glmer(Correct ~ Productive + ihc.c + count_range + starting_num.c +age.c +  (1|SID), 
                            family = "binomial", data = wcn.hindi.within)

#compare
anova(wcn.hindi.within.plus1, wcn.hindi.within.plus2.prod, test = 'LRT')# prod ns

# #IHC v. IHC+FHC
# anova(wcn.hindi.within.plus1, wcn.hindi.within.plus2, test = 'LRT') 
# #IHC v. Prod + FHC
# anova(wcn.hindi.within.plus1, wcn.hindi.within.plus2.prod, test = 'LRT') 

```

### Hindi NN Task within-language results: IHC emerges as best predictor of performance on Unit Task
```{r}
summary(wcn.hindi.within.plus1)
tab_model(wcn.hindi.within.plus1, transform = NULL)
```

## Gujarati: Within-language analyses, NN
### Build the models
```{r}
#Base Model
wcn.gujarati.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c +  (1|SID), family = "binomial", 
                            data = wcn.gujarati.within)
#Productivity
wcn.gujarati.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c +age.c +  (1|SID), family = "binomial", 
                            data = wcn.gujarati.within)
#FHC
wcn.gujarati.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c +  (1|SID), family = "binomial", 
                            data = wcn.gujarati.within)
#IHC
wcn.gujarati.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.gujarati.within)
```

### Gujarati: NN Task models 
Summary
```{r}
mtable.gujarati <- mtable('Base Model' = wcn.gujarati.within.base,
            'Model 1: Productivity' = wcn.gujarati.within.model1,
            'Model 2: FHC' = wcn.gujarati.within.model2,
            'Model 3: IHC' = wcn.gujarati.within.model3,
            # 'Exp: Prod. gradient' = wcn.gujarati.within.model.gain,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.gujarati

tab_model(wcn.gujarati.within.base, transform = NULL)
tab_model(wcn.gujarati.within.model1, transform = NULL)
tab_model(wcn.gujarati.within.model2, transform = NULL)
tab_model(wcn.gujarati.within.model3, transform= NULL)
```

### Model comparisons
#### Base v. Productivity - Sig, Chisq(1) = 10.06, p = .002, AIC = 787.41
```{r}
anova(wcn.gujarati.within.base, wcn.gujarati.within.model1, test = 'LRT')
```

#### Base v. FHC - Sig, Chisq(1) = 36.25, p < .0001, AIC  761.2
```{r}
anova(wcn.gujarati.within.base, wcn.gujarati.within.model2, test = 'LRT')
```

#### Base v. IHC = Sig, Chisq(1) = 33.45, p < .0001, AIC = 764.02
```{r}
anova(wcn.gujarati.within.base, wcn.gujarati.within.model3, test = 'LRT')
```

### Ranking of NN Predictors, Gujarati, by AIC 
1.  FHC - 761.2
2.  IHC - 764.02
3.  Productivity - 787

### Large Model
```{r}
#FHC
wcn.gujarati.within.plus1 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c +  (1|SID), 
                             family = "binomial", 
                           data = wcn.gujarati.within)
#IHC + FHC
wcn.gujarati.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + starting_num.c + age.c +  (1|SID), 
                            family = "binomial", data = wcn.gujarati.within)
#compare
anova(wcn.gujarati.within.plus1, wcn.gujarati.within.plus2, test = 'LRT') #IHC ns

#Prod + FHC
wcn.gujarati.within.plus2.prod <- glmer(Correct ~ Productive + fhc.c + count_range + starting_num.c +age.c +  (1|SID), 
                            family = "binomial", data = wcn.gujarati.within)
#compare
anova(wcn.gujarati.within.plus1, wcn.gujarati.within.plus2.prod, test = 'LRT') #Productivity significant

##ADD IHC, compare
wcn.gujarati.within.plus3 <- glmer(Correct ~ ihc.c + Productive + fhc.c + count_range + age.c + starting_num.c + (1|SID),
                            family = "binomial", data = wcn.gujarati.within)
anova(wcn.gujarati.within.plus2.prod, wcn.gujarati.within.plus3, test = 'LRT') #IHC NS

```

### Gujarati NN Task within-language results: FHC and Productivity emerge as best predictor of performance on Unit Task
```{r}
summary(wcn.gujarati.within.plus2.prod)
tab_model(wcn.gujarati.within.plus2.prod, transform = NULL)
```

## India English: Within-language analyses, NN task

Build the models
```{r}
#Base Model
wcn.ind.eng.within.base <- glmer(Correct ~ count_range + starting_num.c +age.c +  (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
#Productivity
wcn.ind.eng.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c +age.c +  (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
#FHC
wcn.ind.eng.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c +age.c +  (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
#IHC
wcn.ind.eng.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c +age.c +  (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
```

### English (India) WCN Models 
Summary
```{r}
mtable.ind.eng <- mtable('Base Model' = wcn.ind.eng.within.base,
            'Model 1: Productivity' = wcn.ind.eng.within.model1,
            'Model 2: FHC' = wcn.ind.eng.within.model2,
            'Model 3: IHC' = wcn.ind.eng.within.model3,
            # 'Exp: Prod. gradient' = wcn.ind.eng.within.model.gain,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.ind.eng

tab_model(wcn.ind.eng.within.base, transform = NULL)
tab_model(wcn.ind.eng.within.model1, transform = NULL)
tab_model(wcn.ind.eng.within.model2, transform = NULL)
tab_model(wcn.ind.eng.within.model3, transform = NULL)
```

### Model comparisons
#### Base v. Productivity - NS
```{r}
anova(wcn.ind.eng.within.base, wcn.ind.eng.within.model1, test = 'LRT')
```

#### Base v. FHC - Sig, Chisq(1) = 21.1, p < .0001, AIC = 678.7
```{r}
anova(wcn.ind.eng.within.base, wcn.ind.eng.within.model2, test = 'LRT')
```

#### Base v. IHC - Sig, Chisq(1) = 19.49, p < .0001, AIC = 680.30
```{r}
anova(wcn.ind.eng.within.base, wcn.ind.eng.within.model3, test = 'LRT')
```

### Large Model

```{r}
#FHC
wcn.ind.eng.within.plus1 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c +  (1|SID), 
                             family = "binomial", 
                           data = wcn.ind.eng.within)
#IHC + FHC
wcn.ind.eng.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + starting_num.c + age.c +  (1|SID), 
                            family = "binomial", data = wcn.ind.eng.within)

anova(wcn.ind.eng.within.plus1, wcn.ind.eng.within.plus2,test = 'LRT') #IHC sig

summary(wcn.ind.eng.within.plus2)
```

### English (India) NN Task within-language results: IHC and FHC emerge as best predictors of performance on Unit Task
```{r}
summary(wcn.ind.eng.within.plus2)
tab_model(wcn.ind.eng.within.plus2, transform = NULL)
```
---

# Cross-linguistic comparisons

## Make model dfs
```{r, include = FALSE}
#currently for Exp 1
sf.df.cross <- all.data %>%
  filter(Task == "SF", 
         Language == "Cantonese" |
           Language == "Slovenian" | 
           Language == "English (US)")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Language = factor(Language, levels = c("Cantonese", "Slovenian", "English (US)"))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))%>%
  filter(!is.na(highest_contig.c)) #filter out kids who do not have HCNN
  
wcn.df.cross <- all.data %>%
  filter(Task == "NN",
         Language == "Cantonese" |
           Language == "Slovenian" | 
           Language == "English (US)")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))

##For India
sf.df.cross.india <- all.data %>%
  filter(Task == "SF", 
         Language == "English (US)" |
           Language == "Hindi" | 
           Language == "Gujarati")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Language = factor(Language, levels = c("English (US)", "Hindi", "Gujarati"))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))%>%
  filter(!is.na(highest_contig.c)) #filter out kids who do not have HCNN

wcn.df.cross.india <- all.data %>%
  filter(Task == "NN", 
         Language == "English (US)" |
           Language == "Hindi" | 
           Language == "Gujarati")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Language = factor(Language, levels = c("English (US)", "Hindi", "Gujarati"))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))%>%
  filter(!is.na(highest_contig.c)) #filter out kids who do not have HCNN

#followup with Indian English 
wcn.df.cross.india.follow <- all.data %>%
  filter(Task == "NN", 
         Language == "English (India)" |
           Language == "Hindi" | 
           Language == "Gujarati")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Language = factor(Language, levels = c("English (India)", "Hindi", "Gujarati"))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))%>%
  filter(!is.na(highest_contig.c)) #filter out kids who do not have HCNN
```

## Experiment 1
### Unit Task: Cross linguistic models - HK/SLO/US (Cantonese as reference group)
#### Build the models
```{r}
#base
sf.cross.base <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#productivity
sf.cross.model1 <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c +age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#fhc
sf.cross.model2 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#highest contig.
sf.cross.model3 <- glmer(Correct ~ highest_contig.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = sf.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
```

##Cross-linguistic model comparison
```{r}
mtable.sf.cross <- mtable('Base Model' = sf.cross.base,
            'Model 1: Productivity' = sf.cross.model1,
            'Model 2: FHC' = sf.cross.model2,
            'Model 3: Highest Contig.' = sf.cross.model3, 
            # 'Exp: Prod. gradient' = sf.cross.model.gain,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.cross

tab_model(sf.cross.base, transform = NULL)
tab_model(sf.cross.model1, transform = NULL)
tab_model(sf.cross.model2, transform = NULL)
```

#### Model Comparisons
##### Base v. productivity - NS, p = .22
```{r}
anova(sf.cross.base, sf.cross.model1, test = 'LRT')
```

##### Base v. FHC - NS, p = .15
```{r}
anova(sf.cross.base, sf.cross.model2, test = 'LRT')
```

##### Base v. Highest contig. - Sig, Chisq(1) = 22.695, p < .0001, AIC = 4379.3.
```{r}
anova(sf.cross.base, sf.cross.model3, test = 'LRT')
```

### HCNN emerges as best cross-linguistic predictor
```{r}
tab_model(sf.cross.model3, transform = NULL)
```

#### Do the same process with Slovenian as the reference group
```{r}
slo.ref <- sf.df.cross %>%
  mutate(Language = factor(Language, levels = c("Slovenian", "English (US)", "Cantonese")))

#base
sf.cross.base.slo <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = slo.ref, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

#model output
tab_model(sf.cross.base.slo, transform = NULL)
#productivity
sf.cross.model1.slo <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c +age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = slo.ref, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))


#model output
tab_model(sf.cross.model1.slo, transform = NULL)
#fhc
sf.cross.model2.slo <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = slo.ref, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
tab_model(sf.cross.model2.slo, transform = NULL)
#highest contig.
sf.cross.model3.slo <- glmer(Correct ~ highest_contig.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = slo.ref, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

tab_model(sf.cross.model3.slo, transform = NULL)

```

##Large model - no model comparison needed, only sig. predictor above is HCNN
```{r}
#cantonese as comparison
summary(sf.cross.model3)
tab_model(sf.cross.model3, transform = NULL)

#slovenian as comparison
tmp <- sf.df.cross %>%
  mutate(Language = factor(Language, levels = c("Slovenian", "English (US)", "Cantonese")))

sf.cross.model3.slo.comp <- glmer(Correct ~ highest_contig.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = tmp, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
tab_model(sf.cross.model3.slo.comp, transform = NULL)
```

## Experiment 2
#### Unit Task: Cross linguistic models - India (English/Hindi/Gujarati)
##### Build the models
```{r}
#base
sf.cross.base.india <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#productivity
sf.cross.model1.india <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c +age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#fhc
sf.cross.model2.india <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#highest contig.
sf.cross.model3.india <- glmer(Correct ~ highest_contig.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = sf.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
```

##Cross-linguistic model comparison
```{r}
mtable.sf.cross.india <- mtable('Base Model' = sf.cross.base.india,
            'Model 1: Productivity' = sf.cross.model1.india,
            'Model 2: FHC' = sf.cross.model2.india,
            'Model 3: Highest Contig.' = sf.cross.model3.india,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.cross.india

tab_model(sf.cross.base.india, transform = NULL)
tab_model(sf.cross.model1.india, transform = NULL)
tab_model(sf.cross.model2.india, transform = NULL)
tab_model(sf.cross.model3.india, transform = NULL)
```

#### Model Comparisons
##### Base v. productivity - NS, p = .87
```{r}
anova(sf.cross.base.india, sf.cross.model1.india, test = 'LRT')
```

##### Base v. FHC - NS, p = .95
```{r}
anova(sf.cross.base.india, sf.cross.model2.india, test = 'LRT')
```

##### Base v. Highest contig. - Sig, Chisq(1) = 13.18, p = .0003, AIC = 3940.5
```{r}
anova(sf.cross.base.india, sf.cross.model3.india, test = 'LRT')
```

#### Large model - no model comparison needed, only sig. predictor above is HCNN
```{r}
#Summary of final model - hcnn
summary(sf.cross.model3.india)
tab_model(sf.cross.model3.india, transform = NULL)

```























---

##Productivity t-test of Unit Task performance
Using the Resilient/Non-Resilient categorical classification outlined above, we will compare performance between both groups on the Unit task using t-tests. We may do this by considering average performance (averaging the 0s and 1s on each task for each participant); should doing so provide greater precision, we may also compare Highest Contiguous Number.

###HK: Marginally significant difference between groups (*p* = .06)
```{r}
#with mean performance
sf.hk.mean.ms <- all.data %>%
  filter(Language == "Cantonese", 
         Task == "SF")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(subset(sf.hk.mean.ms, Productive == "Resilient")$mean, 
       subset(sf.hk.mean.ms, Productive == "Non-Resilient")$mean, var.equal = TRUE) #marginally significant difference between productive and nonproductive counters for performance on Unit Task

t.test(subset(sf.hk.mean.ms)$mean, mu = .5, var.equal = TRUE)
```

###SLO
```{r}
#with mean performance
sf.slo.mean.ms <- all.data %>%
  filter(Language == "Slovenian", 
         Task == "SF")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(subset(sf.slo.mean.ms, Productive == "Resilient")$mean, 
       subset(sf.slo.mean.ms, Productive == "Non-Resilient")$mean, var.equal = TRUE) #significant difference in performance between productive and nonproductive counters

#test against chance
t.test(subset(sf.slo.mean.ms)$mean, mu = .5, var.equal = TRUE)
```

###US
```{r}
#with mean performance
sf.us.mean.ms <- all.data %>%
  filter(Language == "English (US)", 
         Task == "SF")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(subset(sf.us.mean.ms, Productive == "Resilient")$mean, 
       subset(sf.us.mean.ms, Productive == "Non-Resilient")$mean, var.equal = TRUE) #significant difference in performance between productive and nonproductive counters

#test against chance
t.test(subset(sf.us.mean.ms)$mean, mu = .5, var.equal = TRUE)
```

###Hindi
```{r}
#with mean performance
sf.hindi.mean.ms <- all.data %>%
  filter(Language == "Hindi", 
         Task == "SF")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(subset(sf.hindi.mean.ms, Productive == "Resilient")$mean, 
       subset(sf.hindi.mean.ms, Productive == "Non-Resilient")$mean, var.equal = TRUE) #significant difference in performance between productive and nonproductive counters

#test against chance
t.test(subset(sf.hindi.mean.ms)$mean, mu = .5, var.equal = TRUE)

#follow up removing largest numbers
sf.hindi.mean.ms <- all.data %>%
  filter(Language == "Hindi", 
         Task == "SF", 
         Task_item != "224", 
         Task_item != "252", 
         Task_item != "271")%>%
  group_by(SID)%>% 
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(sf.hindi.mean.ms$mean, mu = .5, var.equal = TRUE)

##correlations 
hindi.cor.dat <- all.data %>%
  filter(Language == "Hindi", 
         Task == "SF") %>%
  mutate(Task_item = as.numeric(as.character(Task_item)))%>%
  group_by(Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

cor.test(hindi.cor.dat$Task_item, hindi.cor.dat$mean)


```

###Gujarati
```{r}
#with mean performance
sf.gujarati.mean.ms <- all.data %>%
  filter(Language == "Gujarati", 
         Task == "SF")%>%
  group_by(SID, Productive)%>% 
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(subset(sf.gujarati.mean.ms, Productive == "Resilient")$mean, 
       subset(sf.gujarati.mean.ms, Productive == "Non-Resilient")$mean, var.equal = TRUE) #significant difference in performance between productive and nonproductive counters

t.test(subset(sf.gujarati.mean.ms)$mean, mu = .5, var.equal = TRUE)

#follow up removing largest numbers
sf.gujarati.mean.ms <- all.data %>%
  filter(Language == "Gujarati", 
         Task == "SF", 
         Task_item != "224", 
         Task_item != "252", 
         Task_item != "271")%>%
  group_by(SID)%>% 
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(sf.gujarati.mean.ms$mean, mu = .5, var.equal = TRUE)
```

--- 
# Next Number Cross-linguistic models
## Experiment 1

### Build the models
```{r}
#base
wcn.cross.base <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#Productivity
wcn.cross.model1 <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#FHC
wcn.cross.model2 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross, family = "binomial", 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

```

##Cross-linguistic model comparison
```{r}
mtable.wcn.cross <- mtable('Base Model' = wcn.cross.base,
            'Model 1: Productivity' = wcn.cross.model1,
            'Model 2: FHC' = wcn.cross.model2,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.cross

tab_model(wcn.cross.base, transform = NULL)
tab_model(wcn.cross.model1, transform = NULL)
tab_model(wcn.cross.model2, transform = NULL)

```

### Model comparisons
#### Base v. Productivity - Sig, Chisq(1) = 19.4, p < .0001, AIC = 2968.2
```{r}
anova(wcn.cross.base, wcn.cross.model1, test = 'LRT')
```

#### Base v. FHC - Sig, Chisq(1) = 38.96, p < .0001, AIC = 2949.1
```{r}
anova(wcn.cross.base, wcn.cross.model2, test = 'LRT')
```


##Ranking of productivity predictors - WCN by AIC
1.  FHC - 2949.5
2.  Productivity - 2968.6

##Large model
```{r}
wcn.cross.plus1 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross, 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
wcn.cross.plus2 <- glmer(Correct ~ Productive + fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross, 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

anova(wcn.cross.plus1, wcn.cross.plus2, test = 'LRT')#Prod is NS

#what about productivity gradient? 
wcn.cross.plus.gain <- glmer(Correct ~ prod.gradient + fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross, 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
anova(wcn.cross.plus1, wcn.cross.plus.gain, test = 'LRT')

# mtable.wcn.cross.large <- mtable('FHC alone' = wcn.cross.plus1,
#             'Productive + FHC.' = wcn.cross.plus2,
#             summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
# mtable.wcn.cross.large

#summary of final model
summary(wcn.cross.plus1)
tab_model(wcn.cross.plus1, transform = NULL)
# summary(wcn.cross.plus.gain)

```

##Slovenian as comparison 
```{r}
wcn.df.cross.slo <- wcn.df.cross %>%
  mutate(Language = factor(Language, levels = c("Slovenian", "English (US)", "Cantonese")))

###BUILD THE MODELS
#base
wcn.cross.base.slo <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross.slo, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

tab_model(wcn.cross.base.slo, transform = NULL)
#Productivity
wcn.cross.model1.slo <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross.slo, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

tab_model(wcn.cross.model1.slo, transform = NULL)
#FHC
wcn.cross.model2.slo <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross.slo, family = "binomial", 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
tab_model(wcn.cross.model2.slo, transform = NULL)

#Exp - prod. gradient
wcn.cross.model.gain.slo <- glmer(Correct ~ prod.gradient + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross.slo, family = "binomial", 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

```


#Test if effects of language are significant
```{r}
wcn.nolang.base <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial", 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
wcn.nolang.model1 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial", 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
anova(wcn.nolang.base, wcn.nolang.model1, test = 'LRT') 
```








***


---

#Productivity t-test of WCN performance
Using the Productive/Non-Productive categorical classification outlined above, we will compare performance between both groups on the Next Number task using t-tests. We may do this by considering average performance
(averaring the 0s and 1s on each task for each participant).

###HK: Significant difference between productive and nonproductive counters (*p* = .002)
```{r}
#with mean performance
wcn.hk.mean.ms <- all.data %>%
  filter(Language == "Cantonese", 
         Task == "NN")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(subset(wcn.hk.mean.ms, Productive == "Resilient")$mean, 
       subset(wcn.hk.mean.ms, Productive == "Non-Resilient")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

###SLO: Significant difference between groups (*p* < .0001)

```{r}
#with mean performance
wcn.slo.mean.ms <- all.data %>%
  filter(Language == "Slovenian", 
         Task == "NN")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(subset(wcn.slo.mean.ms, Productive == "Resilient")$mean, 
       subset(wcn.slo.mean.ms, Productive == "Non-Resilient")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

###US: Significant difference between groups (*p* < .0001)

```{r}
#with mean performance
wcn.us.mean.ms <- all.data %>%
  filter(Language == "English (US)", 
         Task == "NN")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))


t.test(subset(wcn.us.mean.ms, Productive == "Resilient")$mean, 
       subset(wcn.us.mean.ms, Productive == "Non-Resilient")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```


###Hindi

```{r}
#with mean performance
wcn.hindi.mean.ms <- all.data %>%
  filter(Language == "Hindi", 
         Task == "NN")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(subset(wcn.hindi.mean.ms, Productive == "Resilient")$mean, 
       subset(wcn.hindi.mean.ms, Productive == "Non-Resilient")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

###Gujarati

```{r}
#with mean performance
wcn.gujarati.mean.ms <- all.data %>%
  filter(Language == "Gujarati", 
         Task == "NN")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(subset(wcn.gujarati.mean.ms, Productive == "Resilient")$mean, 
       subset(wcn.gujarati.mean.ms, Productive == "Non-Resilient")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

###Indian English

```{r}
#with mean performance
wcn.ind.eng.mean.ms <- all.data%>%
  filter(Language == "English (India)", 
         Task == "NN")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

t.test(subset(wcn.ind.eng.mean.ms, Productive == "Resilient")$mean, 
       subset(wcn.ind.eng.mean.ms, Productive == "Non-Resilient")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

---



***



###Cross-linguistic comparison of mean performance on unit task 
```{r}
sf.df.cross.india.ms <- all.data %>%
  filter(Task == "SF")%>%
  filter(Language == "English (US)" |
           Language == "Hindi" |
           Language == "Gujarati")%>%
  mutate(age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=FALSE)))%>%
  group_by(SID, Language, age.c, wppsi.c)%>%
  summarise(mean_sf = mean(Correct, na.rm = TRUE))

lm.india <- lm(mean_sf ~ Language*age.c + wppsi.c, data = sf.df.cross.india.ms)
summary(lm.india)
```


---

#Experiment 2
##WCN India
##Build the models
```{r}
#base
wcn.cross.base.india <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#Productivity
wcn.cross.model1.india <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#FHC
wcn.cross.model2.india <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross.india, family = "binomial", 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

#Exp - Prod. gradient
wcn.cross.model.gain <- glmer(Correct ~ prod.gradient + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross.india, family = "binomial", 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))


```

##Cross-linguistic model comparison
```{r}
mtable.wcn.cross.india <- mtable('Base Model' = wcn.cross.base.india,
            'Model 1: Productivity' = wcn.cross.model1.india,
            'Model 2: FHC' = wcn.cross.model2.india,
            'Exp: Prod. gradient' = wcn.cross.model.gain,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.cross.india

tab_model(wcn.cross.base.india, transform = NULL)
tab_model(wcn.cross.model1.india, transform = NULL)
tab_model(wcn.cross.model2.india, transform = NULL)
```

##Model comparisons
###Base v. Productivity - Sig, Chisq(1) = 9.9, p = .002, AIC = 2550.3
```{r}
anova(wcn.cross.base.india, wcn.cross.model1.india, test = 'LRT')
```

###Base v. FHC - Sig, Chisq(1) = 22.68, p < .0001, AIC = 2537.6
```{r}
anova(wcn.cross.base.india, wcn.cross.model2.india, test = 'LRT')
```

###Base v. Prod. gradient - Sig, Chisq(1) = 16.05, p < .0001, AIC = 2544
```{r}
anova(wcn.cross.base.india, wcn.cross.model.gain, test = 'LRT')
```

##Large model
```{r}
#FHC
wcn.cross.plus1.india <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross.india, 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#Prod + FHC
wcn.cross.plus2.india <- glmer(Correct ~ Productive + fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross.india, 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

anova(wcn.cross.plus1.india, wcn.cross.plus2.india, test = 'LRT')##Prod does not add to this model

#what about productivity gradient
wcn.cross.plus2.gain <- glmer(Correct ~ prod.gradient + fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross.india, 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

anova(wcn.cross.plus1.india, wcn.cross.plus2.gain, test = 'LRT')##prod gradient does not add to this model


mtable.wcn.cross.large.india <- mtable('FHC alone' = wcn.cross.plus1.india,
            'Productive + FHC.' = wcn.cross.plus2.india,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.cross.large.india

#summary of final model
summary(wcn.cross.plus1.india)
tab_model(wcn.cross.plus1.india, transform = NULL)

```

##Test if interaction between FHC and language is significant
```{r}
lang.prod.int.india.noint <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), family = "binomial", data = wcn.df.cross.india, 
                            control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
lang.prod.int.india <- glmer(Correct ~ fhc.c*Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), family = "binomial", data = wcn.df.cross.india, 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

anova(lang.prod.int.india.noint, lang.prod.int.india, test = 'LRT')##FHC does not interact with language

summary(lang.prod.int.india)
summary(lang.prod.int.india.noint)
```

###Test if effects of language are significant
```{r}
ind.lang <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), family = "binomial", data = wcn.df.cross.india, 
                            control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
ind.nolang <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), family = "binomial", data = wcn.df.cross.india, 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

anova(ind.lang, ind.nolang, test = 'LRT')#language significant
summary(ind.lang)

```

#Cross-linguistic comparison of mean performance on nn task 
```{r}
nn.df.cross.india.ms <- all.data %>%
  filter(Task == "NN")%>%
  filter(Language == "English (US)" |
           Language == "Hindi" |
           Language == "Gujarati")%>%
  mutate(age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=FALSE)))%>%
  group_by(SID, Language, age.c, wppsi.c)%>%
  summarise(mean_sf = mean(Correct, na.rm = TRUE))

lm.india <- lm(mean_sf ~ Language*age.c + wppsi.c, data = nn.df.cross.india.ms)
summary(lm.india)

nn.df.cross.india.ms <- all.data %>%
  filter(Task == "NN")%>%
  filter(Language == "English (India)" |
           Language == "Hindi" |
           Language == "Gujarati")%>%
  mutate(age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=FALSE)))%>%
  group_by(SID, Language, age.c, wppsi.c)%>%
  summarise(mean_sf = mean(Correct, na.rm = TRUE))

lm.india <- lm(mean_sf ~ Language*age.c + wppsi.c, data = nn.df.cross.india.ms)
summary(lm.india)
```
---



#Lang*prod interaction because we found significant effects for FHC in SLO and English, but not Cantonese
```{r}
wcn.prod.int <- glmer(Correct ~ fhc.c*Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial", 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
wcn.prod.noint <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial", 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
anova(wcn.prod.noint, wcn.prod.int, test = 'LRT') 

summary(wcn.prod.int)

all.data %>%
  filter(Task == "NN", 
         Language == "Cantonese" | 
           Language == "English (US)" | 
           Language == "Slovenian")%>%
  group_by(SID, IHC, FHC, Language)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = FHC, y = mean, color = IHC, group = Language)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  facet_grid(~Language)
```

---
#Experiment 2
#Followup with Indian English for NN
##Build the models
```{r}
#base
wcn.cross.base.india.follow <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross.india.follow, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#Productivity
wcn.cross.model1.india.follow <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross.india.follow, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#FHC
wcn.cross.model2.india.follow <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross.india.follow, family = "binomial", 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

#Exp - prod. gradient
wcn.cross.model.gain.india.follow <- glmer(Correct ~ prod.gradient + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross.india.follow, family = "binomial", 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

```

##Cross-linguistic model comparison
```{r}
mtable.wcn.cross.india.follow <- mtable('Base Model' = wcn.cross.base.india.follow,
            'Model 1: Productivity' = wcn.cross.model1.india.follow,
            'Model 2: FHC' = wcn.cross.model2.india.follow,
            'Exp: Prod. gradient' = wcn.cross.model.gain.india.follow,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.cross.india.follow

tab_model(wcn.cross.base.india.follow, transform = NULL)
tab_model(wcn.cross.model1.india.follow, transform = NULL)
tab_model(wcn.cross.model2.india.follow, transform = NULL)
```

##Model comparisons
###Base v. Productivity - NS
```{r}
anova(wcn.cross.base.india.follow, wcn.cross.model1.india.follow, test = 'LRT')
```

###Base v. FHC - Sig, Chisq(1) = 8.36, p = .004, AIC = 2140.2
```{r}
anova(wcn.cross.base.india.follow, wcn.cross.model2.india.follow, test = 'LRT')
```

###Base v. Prod. gradient
```{r}
anova(wcn.cross.base.india.follow, wcn.cross.model.gain.india.follow, test = 'LRT')
```

##Large model
```{r}
#compare with prod. gradient
wcn.cross.model.india.follow.plus.gain <- glmer(Correct ~ prod.gradient + fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross.india.follow, family = "binomial", 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

anova(wcn.cross.model2.india.follow, wcn.cross.model.india.follow.plus.gain, test = 'LRT')

#summary of final model
summary(wcn.cross.model2.india.follow)
tab_model(wcn.cross.model2.india.follow, transform = NULL)
```

---

# SOM 1 and 2 can be found in primary analyses

---

# SOM 3: Replication of Cheung et a. 
## Cheung-style analysis
```{r}
#Classify children based on counting quartile within language 
us.cheung <- all.data %>%
  filter(Language == "English (US)")%>%
  mutate(counting.classification = ifelse(IHC < 20, "Low", 
                                          ifelse((IHC >= 20 & IHC < 40), "Medium", 
                                                 ifelse((IHC >= 40 & IHC < 80), "High", "Very High"))),
         counting.classification = factor(counting.classification, 
                                          levels = c("Low", "Medium", "High", "Very High"), 
                                          labels = c("Low Counters (IHC < 20)", 
                                                     "Medium Counters (20 \u2264 IHC < 40)", 
                                                     "High Counters (40 \u2264 IHC < 80)", 
                                                     "Very High Counters (IHC \u2265 80)")),
         number.magnitude = ifelse((Task_item == "5" | Task_item == "7"), "Small", 
                                   ifelse(Task_item == "16", "Medium", 
                                          ifelse(Task_item == "24", "Large", 
                                                 ifelse((Task_item == "52" | Task_item == "71"), 
                                                        "Very Large", "Extremely Large")))), 
         number.magnitude = factor(number.magnitude, levels = c("Small", "Medium", "Large", "Very Large", 
                                                                "Extremely Large"), 
                                   labels = c("Small (5, 7)", "Medium (16)", "Large (24)",
                                              "Very Large (52, 71)", "Extremely Large (>100)")))

#cheung style accuracy
us.cheung %>%
  group_by(counting.classification, number.magnitude)%>%
  langcog::multi_boot_standard("Correct", na.rm = TRUE)%>%
  ggplot(aes(x = number.magnitude, y= mean, color = counting.classification, group = counting.classification)) + 
  geom_point(size = 2) + 
  geom_line() +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  scale_color_brewer(palette = "Set1") +
  labs(y = "Mean Unit Task Performance", x = "Number Range", 
       color = "Counting Classification") +
  theme_bw(base_size = 13) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid = element_blank(), 
        legend.title = element_text(size = 10), 
        legend.text = element_text(size = 9)) +
  scale_y_continuous(breaks = seq(0, 1, .25))

ggsave("Figures/cheung_graph.png")

##model with cheung analysis 
cheung.model <- us.cheung %>%
  filter(Task == "SF")

main.effects.cheung <- lmer(Correct ~ counting.classification + number.magnitude + Age + (1|SID), 
                            data = cheung.model)

summary(main.effects.cheung)
  ##overall descriptives by counting classification
cheung.model %>%
  group_by(counting.classification)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

```

---
# SOM 4: Analyses of <100 and >100 items
## Unit Task
Unit task first
```{r}
##first create a variable for whether items are above or below 100
#cantonese
sf.hk.within %<>%
  mutate(above.100 = ifelse(Task_item <100, "<100", ">100"))

#slovenian
sf.slo.within %<>%
  mutate(above.100 = ifelse(Task_item <100, "<100", ">100"))

#us english
sf.us.within %<>%
  mutate(above.100 = ifelse(Task_item <100, "<100", ">100"))

#hindi
sf.hindi.within %<>%
  mutate(above.100 = ifelse(as.numeric(as.character(Task_item)) <100, "<100", ">100"))

#gujarati
sf.gujarati.within %<>%
  mutate(above.100 = ifelse(as.numeric(as.character(Task_item)) <100, "<100", ">100"))

##now run a model within langauge
##We're testing whether items below or above 100 take a hit; in all languages, 100 marks the introduction of new syntax and words

##Getting rid of starting num - this is going to overlap with >100, so it's likely going to give us some weird results

##cantonese
#does above 100 explain additional variance
hk.sf.100.base <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                   family = 'binomial', data = sf.hk.within)

hk.sf.100.full <- glmer(Correct ~ above.100 + ihc.c + count_range+ age.c + (1|SID),
                        family = 'binomial', data = sf.hk.within)
anova(hk.sf.100.base, hk.sf.100.full, test = 'LRT')
summary(hk.sf.100.full) ##no difference for items above 100

#Slovenian
#does above 100 explain additional variance
slo.sf.100.base <- glmer(Correct ~ fhc.c + highest_contig.c + count_range  + age.c + (1|SID), 
                   family = 'binomial', data = sf.slo.within)

slo.sf.100.full <- glmer(Correct ~ above.100 + fhc.c + highest_contig.c + count_range + age.c + (1|SID),
                        family = 'binomial', data = sf.slo.within)
anova(slo.sf.100.base, slo.sf.100.full, test = 'LRT')#ns
summary(slo.sf.100.full)

#us
#does above 100 explain additional variance
us.sf.100.base <- glmer(Correct ~ ihc.c + highest_contig.c + count_range+ age.c + (1|SID), 
                   family = 'binomial', data = sf.us.within)

us.sf.100.full <- glmer(Correct ~ above.100 +  ihc.c + highest_contig.c +count_range+ age.c + (1|SID),
                        family = 'binomial', data = sf.us.within)
anova(us.sf.100.base, us.sf.100.full, test = 'LRT')
summary(us.sf.100.full)

#hindi
#does above 100 explain additional variance
hindi.sf.100.base <- glmer(Correct ~ ihc.c + highest_contig.c + count_range+ age.c + (1|SID), 
                   family = 'binomial', data = sf.hindi.within)

hindi.sf.100.full <- glmer(Correct ~ above.100 +  ihc.c + highest_contig.c +count_range+ age.c + (1|SID),
                        family = 'binomial', data = sf.hindi.within)
anova(hindi.sf.100.base, hindi.sf.100.full, test = 'LRT')
summary(hindi.sf.100.full)

#gujarati
#does above 100 explain additional variance
gujarati.sf.100.base <- glmer(Correct ~ count_range+ age.c + (1|SID), 
                   family = 'binomial', data = sf.gujarati.within)

gujarati.sf.100.full <- glmer(Correct ~ above.100 +count_range+ age.c + (1|SID),
                        family = 'binomial', data = sf.gujarati.within)
anova(gujarati.sf.100.base, gujarati.sf.100.full, test = 'LRT')
summary(gujarati.sf.100.full)
```

## Next Number
Now Next Number
```{r}
##first create a variable for whether items are above or below 100
#cantonese
wcn.hk.within %<>%
  mutate(above.100 = ifelse(Task_item <100, "<100", ">100"))

#slovenian
wcn.slo.within %<>%
  mutate(above.100 = ifelse(Task_item <100, "<100", ">100"))

#us english
wcn.us.within %<>%
  mutate(above.100 = ifelse(Task_item <100, "<100", ">100"))

#hindi
wcn.hindi.within %<>%
  mutate(above.100 = ifelse(as.numeric(as.character(Task_item)) <100, "<100", ">100"))

#gujarati
wcn.gujarati.within %<>%
  mutate(above.100 = ifelse(as.numeric(as.character(Task_item)) <100, "<100", ">100"))

##now run a model within langauge
##We're testing whether items below or above 100 take a hit; in all languages, 100 marks the introduction of new syntax and words

##Getting rid of starting num - this is going to overlap with >100, so it's likely going to give us some weird results

##cantonese
#does above 100 explain additional variance
hk.wcn.100.base <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                   family = 'binomial', data = wcn.hk.within)

hk.wcn.100.full <- glmer(Correct ~ above.100 + ihc.c + count_range+ age.c + (1|SID),
                        family = 'binomial', data = wcn.hk.within)
anova(hk.wcn.100.base, hk.wcn.100.full, test = 'LRT')
summary(hk.wcn.100.full) ##no difference for items above 100

#Slovenian
#does above 100 explain additional variances
slo.wcn.100.base <- glmer(Correct ~ fhc.c + count_range  + age.c + (1|SID), 
                   family = 'binomial', data = wcn.slo.within)

slo.wcn.100.full <- glmer(Correct ~ above.100 + fhc.c + count_range + age.c + (1|SID),
                        family = 'binomial', data = wcn.slo.within)
anova(slo.wcn.100.base, slo.wcn.100.full, test = 'LRT') #yes
summary(slo.wcn.100.full)

#us
#does above 100 explain additional variance
us.wcn.100.base <- glmer(Correct ~ ihc.c + highest_contig.c + count_range+ age.c + (1|SID), 
                   family = 'binomial', data = wcn.us.within)

us.wcn.100.full <- glmer(Correct ~ above.100 +  ihc.c + highest_contig.c +count_range+ age.c + (1|SID),
                        family = 'binomial', data = wcn.us.within)
anova(us.wcn.100.base, us.wcn.100.full, test = 'LRT')
summary(us.wcn.100.full)

#hindi
#does above 100 explain additional variance
hindi.wcn.100.base <- glmer(Correct ~ ihc.c + count_range+ age.c + (1|SID), 
                   family = 'binomial', data = wcn.hindi.within)

hindi.wcn.100.full <- glmer(Correct ~ above.100 +  ihc.c  +count_range+ age.c + (1|SID),
                        family = 'binomial', data = wcn.hindi.within)
anova(hindi.wcn.100.base, hindi.wcn.100.full, test = 'LRT')
summary(hindi.wcn.100.full)

#gujarati
#does above 100 explain additional variance
gujarati.wcn.100.base <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), 
                   family = 'binomial', data = wcn.gujarati.within)

gujarati.wcn.100.full <- glmer(Correct ~ above.100 +fhc.c + count_range+ age.c + (1|SID),
                        family = 'binomial', data = wcn.gujarati.within)
anova(gujarati.wcn.100.base, gujarati.wcn.100.full, test = 'LRT')
summary(gujarati.wcn.100.full)
```

---

# SOM 6: Highest Contiguous Next Number
## HCNN by each language
```{r}
#how many children have 0s
all.data %>%
  distinct(SID, highest_contig, Language)%>%
  filter(highest_contig == 0)%>%
  group_by(Language)%>%
  summarise(n = n())%>%
  mutate(total = sum(n))

#how many children have 271s
all.data %>%
  distinct(SID, highest_contig, Language)%>%
  filter(highest_contig == 271)%>%
  group_by(Language)%>%
  summarise(n = n())%>%
  mutate(total = sum(n))

#all together
all.data %>%
  distinct(SID, highest_contig, Language)%>%
  group_by(Language)%>%
  summarise(mean_hcnn = round(mean(highest_contig, na.rm = TRUE)),
            sd_hcnn = round(sd(highest_contig, na.rm = TRUE), 2), 
            median_hcnn = median(highest_contig, na.rm = TRUE))

#by productivity
all.data %>%
  filter(!is.na(highest_contig))%>%
  mutate(Productive = factor(Productive, levels = c("Resilient", "Non-Resilient")))%>%
  distinct(SID, highest_contig, Language, Productive)%>% 
  group_by(Language, Productive)%>%
  summarise(mean_hcnn = round(mean(highest_contig, na.rm = TRUE)),
            sd_hcnn = round(sd(highest_contig, na.rm = TRUE), 2), 
            median_hcnn = median(highest_contig, na.rm = TRUE))
```

## Do Resilient counters have higher HCNNs?
### HK: Significant difference between groups (*p* = .004)
```{r}
sf.hk.mean.nn <- all.data %>%
  filter(Language == "Cantonese")%>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig, na.rm = TRUE))

t.test(subset(sf.hk.mean.nn, Productive == "Resilient")$mean_nn, 
       subset(sf.hk.mean.nn, Productive == "Non-Resilient")$mean_nn, var.equal = TRUE)
```

### SLO - sig, *p* < .0001
```{r}
sf.slo.mean.nn <- all.data %>%
  filter(Language == "Slovenian")%>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig, na.rm = TRUE))

t.test(subset(sf.slo.mean.nn, Productive == "Resilient")$mean_nn, 
       subset(sf.slo.mean.nn, Productive == "Non-Resilient")$mean_nn, var.equal = TRUE)
```


### US - sig, p < .0001
```{r}
sf.us.mean.nn <- all.data %>%
  filter(Language == "English (US)")%>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig, na.rm = TRUE))

t.test(subset(sf.us.mean.nn, Productive == "Resilient")$mean_nn, 
       subset(sf.us.mean.nn, Productive == "Non-Resilient")$mean_nn, var.equal = TRUE)
```

### India-Eng, *p* = .02
```{r}
sf.ind.eng.mean.nn <- all.data %>%
  filter(Language == "English (India)")%>%
  distinct(SID, Productive, highest_contig)%>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig, na.rm = TRUE))

t.test(subset(sf.ind.eng.mean.nn, Productive == "Resilient")$mean_nn, 
       subset(sf.ind.eng.mean.nn, Productive == "Non-Resilient")$mean_nn, var.equal = TRUE)
```

### Hindi - *p* = .03
```{r}
sf.hindi.mean.nn <- all.data %>%
  filter(Language == "Hindi")%>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig, na.rm = TRUE))

t.test(subset(sf.hindi.mean.nn, Productive == "Resilient")$mean_nn, 
       subset(sf.hindi.mean.nn, Productive == "Non-Resilient")$mean_nn, var.equal = TRUE)
```


### Gujarati - *p* < .0001
```{r}
sf.gujarati.mean.nn <- all.data %>%
  filter(Language == "Gujarati")%>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig, na.rm = TRUE))

t.test(subset(sf.gujarati.mean.nn, Productive == "Resilient")$mean_nn, 
       subset(sf.gujarati.mean.nn, Productive == "Non-Resilient")$mean_nn, var.equal = TRUE)
```

## Do transparent languages allow nonproductive counters to generate higher HCNNs?
No significant difference in HCNN for nonproductive counters for Cantonese in comparison to English or Slovenian. US English nonproductive counters have significantly higher HCNNs than Hindi or Gujarati. This difference holds for Indian English speakers.
```{r}
#lm predicting hcnn from language for nonproductive counters
hcnn.hk <- all.data %>%
  filter(Language == "English (US)" |
           Language == "Cantonese" |
           Language == "Slovenian")%>%
  droplevels()%>%
  distinct(SID, highest_contig, Language, Age, sum_wppsi, Productive)%>%
  filter(!is.na(highest_contig), 
         Productive == "Non-Resilient")%>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))

hcnn.nonprod.hk <- lm(highest_contig ~ Language + Age + wppsi.c, data = hcnn.hk)
summary(hcnn.nonprod.hk)

#now with slo as reference
hcnn.hk <- all.data %>%
  filter(Language == "English (US)" |
           Language == "Cantonese" |
           Language == "Slovenian")%>%
  mutate(Language = factor(Language, levels = c("Slovenian", "English (US)", "Cantonese")))%>%
  distinct(SID, highest_contig, Language, Age, sum_wppsi, Productive)%>%
  filter(!is.na(highest_contig), 
         Productive == "Non-Resilient")%>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))

hcnn.nonprod.hk <- lm(highest_contig ~ Language + Age + wppsi.c, data = hcnn.hk)
summary(hcnn.nonprod.hk)

#india - US English
hcnn.ind <- all.data %>%
  filter(Language == "English (US)" |
           Language == "Hindi" |
           Language == "Gujarati")%>%
  distinct(SID, highest_contig, Language, Age, sum_wppsi, Productive)%>%
  filter(!is.na(highest_contig), 
         Productive == "Non-Resilient")%>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))

hcnn.nonprod.india.us <- lm(highest_contig ~ Language + Age + wppsi.c, data = hcnn.ind)
summary(hcnn.nonprod.india.us)

#india - Indian English
hcnn.ind <- all.data %>%
  filter(Language == "English (India)" |
           Language == "Hindi" |
           Language == "Gujarati")%>%
  distinct(SID, highest_contig, Language, Age, sum_wppsi, Productive)%>%
  filter(!is.na(highest_contig), 
         Productive == "Non-Resilient")%>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))

hcnn.nonprod.india <- lm(highest_contig ~ Language + Age + wppsi.c, data = hcnn.ind)
summary(hcnn.nonprod.india)
```

---

# SOM 7: Initial Highest Count 
Fit GMM for each language
#### Cantonese
```{r}
#Cantonese
cant.df <- initial_final %>%
  filter(Language == "Cantonese")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(cant.df)

mod.cant <- Mclust(cant.df, x = BIC)
summary(mod.cant, parameters = TRUE)

```

#### Slovenian
```{r}
#Slovenian
slo.df <- initial_final %>%
  filter(Language == "Slovenian")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(slo.df)

mod.slo <- Mclust(slo.df, x = BIC)
summary(mod.slo, parameters = TRUE)

```

#### US English
```{r}
#English
us.df <- initial_final %>%
  filter(Language == "English (US)")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(us.df)

mod.us <- Mclust(us.df, x = BIC)
summary(mod.us, parameters = TRUE)

```

#### Hindi
```{r}
#Hindi
hindi.df <- initial_final %>%
  filter(Language == "Hindi")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(hindi.df)

mod.hindi <- Mclust(hindi.df, x = BIC)
summary(mod.hindi, parameters = TRUE)

```

#### Gujarati
```{r}
#Gujarati
gujarati.df <- initial_final %>%
  filter(Language == "Gujarati")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(gujarati.df)

mod.gujarati <- Mclust(gujarati.df, x = BIC)
summary(mod.gujarati, parameters = TRUE)

```

#### Indian English
```{r}
#Indian English
ind.eng.df <- initial_final %>%
  filter(Language == "English (India)")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(ind.eng.df)

mod.ind.eng <- Mclust(ind.eng.df, x = BIC)
summary(mod.ind.eng, parameters = TRUE)

```

### IHC cluster visualization 
```{r}
initial_final %>%
  mutate(Experiment = ifelse((Language == "Hindi" | Language == "Gujarati" | Language == "English (India)"), "Experiment 2", "Experiment 1"))%>%
  dplyr::select(IHC, Experiment, Language)%>%
  mutate(Language = factor(Language, levels = c("Cantonese", "Slovenian", "English (US)", "Hindi", "Gujarati", "English (India)")))%>%
  ggplot(aes(x = IHC, colour= Language)) + geom_density(adjust = .5, size = 1.5) +
  scale_x_continuous(breaks = seq(0, 140, 10)) +
  theme_bw(base_size = 13) +
  theme(legend.position = "right",
        panel.grid.minor = element_blank(), 
        legend.title = element_blank()) +
  scale_colour_brewer(palette = "Dark2") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        legend.position = "bottom") +
  labs(x = "Initial Highest Count", y = "Density") + 
  facet_grid(~Experiment)
ggsave("Figures/ihc_density_language.png", height = 5)
```

## What proportion of kids in highest proportion cluster (from GMM) are labeled as resilient in each language?
First, set up GMM
```{r}
library(mclust)

#make a function to identify cluster membership for Initial Highest Count

prod.clust <- function(df) {
  languages <- c("English (US)", "English (India)", "Hindi", "Gujarati", "Slovenian", "Cantonese")
  
  all.clust <- data.frame()
  for (lang in languages) {
    #filter down to correct language
    tmp.df <- df %>%
      filter(Language == lang)%>%
      distinct(SID, IHC)%>%
      dplyr::select(-SID)
    
    #run cluster analysis
    BIC <- mclustBIC(tmp.df)
    tmp.mclust <- Mclust(tmp.df, x = BIC)
    tmp.df$CLUST <- tmp.mclust$classification
    tmp.df$id <- row.names(tmp.df)
    
    #add SIDs back in
    tmp.sids <- df %>%
      filter(Language == lang)%>%
      distinct(SID, IHC)
    
    tmp.sids$id <- row.names(tmp.sids)
    
    tmp.all <- right_join(tmp.sids, tmp.df, by = "id")
    tmp.all$Language <- lang
    
    #add to large df to get back at end
    all.clust <- bind_rows(all.clust, tmp.all)
  }
  return(all.clust)
}

clusters <- prod.clust(all.data)%>%
  dplyr::select(SID, IHC.x, CLUST, Language)%>%
  dplyr::rename(IHC = IHC.x)

#add clusters to all.data
all.data <- full_join(all.data, clusters, by = "SID")

check <- all.data %>%
  filter(IHC.x != IHC.y) # all good

all.data %<>%
  dplyr::select(-IHC.y, -Language.y)%>%
  dplyr::rename(IHC = IHC.x,
                Language = Language.x)

```

### What percentage of each mode turned out to be productive?
```{r}
##Pull out only these clusters 
all.data %>%
  distinct(SID, Language, Productive, CLUST)%>%
  group_by(Language, CLUST, Productive)%>%
  summarise(n = n())%>%
  group_by(Language, CLUST)%>%
  mutate(total.n = sum(n), 
         prop = n/total.n)%>%
  filter(Productive == "Resilient")%>%
  kable()
```

## Do Non-Resilient counters have lower IHCs in languages with more transparent count lists?
```{r}
ihc.cross <- all.data %>%
   filter(!is.na(Productive))%>%
  distinct(SID, Language, Age, sum_wppsi, Productive, IHC, Dataset)%>%
  filter(Productive == "Non-Resilient")%>%
  mutate(Language = factor(Language))%>%
  mutate(age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale = TRUE)))
##Experiment 1
ihc.cross.hk.slo <- ihc.cross %>%
  filter(Language == "Cantonese" | 
           Language == "Slovenian" | 
           Language == "English (US)")

ihc.cross.model.hk.slo <- lm(IHC ~ Language + age.c + wppsi.c, data = ihc.cross.hk.slo)
summary(ihc.cross.model.hk.slo)

#Experiment 2
ihc.cross.ind <- ihc.cross %>%
  filter(Language == "English (US)"|
           Language == "Hindi" |
           Language == "Gujarati")

ihc.cross.model.ind <- lm(IHC ~ Language + age.c + wppsi.c, data = ihc.cross.ind)
summary(ihc.cross.model.ind)

#Experiment 2a.
ihc.cross.ind <- ihc.cross %>%
  filter(Language == "English (India)"|
           Language == "Hindi" |
           Language == "Gujarati")

ihc.cross.model.ind <- lm(IHC ~ Language + age.c + wppsi.c, data = ihc.cross.ind)
summary(ihc.cross.model.ind)
```

---

#SOM 8: Types/Frequencies of counting errors
## Mean number of prompts by Language, productivity
SOM, descriptive analysis of number of errors by Resilience
```{r}
error.freq %>%
  mutate(Productive = factor(Productive, levels = c("Resilient", "Non-Resilient")))%>%
  group_by(Productive, Language, Error_type)%>%
  summarise(n = n())%>%
  group_by(Language, Productive)%>%
  mutate(total.n = sum(n), 
            prop = n/total.n)
```

### Where are errors happening?
Visualization of units
```{r}
error.freq.decade <- error.freq %>%
  filter(Last_successful != 140)%>%
  mutate(error.decade = ifelse(Last_successful < 10, 0, 
                               ifelse(Last_successful >= 10 & Last_successful < 20, 10, 
                                      ifelse(Last_successful >= 20 & Last_successful < 30, 20, 
                                             ifelse(Last_successful >= 30 & Last_successful < 40, 30, 
                                                    ifelse(Last_successful >=40 & Last_successful < 50, 40, 
                                                           ifelse(Last_successful >= 50 & Last_successful < 60, 50, 
                                                                  ifelse(Last_successful >= 60 & Last_successful < 70, 60, 
                                                                         ifelse(Last_successful >= 70 & Last_successful < 80, 70, 
                                                                                ifelse(Last_successful >= 80 & Last_successful < 90, 80, 
                                                                                       ifelse(Last_successful >= 90 & Last_successful < 100, 90, 
                                                                                              ifelse(Last_successful >= 100 & Last_successful < 110, 100, 
                                                                                                     ifelse(Last_successful >= 110 & Last_successful < 120, 110, 
                                                                                                            ifelse(Last_successful >= 120 & Last_successful < 130, 120,130)))))))))))))) %>%
  mutate(error.base = (error.decade - Last_successful) * -1, 
         error.base = ifelse(Last_successful == 140, 0, as.numeric(error.base)))



###Error by unit
##all
error.freq.decade %>%
  filter(Last_successful <= 140)%>% #filter out trials where kid kept going beyond 140
  mutate(Language = factor(Language, levels = c("Hindi", "Gujarati","English (India)", "English (US)", "Slovenian", "Cantonese")), 
         Productive = factor(Productive, levels = c("Resilient", "Non-Resilient"))) %>%
  mutate(error.base = factor(error.base))%>%
  mutate(Lang.prod = paste0(as.character(Language), " ", as.character(Productive), collapse = NULL))%>%
  group_by(Language, Productive, error.base)%>%
  summarise(n = n())%>% 
  group_by(Language, Productive)%>%
  mutate(total.n = sum(n), 
         prop = n/total.n)%>%
  mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
  ggplot(aes(x = error.base, y = Language)) +
  geom_tile(aes(fill = round(prop, 2))) +
  geom_text(aes(label = as.character(round(prop, 2))), 
            size = 2.5) +
  coord_equal() +
  scale_fill_gradient2(low = "white", high = "red", "Proportion") + 
  theme_bw(base_size = 13) + 
  labs(x = "Unit of error") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "right", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        legend.title = element_text(size = 11)) +
  facet_grid(rows = vars(Productive))
ggsave("Figures/errors.png")

###Error by unit
##overall, not split by resilience
error.freq %>%
  filter(Last_successful <= 140)%>% #filter out trials where kid kept going beyond 140
  mutate(Language = factor(Language, levels = c("Hindi", "Gujarati","English (India)", "English (US)", "Slovenian", "Cantonese")), 
         Exp = ifelse((Language == "Cantonese" | Language == "Slovenian" | Language == "English (US)"), 1, 2))%>%
  group_by(Language, Exp, Error_type)%>%
  summarise(n = n())%>% 
  group_by(Language)%>%
  mutate(total.n = sum(n), 
         prop = n/total.n)%>%
  mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
  ggplot(aes(x = Language, y = prop, fill = Error_type)) +
  geom_bar(stat = 'identity') +
  theme_bw(base_size = 13)  +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "right",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.title = element_text(size = 11)) + 
    facet_grid(~Exp, scale = "free_x")
```

---

# Responses

## Testing for differences in IHC between US and Indian English
```{r}
english.counts <- all.data %>%
  filter(Language == "English (US)" | 
           Language == "English (India)")%>%
  distinct(SID, Language, Productive, IHC)

#overall
t.test(subset(english.counts, Language == "English (US)")$IHC, 
       subset(english.counts, Language == "English (India)")$IHC, var.equal = TRUE)

#Resilient
t.test(subset(english.counts, Language == "English (US)" & Productive == "Resilient")$IHC, 
       subset(english.counts, Language == "English (India)" & Productive == "Resilient")$IHC, var.equal = TRUE)

#Non-resilient
t.test(subset(english.counts, Language == "English (US)" & Productive == "Non-Resilient")$IHC, 
       subset(english.counts, Language == "English (India)" & Productive == "Non-Resilient")$IHC, var.equal = TRUE)
```

## What is the relationship between age, productivity, and highest counts? 
```{r}
#by language
ms.cor <- all.data %>%
  distinct(SID, Language, IHC, FHC, Productive, Age)%>%
  mutate(Productive.num = ifelse(Productive == "Resilient", 1, 0))

#overall 
model.prod <- glm(Productive.num ~ Age, data = subset(ms.cor, Language == "Gujarati"), 
                  family = "binomial")
summary(model.prod)

#interaction with language
model.prod.lang <- glm(Productive.num ~ Language*Age, data = ms.cor, 
                       family = "binomial")
summary(model.prod.lang)

#IHC by age
model.ihc <- lm(IHC ~ Age, data = ms.cor)
summary(model.ihc)
```

## Plotting where IHCs appear by language

```{r}
ihc.dist <- all.data %>%
  distinct(SID, Productive, Language, IHC, FHC)%>%
   mutate(IHC_stop = ifelse((Language == "Cantonese" | 
                                Language == "Slovenian" |
                                Language == "English (India)" |
                                Language == "English (US)") & IHC %% 10 == 9 , "Decade end", 
                             ifelse(IHC %% 10 == 0, "Decade beginning",
                                    ifelse(IHC %% 10 == 8 & (Language == "Hindi" | Language == "Gujarati"), "Hindi/Gujarati pre-decade transition", "Mid-decade"))))

#plot
ihc.dist %>%
    mutate(Language = factor(Language, levels = c("Hindi", "Gujarati","English (India)", "English (US)", "Slovenian", "Cantonese")), 
           Exp = ifelse((Language == "Cantonese" | Language == "Slovenian" | Language == "English (US)"), "Experiment 1", "Experiment 2"))%>%
    group_by(Language, Exp, IHC_stop)%>%
    summarise(n = n())%>% 
    group_by(Language)%>%
    mutate(total.n = sum(n), 
           prop = n/total.n)%>%
    mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
    ggplot(aes(x = Language, y = prop, fill = IHC_stop)) +
    geom_bar(stat = 'identity', position = position_dodge()) +
    theme_bw(base_size = 13)  +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position = "right",
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          legend.title = element_text(size = 11)) + 
      facet_grid(~Exp, scale = "free_x") + 
  labs(y = "Proportion of IHC")

ggsave("Figures/dist_IHC.png")
```




