---
title: "XCulture Analysis"
author: "Rose M. Schneider"
date: "8/5/2018"
output: html_document
---
TO-DO
- str of data, change silent to NA

#Setup
```{r setup, include=FALSE}
rm(list = ls())
require("knitr")
opts_knit$set(root.dir = "~/Documents/Projects/xculture/HK_SLO") #this is specific to RMS, change accordingly
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)

'%!in%' <- function(x,y)!('%in%'(x,y))
```

#Load data
##Slovenian
```{r}
#slo data
slo.full.data <- read.csv('Data/SLO_data.csv')%>%
  mutate(Exclude_task = ifelse(is.na(Exclude_task), 0, as.numeric(as.character(Exclude_task))))%>%
  mutate(Trial_number = ifelse(Trial_number == '0', "Training", as.character(Trial_number)), 
         Task_item = factor(Task_item))%>%
  mutate(Response = ifelse(Task == "WPPSI", as.character(Correct), as.character(Response)))%>%
  filter(SID != "CopyPasteMe")%>%
  mutate(Age = as.numeric(as.character(Age)), 
         Correct = as.numeric(as.character(Correct)))

#slo highest count
slo.hc <- read.csv('Data/SLO_HC.csv')
```

##Cantonese
```{r}
#hk data
hk.full.data <- read.csv('Data/HK_data.csv')%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  mutate(Age = as.numeric(as.character(Age)), 
         Correct = as.integer(as.character(Correct)), 
         Mem_check_1 = as.integer(as.character(Mem_check_1)), 
         Mem_check_2 = as.integer(as.character(Mem_check_2)))%>%
  mutate(Response = ifelse(Task == "WPPSI", as.character(Correct), as.character(Response)))

#hk highest count
hk.hc <- read.csv('Data/HK_HC.csv')
```

##Bind together
```{r, warning = FALSE}
#regular data
all.data <- bind_rows(slo.full.data, hk.full.data)%>%
  mutate(Age = round(Age, 2), 
         Agegroup = cut(Age, breaks = c(3.5, 4, 4.5, 5, 5.5, 6, 6.6), 
                        labels = c("3.5-4", "4-4.5", "4.5-5", 
                                   "5-5.5", "5.5-6", "6-6.5")))%>%
  select(-X)
##highest count
slo.hc %<>%
  filter(Exclude != 1)%>%
  mutate(IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))

hk.hc %<>%
  filter(Exclude != 1)%>%
  mutate(IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))

#bind hk and slo hc data
slo.hc %<>%
  mutate(Language = "Slovenian")%>%
  dplyr::rename(Last_successful = Last_Successful)%>%
  mutate(Last_successful = as.integer(as.character(Last_successful)))

hk.hc %<>%
  mutate(Language = "Cantonese")

hc.df <- bind_rows(slo.hc, hk.hc)
```

---

#Classifications
##CP or subset-knower
Children are classified as subset-knowers if they got all 4 numbers requested correct (on either the first or the second try).
```{r}
cp.df <- all.data %>%
  filter(Task == "GiveN")%>%
  group_by(SID)%>%
  summarise(sum_correct = sum(Correct, na.rm = TRUE))%>%
  mutate(Knower.level = ifelse(sum_correct >= 4, "CP-knower", "Subset-knower"))%>%
  select(-sum_correct)

all.data <- full_join(all.data, cp.df, by = "SID")

all.data %>%
  distinct(SID, Language, Knower.level)%>%
  group_by(Language, Knower.level)%>%
  summarise(n=n())%>%
  kable()
```

##WPPSI score
WPPSI score is just the total correct items by participant, excluding feedback/training trials
```{r}
 #get sum per SID, add to sf and wcn for CROSS-LINGUISTIC models
 wppsi.sid <- all.data %>%
  filter(Task == "WPPSI")%>%
  mutate(Trial_number = factor(Trial_number))%>%
  filter(Trial_number != "sample item A", 
         Trial_number != "sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != '1', 
         Trial_number != '2', 
         Trial_number != '7', 
        Trial_number != '8')%>%
   group_by(SID)%>%
   summarise(sum_wppsi = sum(Correct, na.rm = TRUE))

all.data <- full_join(all.data, wppsi.sid, by = "SID")
```


##Productivity
Children are classified as productive if they are able to count at least 2 decades higher than an error without making more than 3 errors along the way, OR if they are able to count to 140 without making an error.
```{r, warning = FALSE}
hc.df %<>%
  mutate(Last_successful = ifelse(Last_successful == "Is quiet", "IDK", Last_successful))%>%
  filter(Exclude != 1)

hc <- hc.df %>% # replace with your local path
  select(SID, Last_successful, IHC, FHC) %>%
  mutate_at(c('Last_successful','IHC','FHC'),
            function(col) as.integer(str_replace_all(col,'\\D',''))) %>% # some of these included '?', so i remove any char thats not a digit
  mutate(Last_successful = ifelse(is.na(Last_successful), 140, Last_successful))%>%
  filter(!is.na(IHC))

# 
# function for determining productivity
is.productive = function(subject){
  # takes as input the data for a single subject
  # RULES:
  # - counts to 120 unaided = productive
  # - after making first error, counts >= 20 higher, with no more than 3 errors on way
  if(subject$IHC[1] >= 140){
    # if they get to 120 on first try, = productive
    return(TRUE)
  } else if(subject$FHC[1] == 140 & nrow(subject) < 4) {
    return(TRUE)
  } else if(subject$FHC[1] < 140 & nrow(subject) == 1 
            & subject$FHC[1] == subject$IHC[1]) {
    return(FALSE)
  } else if((subject$FHC[1] - subject$IHC[1]) >= 20){
    # if their final is >= 20 larger than their intial...
    if(nrow(subject) < 4){
      # and they've made 3 or fewer total errors, = productive
      return(TRUE)
    } 
    else {
      for(i in 1:nrow(subject)){ # start at row 2
        # check if they ever made it >= 20 counts & <= 3 errors after an error
        runLength = 0 # they just made an error, so no post-error successes yet
        numErrors = 0 # first row was an error if it's not finalCount == 120
        prev = subject$Last_successful[i]
        for (j in i+1:nrow(subject)){ # from current row until end...
          numErrors = numErrors + 1 # new row means new error
          runLength = runLength + (subject$Last_successful[j] - prev)
          # ^ add difference between current count and last count to run length
          prev = subject$Last_successful[j] # update last count
          if(runLength >= 20 & numErrors < 4){
            # if at any point the productivity conditions are met...
            return(TRUE) # = productive
          }
        }
      }
      # productivity conditions were never met (because we got to this point) so...
      return(FALSE) # != productive
    }
  } else {
    # highest is not >= 20 greater than initial
    return(FALSE)
  }
}
# 
#make function to run for all participants
unique_SIDs <- as.vector(unique(hc.df$SID))
# 
class_prod <- function(vector) {
  temp_data <- data.frame()
  for (i in vector) {
    prod.class <- data.frame(i, is.productive(subset(hc, SID == i)))
    
    names(prod.class) <- c("SID", "productive")
    temp_data <- bind_rows(temp_data, prod.class)
  }
  return(temp_data)
}
# 

productive <- class_prod(unique_SIDs)%>%
  rename(check_prod = productive)%>%
  mutate(check_prod = ifelse(check_prod == TRUE, "Productive", "Nonproductive"))

hc %<>%
  select(-Last_successful)

productive <- full_join(productive, hc, by = "SID")%>%
  distinct(SID, IHC, FHC, check_prod)%>%
  dplyr::rename(Productive = check_prod)

all.data <- full_join(all.data, productive, by = "SID")
```

##Highest Contiguous NN
Highest Contiguous NN is a measure of productivity. This is the highest number for which a child was correct on the Next Number task, provided that all the previous numbers had also been correct.
```{r, warning = FALSE}
failed.nn <- all.data %>%
  filter(Task == "NN", 
         Correct == 0, 
         Trial_number == "Training")

failed.nn.sids <- unique(as.vector(failed.nn$SID))

#get unique ids
unique.nn <- all.data %>%
  filter(Task == "NN")%>%
  distinct(SID)

unique.nn <- as.vector(unique.nn$SID)
nextnums <- as.vector(c(5, 7, 16, 24, 52, 71, 105, 107, 116, 224, 252, 271))

#this is a function that pulls out the largest number for which a participant had a correct consecutive
get_contiguous <- function(){
  contig <- data.frame()
  for (sub in unique.nn) {
    tmp <- all.data %>%
      mutate(Task_item= as.integer(Task_item))%>%
      filter(Task == "NN",
             SID == sub, 
             Correct == 0)%>%
      mutate(Task_item = sort(as.integer(Task_item)))
    if (length(tmp$SID) == 0) {
      highest_contig = 271
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else if (sub %in% failed.nn.sids) {
      highest_contig = 0
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else if (length(tmp$Task_item) > 0 & min(tmp$Task_item) == 5) {
      highest_contig = 1
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else {
      min.nn <- min(tmp$Task_item)
      prev_correct <- nextnums[nextnums < min.nn]
      highest_contig <- max(prev_correct)
    
      sub_contig <- data.frame(sub,
                             highest_contig)
      contig <- bind_rows(contig, sub_contig)
    }
  }
  return(contig)
}

highest_contiguous_nn <- get_contiguous()%>%
  dplyr::rename(SID = sub)

#add this to df 
all.data <- full_join(all.data, highest_contiguous_nn, by = "SID")

```

##Within/outside count range
Each trial on the Unit or WCN task was determined to be either within or outside a child's unprompted count range (IHC).
```{r}
all.data %<>%
  mutate(count_range = ifelse((Task == "SF" | Task == "NN") & as.numeric(Task_item) <= IHC, "Within", 
                              ifelse((Task == "SF" | Task == "NN") & as.numeric(Task_item) > IHC, "Outside", 
                                     NA)))
```

---
#Exclusions
##Global exclusions
Children were excluded from the analysis only if a) they did not complete the highest count task, or b) their exclusion was noted by the experimenter. Note that there are currently participants excluded from the Slovenian dataset due to not having enough data from the WPPSI. These children may be added back in, but we're currently in a position to replace them. 
```{r}
all.data %>%
  filter(Exclude_analysis == 1)%>%
  distinct(SID, Exclude_analysis, Exclude_analysis_reason, Language)

#exclude
all.data %<>%
  filter(Exclude_analysis != 1)

#Manual exclusions - these are participants who did not receive the correct number of trials in WPPSI. 
all.data %<>%
filter(SID != "11072018-L",
           SID != "12072018-I",
           SID != "19072018-J",
           SID != "19072018-M",
           SID != "19072018-P",
           SID != "Naj16",
           SID != "Sol07", 
         SID != "Naj14")


all.data %<>%
  filter(!is.na(Language))
```

###Task exclusions
Children were excluded from a given task if they did some complete at least TWO trials of that task (in addition to the training trial). In order to be considered as having completed a trial of the task, a child must at least say "I don't know."  
```{r}
all.data %>%
  filter(Exclude_task == 1)%>%
  distinct(SID, Language, Exclude_task, Excluded_task, Exclude_task_reason)

#exclude
all.data %<>%
  filter(Exclude_task != 1)
```

##Excluded trials
Trials where a participant gave no response were excluded from analysis.
```{r}
all.data %>%
  filter(Exclude_trial == 1)%>%
  group_by(Task, Exclude_trial_reason)%>%
  summarise(n = n())

all.data %<>%
  filter(Exclude_trial != 1)

#how many trials do we have for each task?
all.data %>%
  filter(Task == "SF" | 
         Task == "NN")%>%
  group_by(Language, Task, Task_item)%>%
  summarise(n = n())
```

##Exclude practice trials for SF and NN
Practice trials are excluded from analysis. 
```{r}
#how many kids failed the practice trials on these tasks?
all.data %>%
  filter(Task == "SF" | Task == "NN")%>%
  filter(Task_item == 1, 
         Correct == 0)%>%
  group_by(Task)%>%
  summarise(n = n())

#exclude practice trials
all.data %<>%
  filter(Trial_number != "Training")
```

##Memory checks - NAs to 1
Some participants have NAs rather than 1 for their first memory check. 
```{r}
all.data %<>%
  mutate(Mem_check_1 = ifelse((Task == "SF" & is.na(Mem_check_1)), 1, Mem_check_1), 
         Mem_check_2 = ifelse((Task == "SF" & Mem_check_1 == 0 & is.na(Mem_check_2)), 1, NA))
```

---
#Demographics
```{r, warning = FALSE}
#demos by age group, Language
all.data %>%
  distinct(SID, Language, Agegroup, Age)%>%
  group_by(Language, Agegroup)%>%
  summarise(n = n(), 
            Mean_age = mean(Age, na.rm = TRUE), 
            SD_age = sd(Age, na.rm = TRUE))%>%
  kable()

#demos by Language
all.data %>%
  distinct(SID, Language, Age)%>%
  group_by(Language)%>%
  summarise(n = n(),
            Mean_age = mean(Age, na.rm = TRUE), 
            SD_age = sd(Age, na.rm = TRUE))%>%
  kable()
  
#histogram of age
all.data %>%
  distinct(SID, Language, Age)%>%
ggplot(aes(x = Age, fill = Language)) +
  geom_histogram(binwidth = .5, colour = "black") +
  theme_bw() + 
  facet_wrap(~Language) + 
  scale_x_continuous(breaks = c(3.5, 4, 4.5, 5, 5.5, 6, 6.5)) +
  scale_fill_brewer(palette = "Dark2") + 
  guides(fill = FALSE) +
  labs(y = "Count", title = "Number of children in age bin by language")
```

##Productivity by language
```{r}
all.data %>%
  distinct(SID, Language, Productive)%>%
  group_by(Language, Productive)%>%
  summarise(n = n())%>%
  kable()

all.data %<>% 
  filter(!is.na(Language))
```

###Productivity descriptives
```{r}
all.data %>%
  filter(!is.na(Language))%>%
  distinct(SID, Age, Productive, Language, IHC, FHC)%>%
  group_by(Language, Productive)%>%
  summarise(n = n(),
            mean_IHC = round(mean(IHC), 2), 
            sd_IHC = round(sd(IHC), 2), 
            median_IHC = round(median(IHC), 2), 
            mean_FHC = round(mean(FHC), 2), 
            sd_FHC = round(sd(FHC), 2), 
            median_FHC = round(median(FHC), 2))%>%
  kable()
```

---

#Task visualizations
##Highest count
###Histogram Initial and Final Highest Count
```{r}
unique.hc.data <- all.data %>%
  distinct(SID, IHC, FHC, Productive, Language)%>%
  gather(IHC_FHC,highest_count, IHC:FHC)%>%
  mutate(highest_count = as.integer(highest_count), 
         IHC_FHC = factor(IHC_FHC, levels = c("IHC", "FHC"), 
                          labels = c("Initial Highest Count", "Final Highest Count")))

#initial
ggplot(unique.hc.data, aes(x=highest_count, fill=Productive)) + 
  geom_histogram(binwidth = 10, colour = "black") +
  theme_bw(base_size = 10)+
  labs(title = "Initial/Final Highest Counts by Productivity and Dataset") +
  facet_grid(IHC_FHC~Language) +
  scale_x_continuous(breaks = seq(0, 140, 10))+
  scale_fill_brewer(palette = "Set1") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.minor = element_blank())

```

###Scatterplot of IHC and FHC
```{r}
initial_final <- all.data %>%
  filter(!is.na(Productive))%>%
  distinct(SID, Language, IHC, FHC, Productive)%>%
  mutate(IHC = as.numeric(IHC), 
         FHC = as.numeric(FHC))

ggplot(initial_final, aes(x = IHC, y = FHC, 
                          color = Productive)) +
  geom_point(size = 1) + geom_jitter(width = .1) +
  labs(x = "Initial highest count", y = "Final highest count", 
                      color = "", title = "") +
  theme_bw(base_size = 13) + 
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) + 
  theme(panel.grid.minor = element_blank(), 
        legend.position = "bottom", 
        legend.text = element_text(size = 8)) + 
  facet_grid(~Language) + 
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

###Plotting distance between Initial and Final Highest Counts (~Pierina's graph) for Productive counters
```{r}
ggplot(subset(unique.hc.data, Productive == "Productive"), aes(x = SID, y = highest_count)) + 
  facet_grid(rows = vars(Productive)) +
  geom_line() + 
  geom_point(aes(shape = IHC_FHC, colour = IHC_FHC), 
             size = 2, stroke = 1.5) +
  scale_color_brewer(palette="Paired", direction = 1) +
  scale_shape_manual(values = c(4,5,20)) +
  labs(title="Distance between initial and final highest counts",
       x = "Each line = individual kids",
       y="Highest Count by Count Type") +
  theme_bw(base_size = 7) + 
  theme(legend.position="bottom", 
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~Language, scales = "free_x")
```




---

##Unit Task
###How many kids failed the memory checks in each dataset by number

```{r}
#for SF
sf.df <- all.data %>%
  filter(Task == "SF")%>%
  mutate(mem_check_status = ifelse((Mem_check_1 == 1 & is.na(Mem_check_2)), "Needed_1_passed_1",
                                    ifelse((Mem_check_1 == 0 & Mem_check_2 == 0), "Needed_2_failed_2",
                                           ifelse((Mem_check_1 == 1 & Mem_check_2 == 1),
                                                  "unclear_pass1_pass2",
                                                  ifelse((Mem_check_1 == 1 & Mem_check_2 == 0),
                                                         "unclear_passed1_failed2",
                                                         ifelse((Mem_check_1 == 0 & Mem_check_2 == 1),
                                                                "failed1_passed2", "other"))))))

#by number
sf.mem.num.ms <- sf.df %>%
  mutate(Task_item = factor(Task_item, levels = c("5", '7', '16', '24', '52', '71', '105', '107', '116', '224', '252', '271')))%>%
  filter(!is.na(Productive))%>%
  group_by(Task_item, mem_check_status, Language, Productive)%>%
  summarise(n = n())

ggplot(subset(sf.mem.num.ms), aes(x = Task_item, y = n, fill = mem_check_status)) + 
  geom_bar(stat = "identity") + 
  facet_grid(Productive~Language) +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Number queried", y = "Number of trials", title = "Memory checks by number in Unit Task")
```

###Raw performance by Language
```{r}
all.data %>%
  filter(Task == "SF")%>%
  group_by(SID, Language)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "none") +
  ggtitle("Overall mean correct on Unit Task") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2")
```

###Performance by language, productivity
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "SF")%>%
  group_by(SID, Productive, Language)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  facet_grid(~Productive)+
  theme_bw() + 
  theme(legend.position = "none") +
  ggtitle("Performance on Unit Task by language, productivity") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2")
```

###By productivity and count range
```{r}
count_range_pal <- brewer.pal(n = 9, "Spectral")[8:9]

all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "SF")%>%
  group_by(SID, count_range, Language)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = count_range, y = mean, fill=Language)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  ggtitle("Performance on Unit Task by language, within/outside IHC") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2")
```

###Item performance by productivity, Unit Task
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "SF")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  group_by(Productive, Task_item, Language)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_wrap(~Productive) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance", title = "Mean Unit Task performance by language and Productivity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

###By knower-level
```{r}
knower.pal <- brewer.pal(n = 9, "Paired")[3:9]

all.data %>%
  filter(!is.na(Knower.level))%>%
  filter(Task == "SF")%>%
  group_by(SID, Knower.level, Language)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=Knower.level)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  ggtitle("Performance on Unit Task by language, knower-level") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  scale_fill_manual(values = count_range_pal)
```

---

##WCN
###Raw performance by language
```{r}
all.data %>%
  filter(Task == "NN")%>%
  group_by(SID, Language)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "none") +
  ggtitle("Overall mean correct on NN Task") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2")
```

###Performance by language, productivity
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "NN")%>%
  group_by(SID, Productive, Language)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  facet_grid(~Productive)+
  theme_bw(base_size = 13) + 
  theme(legend.position = "none") +
  ggtitle("Performance on NN Task by language, productivity") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2")
```

###Performance by count range
```{r}
count_range_pal <- brewer.pal(n = 9, "Spectral")[8:9]

all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "NN")%>%
  group_by(SID, count_range, Language)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = count_range, y = mean, fill=Language)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  ggtitle("Performance on NN Task by language, within/outside IHC") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2")
```

###By item, productivity
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "NN")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  group_by(Productive, Task_item, Language)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_wrap(~Productive) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance", title = "Mean WCN Task performance by language and Productivity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

###By knower level
```{r}
knower.pal <- brewer.pal(n = 9, "Paired")[3:9]

all.data %>%
  filter(!is.na(Knower.level))%>%
  filter(Task == "NN")%>%
  group_by(SID, Knower.level, Language)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=Knower.level)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  ggtitle("Performance on NN Task by language, knower-level") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  scale_fill_manual(values = count_range_pal)
```

---

##SF and NN together
###By-item performance
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "NN" | Task == "SF")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  group_by(Task, Productive, Task_item, Language)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 10) + 
  facet_grid(Task~Productive) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance", title = "Mean Unit and NN Task performance by language and Productivity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

##WPPSI
```{r, warning = FALSE}
##histogram of WPPSI scores
wppsi.ms <- all.data %>%
  filter(Task == "WPPSI")%>%
  filter(Trial_number != "Sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != "1", 
         Trial_number != '2', 
         Trial_number != '7', 
         Trial_number != '8')%>%
  mutate(Trial_number = as.numeric(as.character(Trial_number)))%>%
  group_by(SID, Language)%>%
  summarise(sum_wppsi = sum(as.numeric(as.character(Correct)), na.rm = TRUE), 
            num_trials = n())
 
 ggplot(wppsi.ms, aes(x = sum_wppsi, fill = Language)) +
   geom_histogram(binwidth = 1, colour = "black") +
   theme_bw() + 
   facet_grid(~Language)+
   scale_fill_brewer(palette = "Dark2") + 
   labs(title = "Frequency of WPPSI scores by language") +
   guides(fill = FALSE)
 
##Mean WPPSI scores 
all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "WPPSI")%>%
  filter(Trial_number != "Sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != "1", 
         Trial_number != '2', 
         Trial_number != '7', 
         Trial_number != '8')%>%
  mutate(Trial_number = as.numeric(as.character(Trial_number)))%>%
  group_by(SID, Language)%>%
  summarise(mean = mean(sum_wppsi, na.rm=TRUE),
            sd = sd(sum_wppsi, na.rm=TRUE)) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean WPPSI score") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "none") +
  ggtitle("Mean WPPSI score by Language") +
  theme(text = element_text(size = 12)) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2")
 
```


---

#Main analyses
##Within-language analyses

###Make model analysis dfs
Note that there is a lot more variability in highest counts and highest contiguous NN than in categorical variables. I am centering age, and centering and scaling FHC, IHC, and highest contiguous NN (which has the most variability).
```{r}
##HK##
sf.hk.within <- all.data%>%
  filter(Task == "SF")%>%
  filter(Language== "Cantonese")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))
  
wcn.hk.within <- all.data%>%
  filter(Task == "NN")%>%
  filter(Language == "Cantonese")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))

##SLO##
sf.slo.within <- all.data%>%
  filter(Task == "SF")%>%
  filter(Language == "Slovenian")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

wcn.slo.within <- all.data%>%
  filter(Language == "Slovenian")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))
```

###Unit Task

This first set of analyses replicates, in Cantonese English and Slovenian speaking samples, analyses similar to those previously conducted on English-speaking subjects. To identify whether there is connection between counting experience and Unit Task performance for participants within particular language groups, we will conduct four initial analyses (plus the null model) within each language, predicting Unit Task performance from (1) Productivity (defined above); (2) Final Highest Count; (3) Initial Highest Count; and (4) Highest Contiguous Next Number.

All models will be logistic mixed effects models, predicting performance on the unit task (0 or 1) on a trial as a function of the following predictors, with a random intercept for subject. In R, the formula will beglmer(predicted ~ (predictor) + age + within/outside range + (1|subject), family = binomial).

In each language, after running these first four models, any predictor that significantly (p &lt;.05) predicts Unit TaskPerformance (as assessed by running a likelihood ratio test on the Null Model (Model 0) and Models 1, 2, 3, and 4) will be added into Model 5, which will be our “Large” model. We will construct model 5 hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 5). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.


-  Model 0 (null model): Unit.Performance ~ Within/Outside range + Age + (1|subject)
-  Model 1: Unit.Performance ~ Productivity + Within/Outside range + Age + (1|subject)
-  Model 2: Unit.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
-  Model 3: Unit.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)
-  Model 4: Unit.Performance ~ Highest.Contiguous.Next.Number + Within/Outside range + Age + (1|subject)

#Hong Kong: Within-language models, Unit Task
Build the models

##Model 0 (base)
```{r}
sf.hk.within.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.base)
```


##Model 1 (Productivity): Not a significant predictor of Unit Task performance (*p* = .70)
```{r}
sf.hk.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model1)
anova(sf.hk.within.model1, sf.hk.within.base, test = 'LRT')
```

##Model 2 (Final Highest Count): Significant predictor of Unit Task performance (*p* = .003)
```{r}
sf.hk.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model2)
anova(sf.hk.within.model2, sf.hk.within.base, test = 'LRT')
```

##Model 3 (Initial Highest Count): Significant predictor of Unit Task Performance (*p* < .0001)
```{r}
sf.hk.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model3)
anova(sf.hk.within.model3, sf.hk.within.base, test = 'LRT')
```

##Model 4 (Highest Continguous Next Number): Significant predictor of Unit Task performance (*p* = .001)
```{r}
sf.hk.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model4)
anova(sf.hk.within.model4, sf.hk.within.base, test = 'LRT')
```

##Large model

We have three significant predictors of performance on the Unit task (FHC, IHC, and Highest Contiguous NN). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task.

###IHC and Highest Contiguous NN: Highest Contig. NN does not significantly explain additional variance (*p* = .09)
```{r}
##IHC and Highest Contig NN##
sf.hk.within.plus1 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
sf.hk.within.plus2 <- glmer(Correct ~ ihc.c + highest_contig.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)
anova(sf.hk.within.plus2, sf.hk.within.plus1, test = 'LRT') #highest contiguous does not significantly explain additional variance
```

###IHC and FHC: FHC does not significantly explain additional variance (*p* = .36)
```{r}
sf.hk.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)
anova(sf.hk.within.plus2, sf.hk.within.plus1, test = 'LRT') #final highest count does not significantly explain additional variance
```

##HK Unit Task within-language results:
IHC emerges as best predictor of performance on this task.

####EXPLORATORY ANALYSIS
This is an exploratory analysis which adds the magniude of the starting number to the model. 
```{r}
##EXPLORE
sf.hk.within.base1 <- glmer(Correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.base1)
anova(sf.hk.within.base1, sf.hk.within.base, test = 'LRT')

sf.hk.within.prod <- glmer(Correct ~ Productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.prod)
anova(sf.hk.within.prod, sf.hk.within.model1, test = 'LRT')

sf.hk.within.fhc <- glmer(Correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.fhc)
anova(sf.hk.within.fhc, sf.hk.within.model2, test = 'LRT')

sf.hk.within.ihc <- glmer(Correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.ihc)
anova(sf.hk.within.ihc, sf.hk.within.model3, test = 'LRT')

sf.hk.within.highest_contig <- glmer(Correct ~ highest_contig.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.highest_contig)
anova(sf.hk.within.highest_contig, sf.hk.within.model4, test = 'LRT')

##compare
sf.hk.within.ihc.plus1 <- glmer(Correct ~ ihc.c + fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
anova(sf.hk.within.ihc.plus1, sf.hk.within.ihc, test = 'LRT')
```

---

#SLO: Within-language models, Unit Task
Build the models 

##Model 0 (base)
```{r}
sf.slo.within.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.base)
```

##Model 1 (Productivity): Barely significant (*p* = .04)
```{r}
sf.slo.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model1)
anova(sf.slo.within.model1, sf.slo.within.base, test = 'LRT')
```

##Model 2 (Final Highest Count): Barely significant (*p* = .04)
```{r}
sf.slo.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model2)
anova(sf.slo.within.model2, sf.slo.within.base, test = 'LRT')
```

##Model 3 (Initial Highest Count): Marginally significant (*p* = .07)
```{r}
sf.slo.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model3)
anova(sf.slo.within.model3, sf.slo.within.base, test = 'LRT')
````

##Model 4 (Highest contiguous NN): Significant predictor (*p* = .02)
```{r}
sf.slo.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within) 
summary(sf.slo.within.model4)
anova(sf.slo.within.model4, sf.slo.within.base, test = 'LRT')
```

##Large model: Comparison between FHC and Highest contiguous NN: FHC does not significantly explain additional variance in the model (*p* = .2); Productivity does not significantly explain additional variance in the model (*p* = .12)
Highest contiguous and Final Highest count best predictors - compare
```{r}
sf.slo.within.plus1 <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
sf.slo.within.plus2 <- glmer(Correct ~ fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
anova(sf.slo.within.plus2, sf.slo.within.plus1, test = 'LRT')

#Test with productivity
sf.slo.within.plus2 <- glmer(Correct ~ Productive + highest_contig.c + count_range + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
anova(sf.slo.within.plus2, sf.slo.within.plus1, test = 'LRT')
```

###Exploratory analysis
Adding starting number magnitude
```{r}
##EXPLORE
sf.slo.within.base1 <- glmer(Correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.base1)
anova(sf.slo.within.base1, sf.slo.within.base, test = 'LRT')

sf.slo.within.prod <- glmer(Correct ~ Productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.prod)
anova(sf.slo.within.prod, sf.slo.within.model1, test = 'LRT')

sf.slo.within.fhc <- glmer(Correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.fhc)
anova(sf.slo.within.fhc, sf.slo.within.model2, test = 'LRT')

sf.slo.within.ihc <- glmer(Correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.ihc)
anova(sf.slo.within.ihc, sf.slo.within.model3, test = 'LRT')

sf.slo.within.highest_contig <- glmer(Correct ~ highest_contig.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.highest_contig)
anova(sf.slo.within.highest_contig, sf.slo.within.model4, test = 'LRT')

##compare
sf.slo.within.highest_contig.plus1 <- glmer(Correct ~ Productive + highest_contig.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
anova(sf.slo.within.highest_contig.plus1, sf.slo.within.highest_contig, test = 'LRT')
```

---

##Productivity t-test of Unit Task performance
Using the Productive/Non-Productive categorical classification outlined above, we will compare performance
between both groups on the Unit task using t-tests. We may do this by considering average performance
(averaring the 0’s and 1’s on each task for each participant); should doing so provide greater precision, we may also compare Highest Contiguous Number.

###HK: Marginally significant difference between groups (*p* = .08)
```{r}
#with mean performance
sf.hk.mean.ms <- sf.hk.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(sf.hk.mean.ms, Productive == "Productive")$mean, 
       subset(sf.hk.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #marginally significant difference between productive and nonproductive counters for performance on Unit Task
```

###SLO: Significant difference between groups (*p* = .0002)
```{r}
#with mean performance
sf.slo.mean.ms <- sf.slo.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(sf.slo.mean.ms, Productive == "Productive")$mean, 
       subset(sf.slo.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #significant difference in performance between productive and nonproductive counters
```

##Productivity t-test of Highest contiguous NN
###HK: Significant difference between groups (*p* = .01)
```{r}
sf.hk.mean.nn <- sf.hk.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.hk.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.hk.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```

###SLO: Significant difference between groups (*p* = .0007)
```{r}
sf.slo.mean.nn <- sf.slo.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.slo.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.slo.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```

---

#WCN Task- within-language analyses, simple models

All models will be logistic mixed effects models, predicting next number performance (0 or 1) on a trial as a function of the following predictors, with a random intercept for subject. In R, the formula will be glmer(predictedSF_correct ~ (predictor) + age + within/outside range + (1|subject), family = binomial).

-  Model 0 (null model): NextNumber.Performance ~ Within/Outside range + Age + (1|subject)
-  Model 1: Next.Number.Performance ~ Productivity + Within/Outside range + Age + (1|subject)
-  Model 2: Next.Number.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
-  Model 3: Next.Number.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)

In each language, after running these first three models, any predictor that significantly (p <.05) predicted Next Number Performance (as assessed by running a likelihood ratio test on the Null Model (Model 0) and Models 1, 2, and 3) will be added into Model 6, which will be our “Large” model (containing all predictors that significantly predicted Next Number Task Performance in the simple models). We will construct model 6 hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 6). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

#HK: Within-language analyses, Next Number Task
Build models

##Model 0 (base)
```{r}
wcn.hk.within.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.base)


```

##Model 1 (Productivity): Not a significant predictor (*p* = .24)
```{r}
wcn.hk.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model1)
anova(wcn.hk.within.model1, wcn.hk.within.base, test = 'LRT')
```

##Model 2 (Final Highest Count): Significant predictor (*p* < .0001)
````{r}
wcn.hk.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model2)
anova(wcn.hk.within.model2, wcn.hk.within.base, test = 'LRT')
````

##Model 3 (Initial Highest Count): Significant predictor (*p* < .0001)
```{r}
wcn.hk.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model3)
anova(wcn.hk.within.model3, wcn.hk.within.base, test = 'LRT')
```

##Large Model - Comparison of FHC and IHC: Both predictors significantly explain unique variance (*p* < .0001)
We have two significant predictors of performance on the Unit task (FHC and IHC). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task. 
```{r}
##IHC and FHC##
wcn.hk.within.plus1 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.hk.within)
wcn.hk.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.hk.within)
anova(wcn.hk.within.plus2, wcn.hk.within.plus1, test = 'LRT') #Initial Highest Count explains additional variance in WCN performance
```

###Exploratory analysis
Adding starting number magnitude
```{r}
###EXPLORE
wcn.hk.within.base1 <- glmer(Correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.base1)
anova(wcn.hk.within.base1, wcn.hk.within.base, test = 'LRT')
wcn.hk.within.prod <- glmer(Correct ~ Productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.prod)
anova(wcn.hk.within.prod, wcn.hk.within.model1, test = 'LRT')
wcn.hk.within.fhc <- glmer(Correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.fhc)
anova(wcn.hk.within.fhc, wcn.hk.within.model2, test = 'LRT')
wcn.hk.within.ihc <- glmer(Correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.ihc)
anova(wcn.hk.within.ihc, wcn.hk.within.model3, test = 'LRT')

#compare 
wcn.hk.within.fhc.plus <- glmer(Correct ~ ihc.c + fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
anova(wcn.hk.within.fhc.plus, wcn.hk.within.fhc, test = 'LRT')
```

---

#SLO: Within-language analyses, NN Task
Build the models

##Model 0
```{r}
wcn.slo.within.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.base)
```


##Model 1 (Productivity): Significant predictor (*p* < .0001)
```{r}
wcn.slo.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model1)
anova(wcn.slo.within.model1, wcn.slo.within.base, test = 'LRT')
```

##Model 2 (FHC): Significant predictor (*p* < .0001)
```{r}
wcn.slo.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model2)
anova(wcn.slo.within.model2, wcn.slo.within.base, test = 'LRT')
```

##Model 3 (IHC): Significant predictor (*p* < .0001)
```{r}
wcn.slo.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model3)
anova(wcn.slo.within.model3, wcn.slo.within.base, test = 'LRT')
```

##Large Model comparison: Productivity, FHC, and IHC
We have three significant predictors of performance on the Unit task (Productivity, FHC and IHC). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task. 

###Productivity and FHC: Productivity does not explain additional variance (*p* = .98)
```{r}
##Productive and FHC##
wcn.slo.within.plus1 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.slo.within)
wcn.slo.within.plus2 <- glmer(Correct ~ Productive + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)
anova(wcn.slo.within.plus2, wcn.slo.within.plus1, test = 'LRT') #Productivity does not explain additional variance
```

##IHC and FHC: IHC does not explain additional variance (*p* = .7)
```{r}
wcn.slo.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)
anova(wcn.slo.within.plus2, wcn.slo.within.plus1, test = 'LRT') ##IHC does not explain additional variance
```

###Exploratory analysis
Adding starting number/magnitude
```{r}
###Explore

wcn.slo.within.base1 <- glmer(Correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.base1)
anova(wcn.slo.within.base1, wcn.slo.within.base, test = 'LRT')
wcn.slo.within.prod <- glmer(Correct ~ Productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.prod)
anova(wcn.slo.within.prod, wcn.slo.within.model1, test = 'LRT')
wcn.slo.within.fhc <- glmer(Correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.fhc)
anova(wcn.slo.within.fhc, wcn.slo.within.model2, test = 'LRT')
wcn.slo.within.ihc <- glmer(Correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.ihc)
anova(wcn.slo.within.ihc, wcn.slo.within.model3, test = 'LRT')

#compare
wcn.slo.within.fhc.plus <- glmer(Correct ~ Productive + fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
anova(wcn.slo.within.fhc.plus, wcn.slo.within.fhc, test = 'LRT')
```

***

##Productivity t-test of WCN performance
Using the Productive/Non-Productive categorical classification outlined above, we will compare performance
between both groups on the Next Number task using t-tests. We may do this by considering average performance
(averaring the 0’s and 1’s on each task for each participant).

###HK: Significant difference between productive and nonproductive counters (*p* = .001)
```{r}
#with mean performance
wcn.hk.mean.ms <- wcn.hk.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(wcn.hk.mean.ms, Productive == "Productive")$mean, 
       subset(wcn.hk.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

###SLO: Significant difference between groups (*p* < .0001)

```{r}
#with mean performance
wcn.slo.mean.ms <- wcn.slo.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(wcn.slo.mean.ms, Productive == "Productive")$mean, 
       subset(wcn.slo.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

---

#Cross-linguistic comparisons
Our second set of analyses is aimed at understanding cross-linguistic differences in performance on the Unit Task. To do this, we will analyze all participants, from all language groups, in a single model. We will then construct our models from above, but will add (a) a measure of Working Memory and (b) the interaction of Initial Highest Count and Language group to each model. These models therefore allow us to test whether (a) language; (b) counting ability; or (c) some interaction between the two predict unit performance. We include Working Memory in all cross-linguistic models with the intention of taking into account baseline differences in processing across samples.

Cross-Linguistic Models:
Model 0a (the Null Model): Unit.Performance~ Language*IHC + Within/Outside range + Age + WM
+ (1|subject)
Model 1a: Unit.Performance ~ Productivity + Language*IHC + Within/Outside range + Age + WM + (1|subject)
Model 2a: Unit.Performance ~ Final.Count + Language*IHC + Within/Outside range + Age + WM + (1|subject)
Model 3a: Unit.Performance ~ Highest.Contiguous.Next.Number + Language*IHC + Within/Outside range +
Age + WM + (1|subject)
Make model dfs


We will then compare Model 0a (the Null Model) to each of the models containing measures of productivity (1a, 2a, and 3a) using a likelihood ratio test in testing whether these measures of productivity significantly explain variance in children’s performance. Should effects of Language emerge, we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects (e.g., Unit.Performance ~ Productivity + IHC + Within/Outside range + Age + WM + (1|subject)). After running the four models above, any predictor that significantly (p &lt;.05) predicted Unit Task Performance will be added into Model 6a, which will be our “Large” model (containing all predictors that significantly predicted Unit Task Performance in the simple models). We will construct model 6a hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 6a). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

##Make model dfs
```{r}
##HK##
sf.df.cross <- all.data %>%
  filter(Task == "SF")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))
  
wcn.df.cross <- all.data %>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))
```

---

#Unit Task: Cross linguistic models

##Model 0 (base)
```{r}
sf.cross.base <- glmer(Correct ~ Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.base)
```

##Model 1 (Productivity): Not a signficant predictor (*p* = .82)
NOTE: Model is currently failing to converge, may need to look at optimizer
```{r}
sf.cross.model1 <- glmer(Correct ~ Productive + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.model1)
anova(sf.cross.model1, sf.cross.base, test = 'LRT')
```

##Model 2 (Final Highest Count): Not a significant predictor (*p* = .88)
NOTE: Model is failing to converge, may need to look at optimizer
```{r}
sf.cross.model2 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.model2)
anova(sf.cross.model2, sf.cross.base, test = 'LRT')
```

##Model 3 (Highest Contiguous NN): Significant predictor (*p* = .02)
```{r}
sf.cross.model3 <- glmer(Correct ~ highest_contig.c + Language*ihc.c + count_range + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.model3)
anova(sf.cross.model3, sf.cross.base, test = 'LRT')
```


---

##WCN
Our third set of analyses is aimed at understanding cross-linguistic differences in performance on the next number task. To do this, we will analyze all participants, from all language groups, in a single model. As above, we add WM, and the language by IHC interaction.

Cross-Linguistic Models
-  Model 0b (the null model): Next.Number.Performance ~ Language*IHC + Within/Outside range + Age + WM +
(1|subject)
-  Model 1b: Next.Number.Performance ~ Productivity + Language*IHC + Within/Outside range + Age + WM +
(1|subject)
-  Model 2b: Next.Number.Performance ~ Final.Count + Language*IHC + Within/Outside range + Age + WM +
(1|subject)

We will construct Model 7b hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 7b). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

###Model 0 (base)
```{r}
wcn.cross.base <- glmer(Correct ~ Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross)
summary(wcn.cross.base)


```

###Model 1 (Productivity): Marginally significant (*p* = .05)
```{r}
wcn.cross.model1 <- glmer(Correct ~ Productive + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
summary(wcn.cross.model1)
anova(wcn.cross.model1, wcn.cross.base, test = 'LRT')
```

##Model 2 (Final Highest Count): Significant predictor (*p* = .002)
```{r}
wcn.cross.model2 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross, family = "binomial")
summary(wcn.cross.model2)
anova(wcn.cross.model2, wcn.cross.base, test = 'LRT')
```

##Large model
NOTE: Models failing to converge, may need to look at optimizer
Comparing productivity and FHC
```{r}
wcn.cross.plus1 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross)
wcn.cross.plus2 <- glmer(Correct ~ Productive + fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross)
anova(wcn.cross.plus1, wcn.cross.plus2, test = 'LRT')
```

##Model comparison: Removing effect of Language from FHC model: FHC still significant predictor (*p* = .03)
NOTE: Need to do this with productivity as well

Should effects of Language emerge, we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects (e.g., Unit.Performance ~ Productivity + IHC + Within/Outside range + Age + WM + (1|subject)). After running these three models, any predictor that significantly (p &lt;.05) predicted Next Number Performance (as assessed by running a likelihood ratio test on the Null Model (Model 0b) and Models 1b and 2b) will be added into Model 7b, which will be our “Large” model (containing all predictors that significantly predicted Next Number Performance in the simple models).

There is a significant effect of Language: we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects (e.g., WCN.Performance ~ Productivity + IHC + Within/Outside range + Age + WM + (1|subject)).
```{r}
wcn.nolang.base <- glmer(Correct ~ ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial")
wcn.nolang.model1 <- glmer(Correct ~ fhc.c + ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial")
anova(wcn.nolang.model1, wcn.nolang.base, test = 'LRT') #FHC is still significant, but just barely

```

---

#Counting distribution
We plan to conduct descriptive analyses to describe the ways in which Initial Highest Count differs across
languages.
```{r}
hc.df %>%
  group_by(Language)%>%
  summarise(mean = mean(IHC, na.rm = TRUE), 
            sd = sd(IHC, na.rm = TRUE), 
            median = median(IHC, na.rm = TRUE))
```

In addition, we plan to test whether children in transparent languages can become productive with less counting experience. To test this, we will consider non-productive counters (those who were labeled as non-Productive). We will then ask whether IHC for these non-productive counters differs across languages. We will only conduct these analyses if we have at least 30 non-productive counters in each language. If count-list transparency allows children to converge on a productive count rule more quickly, then children who learn a system with a transparent-count list should move to the “productive counter” category on the basis of relatively less experience than children who learn a system with an opaque- count list. This predicts that, when considering non-Productive counters, initial highest count should be higher for opaque languages (like English) than for Slovenian, and higher for Slovenian than for Cantonese. The model would like this: 

Model 1: IHC ~ Language + Age + WM, data = NonProductiveCounters

###Model: Nonproductive Slovenians have significantly *lower* IHC than Cantonese speakers
```{r}
ihc.cross <- all.data %>%
  distinct(SID, Language, Age, sum_wppsi, Productive, IHC)%>%
  filter(Productive == "Nonproductive")%>%
  mutate(Language = factor(Language))%>%
  mutate(age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale = TRUE)))

ihc.model.1 = lm(IHC ~ Language + age.c + wppsi.c, data = ihc.cross)
summary(ihc.model.1)
```

In addition, we will test whether count-list transparency allows children to acquire some degree of productivity, even before they are labeled productive counters based on their overall counting performance. To test this, we will predict Highest Contiguous Next Number from Language. If transparent languages allow children to generate a productive counting rule, speakers of these transparent languages may perform better on the Next Number task than speakers of non- transparent languages, even when only considering non-productive counters. Model 2: Highest.Contiguous.NextNumber ~ Language + Age + WM + (1|subject), data = NonProductiveCounters

###Model: No effect of Language here
```{r}
wcn.model <- all.data %>%
  distinct(SID, Language, Age, sum_wppsi, Productive, highest_contig)%>%
  filter(Productive == "Nonproductive")%>%
  mutate(Language = factor(Language))%>%
  mutate(age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale = TRUE)))

highest_contig.model <- lm(highest_contig ~ Language + age.c + wppsi.c, data = wcn.model)
summary(highest_contig.model)
```

TO-do for RMS: 
- Follow up analysis for productivity:lang interactions: In the event that, when analyzing each language group separately, we find evidence that a particular counting/productivity measure (Next Number, Final HC, Productivity) improves model fit for one language group by not another, we will conduct a follow-up analysis testing whether productivity classification interacts with language group. We will compare the model containing an interaction to one that excludes the interaction. It is important to note that our critical effect of interest is not necessarily a [Productivity Measure]:[Language Group] interaction, although finding such an interaction may be interpretable (e.g., it may suggest that productivity predicts other measures to a greater degree in some languages vs. others): ProductivityLang: Unit ~ Productivity Measure (Highest NN, FHC, Productivity classification)*Language.Group +
Language*IHC + Within/Outside range + Age + WM (1|subject)
- Exploratory analyses
- Cluster analysis...
- Frequency of error types
- Test whether modes differ across languages
- Include vs. exclude memory check failure SF trials
- Highest contiguous Successor vs. Highest contiguous NN
- Teacher survey data...
- Comparison of numbers on NN and SF
- Comparison of above and below 100 for NN and SF
- 