---
title: "XCulture Analysis"
author: "Rose M. Schneider"
date: "8/5/2018"
output: html_document
---
TO-DO
- str of data, change silent to NA
- Break apart India and HK/SLO data for visualizations - it's getting crazy

#Setup
```{r}
rm(list = ls())
require("knitr")
opts_knit$set(root.dir = "~/Documents/Projects/xculture/HK_SLO/") #this is specific to RMS, change accordingly
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)
library(memisc)
library(pander)
'%!in%' <- function(x,y)!('%in%'(x,y))
```

#Load data
##Slovenian
```{r}
#slo data
slo.full.data <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/SLO_data.csv')%>%
  mutate(Exclude_task = ifelse(is.na(Exclude_task), 0, as.numeric(as.character(Exclude_task))))%>%
  mutate(Trial_number = ifelse(Trial_number == '0', "Training", as.character(Trial_number)), 
         Task_item = factor(Task_item))%>%
  mutate(Response = ifelse(Task == "WPPSI", as.character(Correct), as.character(Response)))%>%
  filter(SID != "CopyPasteMe")%>%
  mutate(Age = as.numeric(as.character(Age)), 
         Correct = as.integer(as.character(Correct)))

#slo highest count
slo.hc <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/SLO_HC.csv')%>%
  select(-Special_count)
```

##Cantonese
```{r}
#hk data
hk.full.data <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/HK_data.csv')%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  mutate(Age = as.numeric(as.character(Age)), 
         Correct = as.integer(as.character(Correct)), 
         Mem_check_1 = as.integer(as.character(Mem_check_1)), 
         Mem_check_2 = as.integer(as.character(Mem_check_2)))%>%
  mutate(Response = ifelse(Task == "WPPSI", as.character(Correct), as.character(Response)))

#hk highest count
hk.hc <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/HK_HC.csv')%>%
  select(-Special_count)
```

##English - US
```{r}
us.full.data <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/US_Data.csv') %>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  mutate(Age = as.numeric(as.character(Age)), 
         Mem_check_1 = as.integer(as.character(Mem_check_1)), 
         Mem_check_2 = as.integer(as.character(Mem_check_2)), 
         Correct = as.integer(as.character(Correct)))%>%
  mutate(Exclude_task = ifelse(is.na(Exclude_task), 0, 1), 
         Exclude_trial = as.integer(as.character(Exclude_trial)))

#highest count
us.hc <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/US_HC.csv')%>%
  dplyr::rename(IHC = IHC_final, 
                FHC = FHC_final)%>%
  filter(Exclude != "1", 
         Exclude != "HELP")%>%
  mutate(Exclude = as.integer(as.character(Exclude)))%>%
  mutate(Special_Count = ifelse(Special_Count != "0", 1, 0), 
         Special_Count = as.integer(as.character(Special_Count)), 
         IHC = as.integer(as.character(IHC)), 
         FHC = as.integer(as.character(FHC)))%>%
  select(-Special_Count)

##TEMPORARY##
#filter to make sure we have the same SIDS in HC and data 
included_SIDs <- as.vector(unique(us.hc$SID))

us.full.data %<>%
  filter(SID %in% included_SIDs)
```

##India data
TO-DO RMS: There is someone with a "ChangeMe" for language - find out who and fix. Currently they are excluded
TO-DO RMS: It looks like people have been entering some weird stuff for memory checks - fix this on the actual data sheet, as well as all of the Languages
TO-DO RMS: There are some notes in the data about exclusions - make sure these are incorporated in the final data set
TO-DO RMS: Need to deal with all of the help responses
```{r}
india.full.data <- read.csv('/Users/roseschneider/Documents/Projects/xculture/India/Data/India_Data.csv')%>%
  filter(SID != "CopyPasteMe",
         Language != "ChangeMe")%>%
  droplevels()%>%
  select(-Response_single, -Response_double, -Response_mismatch, -Mem_check_1_single, 
         -Mem_check_1_double, -Mem_check_2_single, -Mem_check_2_double, -Mem_check_1_mismatch, 
         -Mem_check_2_mismatch, -Exclude_trial_single, -Exclude_trial_double, -Exclude_trial_reason_single,
         -Exclude_trial_double, -Exclude_trial_reason_double)%>%
  dplyr::rename(Response = Response_final,
                Mem_check_1 = Mem_check_1_final, 
                Mem_check_2 = Mem_check_2_final, 
                Exclude_trial = Exclude_trial_validate,
                Exclude_trial_reason = Exclude_trial_reason_validate, 
                Correct = Correct_final)%>%
  mutate(Response = ifelse(Response == "<NA>", NA, as.character(Response)))%>%
  select(-Unit_task_repeat_alts)%>%
  mutate(Language = ifelse(Language == "English", "English - India", as.character(Language)))%>%
  mutate(Task = ifelse(Task == "WCN", "NN", as.character(Task)))%>%
  mutate(Trial_number = ifelse(Trial_number == "training", "Training", as.character(Trial_number)))
```

##India HC
```{r}
india.hc <- read.csv("/Users/roseschneider/Documents/Projects/xculture/India/Data/India_HighestCount.csv") %>%
  filter(Exclude != "1",
           Exclude != "HELP")%>%
  mutate(Last_successful = as.integer(as.character(Last_successful)))%>%
  select(-Special_count)

##TEMPORARY##
#only keeping the SIDs that are included in Highest Count
included_SIDs <- as.vector(unique(india.hc$SID))

#check to see if there are any SID mismatches
check <- india.full.data %>%
  filter(SID %!in% included_SIDs)%>%
  distinct(SID)

#filter india.full.data to keep only these kiddos
india.full.data %<>%
  filter(SID %in% included_SIDs)



#Also temporary, we're going to assume that all kids with HELP are to be excluded
india.full.data %<>%
  mutate(Exclude_analysis = ifelse(Exclude_analysis == "HELP", 1, as.character(Exclude_analysis)), 
         Exclude_task = ifelse(Exclude_task == "HELP", 1, as.character(Exclude_task)), 
         Exclude_trial = ifelse(Exclude_task == "HELP", 1, as.character(Exclude_trial)), 
         Exclude_analysis = as.integer(Exclude_analysis), 
         Exclude_task = as.integer(Exclude_task), 
         Exclude_trial = as.integer(Exclude_trial))%>%
  mutate(Mem_check_2 = ifelse(Mem_check_2 == "IDK", 0, 
                              ifelse(Mem_check_2 == "18", 0, as.integer(as.character(Mem_check_2)))))
```

##Bind together
```{r, warning = FALSE}
#regular data
all.data <- bind_rows(slo.full.data, hk.full.data, us.full.data, india.full.data)%>%
  mutate(Age = round(Age, 2), 
         Agegroup = cut(Age, breaks = c(3.49, 4, 4.5, 5, 5.5, 6, 6.66), 
                        labels = c("3.5-4", "4-4.5", "4.5-5", 
                                   "5-5.5", "5.5-6", "6-6.5")))%>%
  select(-X)%>%
  mutate(Language = factor(Language))
##highest count

slo.hc %<>%
  filter(Exclude != 1)%>%
  mutate(IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))

hk.hc %<>%
  filter(Exclude != 1)%>%
  mutate(IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))

us.hc %<>%
  filter(Exclude != 1)%>%
  mutate(IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))%>%
  dplyr::rename(Last_successful = Last_Successful)

india.hc %<>%
  filter(Exclude != 1, 
         Exclude != "HELP", 
         Language != "")%>%
  select(-IHC_single, -FHC_single)%>%
  dplyr::rename(IHC = IHC_final, 
                FHC = FHC_final)%>%
  mutate(IHC = as.integer(as.character(IHC)), 
         FHC = as.integer(as.character(FHC)), 
         IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))%>%
  mutate(Language = ifelse(Language == "English", "English - India", as.character(Language)), 
         Language = ifelse(Language == "English ", "English - India", as.character(Language)), 
         Language = ifelse(Language == "Hindi ", "Hindi", as.character(Language)), 
         Language = ifelse(Language == "Gujarati ", "Gujarati", as.character(Language)))%>%
  mutate(Exclude = as.integer(as.character(Exclude)))%>%
  mutate(Language = factor(Language))

#bind hk and slo hc data
slo.hc %<>%
  mutate(Language = "Slovenian")%>%
  dplyr::rename(Last_successful = Last_Successful)%>%
  mutate(Last_successful = as.integer(as.character(Last_successful)))

hk.hc %<>%
  mutate(Language = "Cantonese")

us.hc %<>%
  mutate(Language = "English")

hc.df <- bind_rows(slo.hc, hk.hc, us.hc, india.hc)%>%
  mutate(Language = factor(Language))
```

---

#Classifications
##CP or subset-knower
Children are classified as subset-knowers if they got all 4 numbers requested correct (on either the first or the second try).
```{r}
cp.df <- all.data %>%
  filter(Task == "GiveN")%>%
  group_by(SID)%>%
  summarise(sum_correct = sum(Correct, na.rm = TRUE))%>%
  mutate(Knower.level = ifelse(sum_correct >= 4, "CP-knower", "Subset-knower"))%>%
  select(-sum_correct)

all.data <- full_join(all.data, cp.df, by = "SID")
```

##WPPSI score
WPPSI score is just the total correct items by participant, excluding feedback/training trials
```{r}
 #get sum per SID, add to sf and wcn for CROSS-LINGUISTIC models
 wppsi.sid <- all.data %>%
  filter(Task == "WPPSI")%>%
  filter(Exclude_trial != 1)%>%
  mutate(Trial_number = factor(Trial_number))%>%
  filter(Trial_number != "sample item A", 
         Trial_number != "sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != '1', 
         Trial_number != '2', 
         Trial_number != '7', 
        Trial_number != '8')%>%
   group_by(SID)%>%
   summarise(sum_wppsi = sum(Correct, na.rm = TRUE))

all.data <- full_join(all.data, wppsi.sid, by = "SID")
```


##Productivity
Children are classified as productive if they are able to count at least 2 decades higher than an error without making more than 3 errors along the way, OR if they are able to count to 140 without making an error.
```{r, warning = FALSE}
hc.df %<>%
  mutate(Last_successful = ifelse(Last_successful == "Is quiet", "IDK", Last_successful))%>%
  filter(Exclude != 1)%>%
  filter(SID != "CH-VC-1")#excluding this kid because they break my productivity code

hc <- hc.df %>% # replace with your local path
  select(SID, Last_successful, IHC, FHC, Language) %>%
  mutate_at(c('Last_successful','IHC','FHC'),
            function(col) as.integer(str_replace_all(col,'\\D',''))) %>% # some of these included '?', so i remove any char thats not a digit
  mutate(Last_successful = ifelse(is.na(Last_successful), 140, Last_successful))%>%
  filter(!is.na(IHC))

# 
# function for determining productivity
is.productive = function(subject){
  # takes as input the data for a single subject
  # RULES:
  # - counts to 120 unaided = productive
  # - after making first error, counts >= 20 higher, with no more than 3 errors on way
  if(subject$IHC[1] >= 140){
    # if they get to 120 on first try, = productive
    return(TRUE)
  } else if(subject$FHC[1] == 140 & nrow(subject) < 4) {
    return(TRUE)
  } else if(subject$FHC[1] < 140 & nrow(subject) == 1 
            & subject$FHC[1] == subject$IHC[1]) {
    return(FALSE)
  } else if((subject$FHC[1] - subject$IHC[1]) >= 20){
    # if their final is >= 20 larger than their intial...
    if(nrow(subject) < 4){
      # and they've made 3 or fewer total errors, = productive
      return(TRUE)
    } 
    else {
      for(i in 1:nrow(subject)){ # start at row 2
        # check if they ever made it >= 20 counts & <= 3 errors after an error
        runLength = 0 # they just made an error, so no post-error successes yet
        numErrors = 0 # first row was an error if it's not finalCount == 120
        prev = subject$Last_successful[i]
        for (j in i+1:nrow(subject)){ # from current row until end...
          numErrors = numErrors + 1 # new row means new error
          runLength = runLength + (subject$Last_successful[j] - prev)
          # ^ add difference between current count and last count to run length
          prev = subject$Last_successful[j] # update last count
          if(runLength >= 20 & numErrors < 4){
            # if at any point the productivity conditions are met...
            return(TRUE) # = productive
          }
        }
      }
      # productivity conditions were never met (because we got to this point) so...
      return(FALSE) # != productive
    }
  } else {
    # highest is not >= 20 greater than initial
    return(FALSE)
  }
}
# 
#make function to run for all participants
unique_SIDs <- as.vector(unique(hc.df$SID))
# 
class_prod <- function(vector) {
  temp_data <- data.frame()
  for (i in vector) {
    prod.class <- data.frame(i, is.productive(subset(hc, SID == i)))
    # print(i) # for debugging
    names(prod.class) <- c("SID", "productive")
    temp_data <- bind_rows(temp_data, prod.class)
  }
  return(temp_data)
}
# 

productive <- class_prod(unique_SIDs)%>%
  rename(check_prod = productive)%>%
  mutate(check_prod = ifelse(check_prod == TRUE, "Productive", "Nonproductive"))

#manually add child who broke productivity code: CH-VC-1, IHC 20, FHC 56, productive

hc %<>%
  select(-Last_successful)

productive <- full_join(productive, hc, by = "SID")%>%
  distinct(SID, IHC, FHC, check_prod)%>%
  dplyr::rename(Productive = check_prod)

productive <- rbind(productive, c('CH-VC-1', 'Productive', 20, 56))

all.data <- full_join(all.data, productive, by = "SID")%>%
  mutate(IHC = as.integer(IHC), 
         FHC = as.integer(FHC))
```

##Highest Contiguous NN
Highest Contiguous NN is a measure of productivity. This is the highest number for which a child was correct on the Next Number task, provided that all the previous numbers had also been correct.
```{r, warning = FALSE}
failed.nn <- all.data %>%
  filter(Task == "NN", 
         Correct == 0, 
         Trial_number == "Training")

failed.nn.sids <- unique(as.vector(failed.nn$SID))

#get unique ids
unique.nn <- all.data %>%
  filter(Task == "NN")%>%
  distinct(SID)

unique.nn <- as.vector(unique.nn$SID)
nextnums <- as.vector(c(5, 7, 16, 24, 52, 71, 105, 107, 116, 224, 252, 271))

#this is a function that pulls out the largest number for which a participant had a correct consecutive
get_contiguous <- function(){
  contig <- data.frame()
  for (sub in unique.nn) {
    tmp <- all.data %>%
      mutate(Task_item= as.integer(Task_item))%>%
      filter(Task == "NN",
             SID == sub, 
             Correct == 0)%>%
      mutate(Task_item = sort(as.integer(Task_item)))
    if (length(tmp$SID) == 0) {
      highest_contig = 271
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else if (sub %in% failed.nn.sids) {
      highest_contig = 0
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else if (length(tmp$Task_item) > 0 & min(tmp$Task_item) == 5) {
      highest_contig = 1
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else {
      min.nn <- min(tmp$Task_item)
      prev_correct <- nextnums[nextnums < min.nn]
      highest_contig <- max(prev_correct)
    
      sub_contig <- data.frame(sub,
                             highest_contig)
      contig <- bind_rows(contig, sub_contig)
    }
  }
  return(contig)
}

highest_contiguous_nn <- get_contiguous()%>%
  dplyr::rename(SID = sub)

#add this to df 
all.data <- full_join(all.data, highest_contiguous_nn, by = "SID")

```

##Within/outside count range
Each trial on the Unit or WCN task was determined to be either within or outside a child's unprompted count range (IHC).
```{r}
all.data %<>%
  mutate(count_range = ifelse((Task == "SF" | Task == "NN") & as.numeric(Task_item) <= IHC, "Within", 
                              ifelse((Task == "SF" | Task == "NN") & as.numeric(Task_item) > IHC, "Outside", 
                                     NA)))
```

---
#Exclusions
##Global exclusions
Children were excluded from the analysis only if a) they did not complete the highest count task, or b) their exclusion was noted by the experimenter. Note that there are currently participants excluded from the Slovenian dataset due to not having enough data from the WPPSI. These children may be added back in, but we're currently in a position to replace them. 
```{r}
all.data %>%
  filter(Exclude_analysis == 1)%>%
  distinct(SID, Exclude_analysis, Exclude_analysis_reason, Language)

#exclude
all.data %<>%
  filter(Exclude_analysis != 1)

#Manual exclusions - these are participants who did not receive the correct number of trials in WPPSI. Manually excluded for now because we're in a position to replace them. 

#slovenian
all.data %<>%
filter(SID != "11072018-L",
           SID != "12072018-I",
           SID != "19072018-J",
           SID != "19072018-M",
           SID != "19072018-P",
           SID != "Naj16",
           SID != "Sol07", 
         SID != "Naj14")

#US
all.data %<>%
  filter(SID != "081318-LH", 
         SID != "073118-TC", 
         SID != "072618-DH", 
         SID != "072518-SH", 
         SID != '072418-GG', 
         SID != "072318-W", 
         SID != "072318-EB",
         SID != "072318-AT", 
         SID != "0723118-LM")

all.data %<>%
  filter(!is.na(Language))
```

###Task exclusions
TO-DO RMS: Automate this in code
Children were excluded from a given task if they did not complete at least TWO trials of that task (in addition to the training trial). In order to be considered as having completed a trial of the task, a child must at least say "I don't know."  These children were excluded manually.
```{r}
all.data %>%
  filter(Exclude_task == 1)%>%
  distinct(SID, Language, Exclude_task, Excluded_task, Exclude_task_reason)

#check to make sure there aren't other kids who snuck in
check_wppsi <- all.data %>%
  filter(Task == "WPPSI")%>%
  filter(Exclude_trial != 1)%>%
  mutate(Trial_number = factor(Trial_number))%>%
  filter(Trial_number != "sample item A", 
         Trial_number != "sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != '1', 
         Trial_number != '2', 
         Trial_number != '7', 
        Trial_number != '8')%>%
  group_by(SID)%>%
  summarise(n = n())%>%
  mutate(WPPSI_exc = ifelse(n < 3, 'EXCLUDE', 'KEEP'))%>%
  filter(WPPSI_exc == 'EXCLUDE')

exclude_wppsi_SIDs <- as.vector(unique(check_wppsi$SID))

#this is currently 0, need to update so exclusions can be run on this
check_all <- all.data %>%
  filter(Trial_number != "Training")%>%
  group_by(SID, Task)%>%
  summarise(n = n())%>%
  mutate(GiveN_exc = ifelse(Task == "GiveN" & n < 2, 'EXCLUDE', 'KEEP'), 
         SF_exc = ifelse(Task == "SF" & n < 2, 'EXCLUDE', 'KEEP'), 
         NN_exc = ifelse(Task == "NN" & n < 2, 'EXCLUDE', 'KEEP'))%>%
  filter(GiveN_exc == 'EXCLUDE' |
           SF_exc == "EXCLUDE" |
           NN_exc == 'EXCLUDE')

all.data %<>%
  mutate(Exclude_task = ifelse(SID %in% exclude_wppsi_SIDs, 1, as.integer(as.character(Exclude_task))))


#exclude
all.data %<>%
  filter(Exclude_task != 1)
```

##Excluded trials
Trials where a participant gave no response were excluded from analysis.
```{r}
all.data %>%
  filter(Exclude_trial == 1)%>%
  group_by(Task, Exclude_trial_reason)%>%
  summarise(n = n())

all.data %<>%
  filter(Exclude_trial != 1)

#how many trials do we have for each task?
all.data %>%
  filter(Task == "SF" | 
         Task == "NN")%>%
  group_by(Language, Task, Task_item)%>%
  summarise(n = n())
```

##Exclude practice trials for SF and NN
Practice trials are excluded from analysis. 
```{r}
#how many kids failed the practice trials on these tasks?
all.data %>%
  filter(Task == "SF" | Task == "NN")%>%
  filter(Task_item == 1, 
         Correct == 0)%>%
  group_by(Task)%>%
  summarise(n = n())

#exclude practice trials
all.data %<>%
  filter(Trial_number != "Training")
```

##Memory checks - NAs to 1
Some participants have NAs rather than 1 for their first memory check. Also, if first mem check is a 0, and second is NA, change that second one to 1.
```{r}
all.data %<>%
  mutate(Task = factor(Task))%>%
  mutate(Mem_check_1 = ifelse(Task == "SF" & is.na(Mem_check_1), 1, Mem_check_1))%>%
  mutate(Mem_check_2 = ifelse(Task == "SF" & is.na(Mem_check_2) & Mem_check_1 == 0, 1, Mem_check_2))
```

---

#Demographics
```{r, warning = FALSE}
#demos by age group, Language
all.data %>%
  distinct(SID, Language, Agegroup, Age)%>%
  group_by(Language, Agegroup)%>%
  summarise(n = n(), 
            Mean_age = mean(Age, na.rm = TRUE), 
            SD_age = sd(Age, na.rm = TRUE))%>%
  kable()

#demos by Language
all.data %>%
  distinct(SID, Language, Age)%>%
  group_by(Language)%>%
  summarise(n = n(),
            Mean_age = mean(Age, na.rm = TRUE), 
            SD_age = sd(Age, na.rm = TRUE))%>%
  kable()
  
#histogram of age
all.data %>%
  distinct(SID, Language, Age)%>%
ggplot(aes(x = Age, fill = Language)) +
  geom_histogram(binwidth = .5, colour = "black") +
  theme_bw() + 
  facet_wrap(~Language) + 
  scale_x_continuous(breaks = c(3.5, 4, 4.5, 5, 5.5, 6, 6.5)) +
  scale_fill_brewer(palette = "Dark2") + 
  guides(fill = FALSE) +
  labs(y = "Count", title = "Number of children in age bin by language")
```

##Productivity by language
```{r}
all.data %>%
  distinct(SID, Language, Productive)%>%
  group_by(Language, Productive)%>%
  summarise(n = n())%>%
  kable()

all.data %<>% 
  filter(!is.na(Language))
```

###Productivity descriptives
```{r}
all.data %<>%
  mutate(IHC = as.integer(IHC), 
         FHC = as.integer(FHC))

all.data %>%
  filter(!is.na(Productive))%>% #filtering out cases with no productivity classification
  filter(!is.na(Language))%>%
  distinct(SID, Age, Productive, Language, IHC, FHC)%>%
  group_by(Language, Productive)%>%
  summarise(n = n(),
            mean_IHC = round(mean(IHC), 2), 
            sd_IHC = round(sd(IHC), 2), 
            median_IHC = round(median(IHC), 2), 
            mean_FHC = round(mean(FHC), 2), 
            sd_FHC = round(sd(FHC), 2), 
            median_FHC = round(median(FHC), 2))%>%
  kable()
```

---

#Task visualizations
##Highest count
###Histogram Initial and Final Highest Count
```{r}
unique.hc.data <- all.data %>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  distinct(SID, IHC, FHC, Productive, Language, Dataset)%>%
  gather(IHC_FHC,highest_count, IHC:FHC)%>%
  mutate(highest_count = as.integer(highest_count), 
         IHC_FHC = factor(IHC_FHC, levels = c("IHC", "FHC"), 
                          labels = c("Initial Highest Count", "Final Highest Count")))

#Initial/Final, HK/SLO/US
unique.hc.data %>%
  filter(Dataset == "HK/SLO/US")%>%
ggplot(aes(x=highest_count, fill=Productive)) + 
  geom_histogram(binwidth = 10, colour = "black") +
  theme_bw(base_size = 10)+
  labs(title = "Initial/Final Highest Counts by Productivity and Dataset") +
  facet_grid(IHC_FHC~Language) +
  scale_x_continuous(breaks = seq(0, 140, 10))+
  scale_fill_brewer(palette = "Set1") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.minor = element_blank())+
  theme(legend.position = "bottom")

#Initial/Final, India
unique.hc.data %>%
  filter(Dataset == "India")%>%
ggplot(aes(x=highest_count, fill=Productive)) + 
  geom_histogram(binwidth = 10, colour = "black") +
  theme_bw(base_size = 10)+
  labs(title = "Initial/Final Highest Counts by Productivity and Dataset") +
  facet_grid(IHC_FHC~Language) +
  scale_x_continuous(breaks = seq(0, 140, 10))+
  scale_fill_brewer(palette = "Set1") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.minor = element_blank()) +
  theme(legend.position = "bottom")

```

###Scatterplot of IHC and FHC
```{r}
initial_final <- all.data %>%
   mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(!is.na(Productive))%>%
  distinct(SID, Language, IHC, FHC, Productive, Dataset)%>%
  mutate(IHC = as.numeric(IHC), 
         FHC = as.numeric(FHC))

#IHC/FHC scatter, HK/SLO/US
initial_final %>%
  filter(Dataset == "HK/SLO/US")%>%
ggplot(aes(x = IHC, y = FHC, 
                          color = Productive)) +
  geom_point(size = 1) + geom_jitter(width = .1) +
  labs(x = "Initial highest count", y = "Final highest count", 
                      color = "", title = "") +
  theme_bw(base_size = 13) + 
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) + 
  theme(panel.grid.minor = element_blank(), 
        legend.position = "bottom", 
        legend.text = element_text(size = 8)) + 
  facet_wrap(~Language, ncol = 3) + 
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#IHC/FHC scatter, India
initial_final %>%
  filter(Dataset == "India")%>%
ggplot(aes(x = IHC, y = FHC, 
                          color = Productive)) +
  geom_point(size = 1) + geom_jitter(width = .1) +
  labs(x = "Initial highest count", y = "Final highest count", 
                      color = "", title = "") +
  theme_bw(base_size = 13) + 
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) + 
  theme(panel.grid.minor = element_blank(), 
        legend.position = "bottom", 
        legend.text = element_text(size = 8)) + 
  facet_wrap(~Language, ncol = 3) + 
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

###Plotting distance between Initial and Final Highest Counts (~Pierina's graph) for Productive counters (this is a mess)
```{r}
#HK/SLO/US
unique.hc.data %>%
  filter(Dataset == "HK/SLO/US", 
         Productive == "Productive")%>%
ggplot(aes(x = SID, y = highest_count)) + 
  facet_grid(rows = vars(Productive)) +
  geom_line() + 
  geom_point(aes(shape = IHC_FHC, colour = IHC_FHC), 
             size = 2, stroke = 1.5) +
  scale_color_brewer(palette="Paired", direction = 1) +
  scale_shape_manual(values = c(4,5,20)) +
  labs(title="Distance between initial and final highest counts",
       x = "Each line = individual kids",
       y="Highest Count by Count Type") +
  theme_bw(base_size = 7) + 
  theme(legend.position="bottom", 
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~Language, scales = "free_x")

#India
unique.hc.data %>%
  filter(Dataset == "India", 
         Productive == "Productive")%>%
ggplot(aes(x = SID, y = highest_count)) + 
  facet_grid(rows = vars(Productive)) +
  geom_line() + 
  geom_point(aes(shape = IHC_FHC, colour = IHC_FHC), 
             size = 2, stroke = 1.5) +
  scale_color_brewer(palette="Paired", direction = 1) +
  scale_shape_manual(values = c(4,5,20)) +
  labs(title="Distance between initial and final highest counts",
       x = "Each line = individual kids",
       y="Highest Count by Count Type") +
  theme_bw(base_size = 7) + 
  theme(legend.position="bottom", 
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~Language, scales = "free_x")
```




---

##Unit Task
###How many kids failed the memory checks in each dataset by number
TO-DO RMS: There are a bunch of NAs for India data - what's going on here
```{r}
#for SF
sf.df <- all.data %>%
  filter(Task == "SF")%>%
  mutate(mem_check_status = ifelse((Mem_check_1 == 1 & is.na(Mem_check_2)), "Needed_1_passed_1",
                                    ifelse((Mem_check_1 == 0 & Mem_check_2 == 0), "Needed_2_failed_2",
                                           ifelse((Mem_check_1 == 1 & Mem_check_2 == 1),
                                                  "unclear_pass1_pass2",
                                                  ifelse((Mem_check_1 == 1 & Mem_check_2 == 0),
                                                         "unclear_passed1_failed2",
                                                         ifelse((Mem_check_1 == 0 & Mem_check_2 == 1),
                                                                "failed1_passed2", "other"))))))

#by number
sf.mem.num.ms <- sf.df %>%
  mutate(Task_item = factor(Task_item, levels = c("5", '7', '16', '24', '52', '71', '105', '107', '116', '224', '252', '271')))%>%
  filter(!is.na(Productive))%>%
  group_by(Task_item, mem_check_status, Language, Productive)%>%
  summarise(n = n())

ggplot(subset(sf.mem.num.ms), aes(x = Task_item, y = n, fill = mem_check_status)) + 
  geom_bar(stat = "identity") + 
  facet_grid(Productive~Language) +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Number queried", y = "Number of trials", title = "Memory checks by number in Unit Task")
```

###Overall performance by Language
```{r}
all.data %>%
  filter(Task == "SF")%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "none") +
  ggtitle("Overall mean correct on Unit Task") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2") +
  facet_grid(~Dataset, scale = "free_x")
```

###Performance by language, productivity
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "SF")%>%
  group_by(SID, Productive, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  facet_grid(Productive~Dataset, scale = "free_x")+
  theme_bw() + 
  theme(legend.position = "none") +
  ggtitle("Performance on Unit Task by language, productivity") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

###By productivity and count range
```{r}
count_range_pal <- brewer.pal(n = 9, "Spectral")[8:9]

all.data %>%
  filter(!is.na(Productive))%>%
   mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "SF")%>%
  group_by(SID, count_range, Language, Productive, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = count_range, y = mean, fill=Language)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  ggtitle("Performance on Unit Task by language, within/outside IHC") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2") + 
  facet_grid(Productive~Dataset)
```

###Item performance by productivity, Unit Task
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
   mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "SF")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  group_by(Productive, Task_item, Language, Dataset)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_grid(Dataset~Productive) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance", title = "Mean Unit Task performance by language and Productivity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

###By knower-level
```{r}
knower.pal <- brewer.pal(n = 9, "Paired")[3:9]

all.data %>%
  filter(!is.na(Knower.level))%>%
   mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "SF")%>%
  group_by(SID, Knower.level, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=Knower.level)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  ggtitle("Performance on Unit Task by language, knower-level") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  scale_fill_manual(values = count_range_pal) + 
  facet_grid(~Dataset, scale = "free_x")
```

---

##WCN
###Overall performance by language
```{r}
all.data %>%
  filter(Task == "NN")%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "none") +
  ggtitle("Overall mean correct on NN Task") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2") +
  facet_grid(~Dataset, scale = "free_x")
```

###Performance by language, productivity
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "NN")%>%
  group_by(SID, Productive, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  facet_grid(Productive~Dataset, scale = "free_x")+
  theme_bw(base_size = 13) + 
  theme(legend.position = "none") +
  ggtitle("Performance on NN Task by language, productivity") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

###Performance by count range
```{r}
count_range_pal <- brewer.pal(n = 9, "Spectral")[8:9]

all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "NN")%>%
  group_by(SID, count_range, Language, Dataset, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = count_range, y = mean, fill=Language)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  ggtitle("Performance on NN Task by language, within/outside IHC") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2") +
facet_grid(Productive~Dataset)
```

###By item, productivity
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "NN")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  group_by(Productive, Task_item, Language, Dataset)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_grid(Productive~Dataset) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance", title = "Mean WCN Task performance by language and Productivity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

###By knower level
```{r}
knower.pal <- brewer.pal(n = 9, "Paired")[3:9]

all.data %>%
  filter(!is.na(Knower.level))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "NN")%>%
  group_by(SID, Knower.level, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=Knower.level)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  ggtitle("Performance on NN Task by language, knower-level") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  scale_fill_manual(values = count_range_pal)+
  facet_grid(~Dataset, scale= "free_x")
```

---

##SF and NN together
###By-item performance - this is a mess, do it separately for India/HK
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "NN" | Task == "SF")%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  group_by(Task, Productive, Task_item, Language, Dataset)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 10) + 
  facet_grid(Task~Productive) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance", title = "Mean Unit and NN Task performance by language and Productivity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

##WPPSI
```{r, warning = FALSE}
##histogram of WPPSI scores
wppsi.ms <- all.data %>%
  filter(Task == "WPPSI")%>%
  filter(Trial_number != "Sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != "1", 
         Trial_number != '2', 
         Trial_number != '7', 
         Trial_number != '8')%>%
  mutate(Trial_number = as.numeric(as.character(Trial_number)))%>%
  group_by(SID, Language)%>%
  summarise(sum_wppsi = sum(as.numeric(as.character(Correct)), na.rm = TRUE), 
            num_trials = n())
 
 ggplot(wppsi.ms, aes(x = sum_wppsi, fill = Language)) +
   geom_histogram(binwidth = 1, colour = "black") +
   theme_bw() + 
   facet_grid(~Language)+
   scale_fill_brewer(palette = "Dark2") + 
   labs(title = "Frequency of WPPSI scores by language") +
   guides(fill = FALSE)
 
##Mean WPPSI scores 
all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "WPPSI")%>%
  filter(Trial_number != "Sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != "1", 
         Trial_number != '2', 
         Trial_number != '7', 
         Trial_number != '8')%>%
  mutate(Trial_number = as.numeric(as.character(Trial_number)))%>%
  group_by(SID, Language, Dataset)%>%
  summarise(mean = mean(sum_wppsi, na.rm=TRUE),
            sd = sd(sum_wppsi, na.rm=TRUE)) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean WPPSI score") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "none") +
  ggtitle("Mean WPPSI score by Language") +
  theme(text = element_text(size = 12)) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2")+
  facet_grid(~Dataset, scale = "free_x")
 
```


---

##IHC to NN and Unit task mean performance
```{r}
all.data %>%
  filter(Task == "SF") %>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(!is.na(Productive))%>%
  group_by(SID, IHC, Language, Dataset)%>%
  summarise(mean_unit = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = IHC, y = mean_unit, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 10) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  theme(legend.position = "bottom")+
  labs(title = "Mean Unit Task Performance and IHC by Language", x = "IHC", 
       y = "Mean Unit Task Performance")+
  facet_grid(~Dataset) +
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE)

all.data %>%
  filter(Task == "NN")%>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, IHC, Language, Dataset)%>%
  summarise(mean_nn = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = IHC, y = mean_nn, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 10) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean NN Task Performance and IHC by Language", x = "IHC", 
       y = "Mean NN Task Performance") + 
  facet_grid(~Dataset)

all.data %>%
  filter(Task == "SF") %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, IHC, Language, Productive, Dataset)%>%
  summarise(mean_unit = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = IHC, y = mean_unit, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 10) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean Unit Task Performance and IHC by Language", x = "IHC", 
       y = "Mean Unit Task Performance")+
  facet_grid(Productive~Dataset, scale = "free_x")

all.data %>%
  filter(Task == "NN")%>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, IHC, Language, Productive, Dataset)%>%
  summarise(mean_nn = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = IHC, y = mean_nn, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 10) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean NN Task Performance and IHC by Language", x = "IHC", 
       y = "Mean NN Task Performance") + 
  facet_grid(Productive~Dataset, scale = "free_x")
```


##FHC to NN and Unit task mean performance
```{r}
all.data %>%
  filter(Task == "SF") %>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(!is.na(Productive))%>%
  group_by(SID, FHC, Language, Dataset)%>%
  summarise(mean_unit = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = FHC, y = mean_unit, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 10) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean Unit Task Performance and FHC by Language", x = "FHC", 
       y = "Mean Unit Task Performance") +
  facet_grid(~Dataset)

all.data %>%
  filter(Task == "NN")%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(!is.na(Productive))%>%
  group_by(SID, FHC, Language, Dataset)%>%
  summarise(mean_nn = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = FHC, y = mean_nn, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 10) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean NN Task Performance and FHC by Language", x = "FHC", 
       y = "Mean NN Task Performance") + 
  facet_grid(~Dataset)

all.data %>%
  filter(Task == "SF") %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, FHC, Language, Productive, Dataset)%>%
  summarise(mean_unit = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = FHC, y = mean_unit, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 10) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean Unit Task Performance and FHC by Language", x = "FHC", 
       y = "Mean Unit Task Performance") +
  facet_grid(Productive~Dataset, scale = "free_x")

all.data %>%
  filter(Task == "NN")%>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, FHC, Language, Productive, Dataset)%>%
  summarise(mean_nn = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = FHC, y = mean_nn, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 10) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean NN Task Performance and FHC by Language", x = "FHC", 
       y = "Mean NN Task Performance") +
  facet_grid(Productive~Dataset, scale = "free_x")
```

##Unit performance by highest contiguous NN for each language
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "SF")%>%
  mutate(highest_contig = factor(highest_contig))%>%
  group_by(highest_contig, Language, Dataset)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = highest_contig, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 10) + 
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Highest contiguous NN", y = "Mean Unit Task performance", title = "Unit Task performance by Highest Contiguous NN") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + facet_grid(~Dataset, scale = "free_x")

```

---

#Main analyses
#Within-language analyses

###Make model analysis dfs
Note that there is a lot more variability in highest counts and highest contiguous NN than in categorical variables. I am centering age, and centering and scaling FHC, IHC, and highest contiguous NN (which has the most variability).
```{r}
##HK##
sf.hk.within <- all.data%>%
  filter(Task == "SF")%>%
  filter(Language== "Cantonese")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))
  
wcn.hk.within <- all.data%>%
  filter(Task == "NN")%>%
  filter(Language == "Cantonese")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))

##SLO##
sf.slo.within <- all.data%>%
  filter(Task == "SF")%>%
  filter(Language == "Slovenian")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

wcn.slo.within <- all.data%>%
  filter(Language == "Slovenian")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

##US
sf.us.within <- all.data%>%
  filter(Task == "SF")%>%
  filter(Language == "English")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

wcn.us.within <- all.data%>%
  filter(Language == "English")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

##English - India
sf.ind.eng.within <- all.data %>%
  filter(Task == "SF")%>%
  filter(Language == "English - India")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

wcn.ind.eng.within <- all.data %>%
  filter(Language == "English - India")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

#Hindi
sf.hindi.within <- all.data %>%
  filter(Task == "SF")%>%
  filter(Language == "Hindi")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

wcn.hindi.within <- all.data %>%
  filter(Language == "Hindi")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))


#Gujarati
sf.gujarati.within <- all.data %>%
  filter(Task == "SF")%>%
  filter(Language == "Gujarati")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

wcn.gujarati.within <- all.data %>%
  filter(Language == "Gujarati")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))
```

###Unit Task

This first set of analyses replicates, in Cantonese English and Slovenian speaking samples, analyses similar to those previously conducted on English-speaking subjects. To identify whether there is connection between counting experience and Unit Task performance for participants within particular language groups, we will conduct four initial analyses (plus the null model) within each language, predicting Unit Task performance from (1) Productivity (defined above); (2) Final Highest Count; (3) Initial Highest Count; and (4) Highest Contiguous Next Number.

All models will be logistic mixed effects models, predicting performance on the unit task (0 or 1) on a trial as a function of the following predictors, with a random intercept for subject. In R, the formula will beglmer(predicted ~ (predictor) + age + within/outside range + (1|subject), family = binomial).

In each language, after running these first four models, any predictor that significantly (p &lt;.05) predicts Unit TaskPerformance (as assessed by running a likelihood ratio test on the Null Model (Model 0) and Models 1, 2, 3, and 4) will be added into Model 5, which will be our Large model. We will construct model 5 hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 5). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.


-  Model 0 (null model): Unit.Performance ~ Within/Outside range + Age + (1|subject)
-  Model 1: Unit.Performance ~ Productivity + Within/Outside range + Age + (1|subject)
-  Model 2: Unit.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
-  Model 3: Unit.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)
-  Model 4: Unit.Performance ~ Highest.Contiguous.Next.Number + Within/Outside range + Age + (1|subject)

#Hong Kong: Within-language models, Unit Task
Build the models

##Build the models
```{r}
#base
sf.hk.within.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
#Productivity
sf.hk.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
#FHC
sf.hk.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
#IHC
sf.hk.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
#Highest contig.
sf.hk.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
```

##Hong Kong: Unit task models
```{r}
mtable.sf.hk <- mtable('Base Model' = sf.hk.within.base,
            'Model 1: Productivity' = sf.hk.within.model1,
            'Model 2: FHC' = sf.hk.within.model2,
            'Model 3: IHC' = sf.hk.within.model3,
            'Model 4: Highest Contig.' = sf.hk.within.model4,
            summary.stats = c('R-squared','F','p','N'))
mtable.sf.hk
```

##Model comparisons
###Base v. productivity
```{r}
anova(sf.hk.within.model1, sf.hk.within.base, test = 'LRT')
```

###Base v. FHC
```{r}
anova(sf.hk.within.model2, sf.hk.within.base, test = 'LRT')
```

###Base v. IHC
```{r}
anova(sf.hk.within.model3, sf.hk.within.base, test = 'LRT')
```

###Base v. Highest Contiguous NN
```{r}
anova(sf.hk.within.model4, sf.hk.within.base, test = 'LRT')
```

##Large model
We have three significant predictors of performance on the Unit task (FHC, IHC, and Highest Contiguous NN). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task.
```{r}
##IHC and Highest Contig NN##
sf.hk.within.plus1 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
sf.hk.within.plus2.hc <- glmer(Correct ~ highest_contig.c + ihc.c+ count_range + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)
sf.hk.within.plus2.fhc <- glmer(Correct ~ fhc.c + ihc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)
sf.hk.within.plus3 <- glmer(Correct ~ highest_contig.c + fhc.c + ihc.c + count_range + age.c + 
                              (1|SID), family = "binomial", data = sf.hk.within)
#comparison of all 4
anova(sf.hk.within.plus3, sf.hk.within.plus2.hc, sf.hk.within.plus2.fhc, sf.hk.within.plus1, test = 'LRT') 
mtable.sf.hk.large <- mtable('IHC alone' = sf.hk.within.plus1,
            'Highest Contig. NN + IHC' = sf.hk.within.plus2.hc,
            'FHC + IHC' = sf.hk.within.plus2.fhc,
            'Highest Contig. + FHC + IHC' = sf.hk.within.model3,
            summary.stats = c('R-squared','F','p','N'))
mtable.sf.hk.large
```


##HK Unit Task within-language results:
IHC emerges as best predictor of performance on this task.

```{r, include = FALSE}
##EXPLORE
sf.hk.within.base1 <- glmer(Correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.base1)
anova(sf.hk.within.base1, sf.hk.within.base, test = 'LRT')

sf.hk.within.prod <- glmer(Correct ~ Productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.prod)
anova(sf.hk.within.prod, sf.hk.within.model1, test = 'LRT')

sf.hk.within.fhc <- glmer(Correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.fhc)
anova(sf.hk.within.fhc, sf.hk.within.model2, test = 'LRT')

sf.hk.within.ihc <- glmer(Correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.ihc)
anova(sf.hk.within.ihc, sf.hk.within.model3, test = 'LRT')

sf.hk.within.highest_contig <- glmer(Correct ~ highest_contig.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.highest_contig)
anova(sf.hk.within.highest_contig, sf.hk.within.model4, test = 'LRT')

##compare
sf.hk.within.ihc.plus1 <- glmer(Correct ~ ihc.c + fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
anova(sf.hk.within.ihc.plus1, sf.hk.within.ihc, test = 'LRT')
```

---

#SLO: Within-language models, Unit Task
Build the models 

##Model 0 (base)
```{r}
sf.slo.within.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.base)
```

##Model 1 (Productivity): Marginally significant (*p* = .07)
```{r}
sf.slo.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model1)
anova(sf.slo.within.model1, sf.slo.within.base, test = 'LRT')
```

##Model 2 (Final Highest Count): Significant (*p* = .03)
```{r}
sf.slo.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model2)
anova(sf.slo.within.model2, sf.slo.within.base, test = 'LRT')
```

##Model 3 (Initial Highest Count): Significant (*p* = .03)
```{r}
sf.slo.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model3)
anova(sf.slo.within.model3, sf.slo.within.base, test = 'LRT')
````

##Model 4 (Highest contiguous NN): Significant predictor (*p* = .007)
```{r}
sf.slo.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within) 
summary(sf.slo.within.model4)
anova(sf.slo.within.model4, sf.slo.within.base, test = 'LRT')
```

##Large model: Comparison between FHC and Highest contiguous NN: FHC does not significantly explain additional variance in the model (*p* = .17)
Highest contiguous and Final Highest count best predictors - compare
```{r}
sf.slo.within.plus1 <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
sf.slo.within.plus2 <- glmer(Correct ~ fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
sf.slo.within.plus3 <- glmer(Correct ~ ihc.c + fhc.c + highest_contig.c + count_range + age.c + 
                               (1|SID), family = "binomial", data = sf.slo.within)
anova(sf.slo.within.plus3, sf.slo.within.plus2, sf.slo.within.plus1, test = 'LRT')

summary(sf.slo.within.plus3)
```

###SLO results (interim)
Highest contiguous NN emerges as best predictor

```{r, include = FALSE}
##EXPLORE
sf.slo.within.base1 <- glmer(Correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.base1)
anova(sf.slo.within.base1, sf.slo.within.base, test = 'LRT')

sf.slo.within.prod <- glmer(Correct ~ Productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.prod)
anova(sf.slo.within.prod, sf.slo.within.model1, test = 'LRT')

sf.slo.within.fhc <- glmer(Correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.fhc)
anova(sf.slo.within.fhc, sf.slo.within.model2, test = 'LRT')

sf.slo.within.ihc <- glmer(Correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.ihc)
anova(sf.slo.within.ihc, sf.slo.within.model3, test = 'LRT')

sf.slo.within.highest_contig <- glmer(Correct ~ highest_contig.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.highest_contig)
anova(sf.slo.within.highest_contig, sf.slo.within.model4, test = 'LRT')

##compare
sf.slo.within.highest_contig.plus1 <- glmer(Correct ~ Productive + highest_contig.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
anova(sf.slo.within.highest_contig.plus1, sf.slo.within.highest_contig, test = 'LRT')
```

--- 

#English (US): Within-language models, Unit Task
Build the models
##Model 0 (base)
```{r}
sf.us.within.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.us.within)
summary(sf.us.within.base)
```

##Model 1 (Productivity)
```{r}
sf.us.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.us.within)
summary(sf.us.within.model1)
anova(sf.us.within.model1, sf.us.within.base, test = 'LRT')
```

##Model 2 (Final Highest Count): Significant (*p* = .02)
```{r}
sf.us.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.us.within)
summary(sf.us.within.model2)
anova(sf.us.within.model2, sf.us.within.base, test = 'LRT')
```

##Model 3 (Initial Highest Count)
```{r}
sf.us.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.us.within)
summary(sf.us.within.model3)
anova(sf.us.within.model3, sf.us.within.base, test = 'LRT')
````

##Model 4 (Highest contiguous NN)
```{r}
sf.us.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.us.within) 
summary(sf.us.within.model4)
anova(sf.us.within.model4, sf.us.within.base, test = 'LRT')
```

##Large model: Comparison between FHC and Highest contiguous NN: FHC does not significantly explain additional variance in the model; Model comparison with Highest contiguous and IHC - IHC does significantly explain additional variance
Highest contiguous and Final Highest count best predictors - compare
```{r}
sf.us.within.plus1 <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             data = sf.us.within, family = "binomial")
sf.us.within.plus2 <- glmer(Correct ~ fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                             data = sf.us.within, family = "binomial")
sf.us.within.plus3 <- glmer(Correct ~ ihc.c + fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                             data = sf.us.within, family = "binomial")
anova(sf.us.within.plus3, sf.us.within.plus2, sf.us.within.plus1, test = 'LRT')
summary(sf.us.within.plus3)

sf.us.within.large <- glmer(Correct ~ ihc.c + fhc.c + count_range + age.c + (1|SID), 
                            data = sf.us.within, family = "binomial")
summary(sf.us.within.large)
```

---

#English (India): Within-language models, Unit Task (recall that these models include starting magnitude, centered)
Build the models

##Model 0 (base)
```{r}
sf.ind.eng.within.base <- glmer(Correct ~ count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within)
summary(sf.ind.eng.within.base)
```


##Model 1 (Productivity)
```{r}
sf.ind.eng.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within)
summary(sf.ind.eng.within.model1)
anova(sf.ind.eng.within.model1, sf.ind.eng.within.base, test = 'LRT')
```

##Model 2 (Final Highest Count)
```{r}
sf.ind.eng.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within)
summary(sf.ind.eng.within.model2)
anova(sf.ind.eng.within.model2, sf.ind.eng.within.base, test = 'LRT')
```

##Model 3 (Initial Highest Count)
```{r}
sf.ind.eng.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within)
summary(sf.ind.eng.within.model3)
anova(sf.ind.eng.within.model3, sf.ind.eng.within.base, test = 'LRT')
```

##Model 4 (Highest Continguous Next Number)
```{r}
sf.ind.eng.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within)
summary(sf.ind.eng.within.model4)
anova(sf.ind.eng.within.model4, sf.ind.eng.within.base, test = 'LRT')
```

##Large model

We have three/4 significant predictors of performance on the Unit task (Productivity, FHC, IHC, and Highest Contiguous NN). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task.
```{r}
##FHC and Highest Contig NN##
sf.ind.eng.within.plus1 <- glmer(Correct ~ fhc.c + count_range + age.c + starting_num.c + (1|SID), 
                             family = "binomial", 
                           data = sf.ind.eng.within)
sf.ind.eng.within.plus2 <- glmer(Correct ~ highest_contig.c + fhc.c + count_range + age.c + starting_num.c + (1|SID), 
                            family = "binomial", data = sf.ind.eng.within)
##Compare
anova(sf.ind.eng.within.plus1, sf.ind.eng.within.plus2, test = 'LRT') #highest contig currently does not add anything to the model

##FHC and IHC
sf.ind.eng.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + age.c + starting_num.c + (1|SID), 
                            family = "binomial", data = sf.ind.eng.within)
anova(sf.ind.eng.within.plus1, sf.ind.eng.within.plus2, test = 'LRT') #IHC currently doesn't add anything to the model

##FHC and Productivity
sf.ind.eng.within.plus2 <- glmer(Correct ~ Productive + fhc.c + count_range + age.c + starting_num.c + (1|SID), 
                            family = "binomial", data = sf.ind.eng.within)
anova(sf.ind.eng.within.plus1, sf.ind.eng.within.plus2, test = 'LRT') #Productivity currently doesn't add anything to the model 
```

---

#Hindi: Within-language models, Unit Task
Build the models

##Model 0 (base)
```{r}
sf.hindi.within.base <- glmer(Correct ~ count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
summary(sf.hindi.within.base)
```


##Model 1 (Productivity)
```{r}
sf.hindi.within.model1 <- glmer(Correct ~ Productive + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
summary(sf.hindi.within.model1)
anova(sf.hindi.within.model1, sf.hindi.within.base, test = 'LRT')
```

##Model 2 (Final Highest Count)
```{r}
sf.hindi.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
summary(sf.hindi.within.model2)
anova(sf.hindi.within.model2, sf.hindi.within.base, test = 'LRT')
```

##Model 3 (Initial Highest Count)
```{r}
sf.hindi.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
summary(sf.hindi.within.model3)
anova(sf.hindi.within.model3, sf.hindi.within.base, test = 'LRT')
```

##Model 4 (Highest Continguous Next Number)
```{r}
sf.hindi.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
summary(sf.hindi.within.model4)
anova(sf.hindi.within.model4, sf.hindi.within.base, test = 'LRT')
```

##Large model

IHC v. FHC v. Highest Contig
```{r}
##FHC and Highest Contig NN##
sf.hindi.within.plus1 <- glmer(Correct ~ ihc.c + count_range + age.c + starting_num.c + (1|SID),
                             family = "binomial",
                           data = sf.hindi.within)
sf.hindi.within.plus2 <- glmer(Correct ~ highest_contig.c + ihc.c + count_range + age.c + starting_num.c + (1|SID),
                            family = "binomial", data = sf.hindi.within)
##Compare
anova(sf.hindi.within.plus1, sf.hindi.within.plus2, test = 'LRT') #highest contig currently does not add anything to the model

##FHC and IHC
sf.hindi.within.plus2 <- glmer(Correct ~ fhc.c + ihc.c + count_range + age.c + starting_num.c + (1|SID),
                            family = "binomial", data = sf.hindi.within)
anova(sf.hindi.within.plus1, sf.hindi.within.plus2, test = 'LRT') #FHC marginal
```

---

#Gujarati: Within-language models, Unit Task
Build the models

##Model 0 (base)
```{r}
sf.gujarati.within.base <- glmer(Correct ~ count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
summary(sf.gujarati.within.base)
```


##Model 1 (Productivity)
```{r}
sf.gujarati.within.model1 <- glmer(Correct ~ Productive + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
summary(sf.gujarati.within.model1)
anova(sf.gujarati.within.model1, sf.gujarati.within.base, test = 'LRT')
```

##Model 2 (Final Highest Count)
```{r}
sf.gujarati.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
summary(sf.gujarati.within.model2)
anova(sf.gujarati.within.model2, sf.gujarati.within.base, test = 'LRT')
```

##Model 3 (Initial Highest Count)
```{r}
sf.gujarati.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
summary(sf.gujarati.within.model3)
anova(sf.gujarati.within.model3, sf.gujarati.within.base, test = 'LRT')
```

##Model 4 (Highest Continguous Next Number)
```{r}
sf.gujarati.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
summary(sf.gujarati.within.model4)
anova(sf.gujarati.within.model4, sf.gujarati.within.base, test = 'LRT')
```

##Large model

No large model yet
```{r, include = FALSE}
# ##FHC and Highest Contig NN##
# sf.hindi.within.plus1 <- glmer(Correct ~ ihc.c + count_range + age.c + starting_num.c + (1|SID),
#                              family = "binomial",
#                            data = sf.hindi.within)
# sf.hindi.within.plus2 <- glmer(Correct ~ highest_contig.c + ihc.c + count_range + age.c + starting_num.c + (1|SID),
#                             family = "binomial", data = sf.hindi.within)
# ##Compare
# anova(sf.hindi.within.plus1, sf.hindi.within.plus2, test = 'LRT') #highest contig currently does not add anything to the model
# 
# ##FHC and IHC
# sf.hindi.within.plus2 <- glmer(Correct ~ fhc.c + ihc.c + count_range + age.c + starting_num.c + (1|SID),
#                             family = "binomial", data = sf.hindi.within)
# anova(sf.hindi.within.plus1, sf.hindi.within.plus2, test = 'LRT') #FHC marginal
```


---

##Productivity t-test of Unit Task performance
Using the Productive/Non-Productive categorical classification outlined above, we will compare performance
between both groups on the Unit task using t-tests. We may do this by considering average performance
(averaring the 0s and 1s on each task for each participant); should doing so provide greater precision, we may also compare Highest Contiguous Number.

###HK: Marginally significant difference between groups (*p* = .08)
```{r}
#with mean performance
sf.hk.mean.ms <- sf.hk.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(sf.hk.mean.ms, Productive == "Productive")$mean, 
       subset(sf.hk.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #marginally significant difference between productive and nonproductive counters for performance on Unit Task
```

###SLO: Significant difference between groups (*p* = .0002)
```{r}
#with mean performance
sf.slo.mean.ms <- sf.slo.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(sf.slo.mean.ms, Productive == "Productive")$mean, 
       subset(sf.slo.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #significant difference in performance between productive and nonproductive counters
```

###US: Significant difference between groups 
```{r}
#with mean performance
sf.us.mean.ms <- sf.us.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(sf.us.mean.ms, Productive == "Productive")$mean, 
       subset(sf.us.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #significant difference in performance between productive and nonproductive counters
```

---

##Productivity t-test of Highest contiguous NN
###HK: Significant difference between groups (*p* = .01)
```{r}
sf.hk.mean.nn <- sf.hk.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.hk.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.hk.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```

###SLO: Significant difference between groups (*p* = .001)
```{r}
sf.slo.mean.nn <- sf.slo.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.slo.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.slo.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```


###US: Significant difference between groups 
```{r}
sf.us.mean.nn <- sf.us.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.us.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.us.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```

###India-Eng: NS
```{r}
sf.ind.eng.mean.nn <- sf.ind.eng.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.ind.eng.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.ind.eng.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```

###Hindi: Significant difference between groups  (ns)
```{r}
sf.hindi.mean.nn <- sf.hindi.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.hindi.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.hindi.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```


###Gujarati: Significant difference between groups 
```{r}
sf.gujarati.mean.nn <- sf.gujarati.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.gujarati.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.gujarati.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```


---

#WCN Task- within-language analyses, simple models

All models will be logistic mixed effects models, predicting next number performance (0 or 1) on a trial as a function of the following predictors, with a random intercept for subject. In R, the formula will be glmer(predictedSF_correct ~ (predictor) + age + within/outside range + (1|subject), family = binomial).

-  Model 0 (null model): NextNumber.Performance ~ Within/Outside range + Age + (1|subject)
-  Model 1: Next.Number.Performance ~ Productivity + Within/Outside range + Age + (1|subject)
-  Model 2: Next.Number.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
-  Model 3: Next.Number.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)

In each language, after running these first three models, any predictor that significantly (p <.05) predicted Next Number Performance (as assessed by running a likelihood ratio test on the Null Model (Model 0) and Models 1, 2, and 3) will be added into Model 6, which will be our Large model (containing all predictors that significantly predicted Next Number Task Performance in the simple models). We will construct model 6 hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 6). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

#HK: Within-language analyses, Next Number Task
Build models

##Model 0 (base)
```{r}
wcn.hk.within.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.base)


```

##Model 1 (Productivity): Not a significant predictor (*p* = .24)
```{r}
wcn.hk.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model1)
anova(wcn.hk.within.model1, wcn.hk.within.base, test = 'LRT')
```

##Model 2 (Final Highest Count): Significant predictor (*p* < .0001)
````{r}
wcn.hk.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model2)
anova(wcn.hk.within.model2, wcn.hk.within.base, test = 'LRT')
````

##Model 3 (Initial Highest Count): Significant predictor (*p* < .0001)
```{r}
wcn.hk.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model3)
anova(wcn.hk.within.model3, wcn.hk.within.base, test = 'LRT')
```

##Large Model - Comparison of FHC and IHC: Both predictors significantly explain unique variance (*p* < .0001)
We have two significant predictors of performance on the Unit task (FHC and IHC). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task. 
```{r}
##IHC and FHC##
wcn.hk.within.plus1 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.hk.within)
wcn.hk.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.hk.within)
anova(wcn.hk.within.plus2, wcn.hk.within.plus1, test = 'LRT') #Initial Highest Count explains additional variance in WCN performance
summary(wcn.hk.within.plus2)
```

```{r, include = FALSE}
###EXPLORE
wcn.hk.within.base1 <- glmer(Correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.base1)
anova(wcn.hk.within.base1, wcn.hk.within.base, test = 'LRT')
wcn.hk.within.prod <- glmer(Correct ~ Productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.prod)
anova(wcn.hk.within.prod, wcn.hk.within.model1, test = 'LRT')
wcn.hk.within.fhc <- glmer(Correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.fhc)
anova(wcn.hk.within.fhc, wcn.hk.within.model2, test = 'LRT')
wcn.hk.within.ihc <- glmer(Correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.ihc)
anova(wcn.hk.within.ihc, wcn.hk.within.model3, test = 'LRT')

#compare 
wcn.hk.within.fhc.plus <- glmer(Correct ~ ihc.c + fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
anova(wcn.hk.within.fhc.plus, wcn.hk.within.fhc, test = 'LRT')
```

---

#SLO: Within-language analyses, NN Task
Build the models

##Model 0
```{r}
wcn.slo.within.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.base)
```


##Model 1 (Productivity): Significant predictor (*p* < .0001)
```{r}
wcn.slo.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model1)
anova(wcn.slo.within.model1, wcn.slo.within.base, test = 'LRT')
```

##Model 2 (FHC): Significant predictor (*p* < .0001)
```{r}
wcn.slo.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model2)
anova(wcn.slo.within.model2, wcn.slo.within.base, test = 'LRT')
```

##Model 3 (IHC): Significant predictor (*p* < .0001)
```{r}
wcn.slo.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model3)
anova(wcn.slo.within.model3, wcn.slo.within.base, test = 'LRT')
```

##Large Model comparison: Productivity, FHC, and IHC
We have three significant predictors of performance on the Unit task (Productivity, FHC and IHC). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the NN Task. 
```{r}
##Productive and FHC##
wcn.slo.within.plus1 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.slo.within)
wcn.slo.within.plus2 <- glmer(Correct ~ Productive + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)
wcn.slo.within.plus3 <- glmer(Correct ~ ihc.c + Productive + fhc.c + count_range + age.c + 
                                (1|SID), family = "binomial", data = wcn.slo.within)
anova(wcn.slo.within.plus3, wcn.slo.within.plus2, wcn.slo.within.plus1, test = 'LRT') #Productivity does not explain additional variance
summary(wcn.slo.within.plus3)
summary(wcn.slo.within.plus1)
```

```{r, include = FALSE}
###Explore

wcn.slo.within.base1 <- glmer(Correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.base1)
anova(wcn.slo.within.base1, wcn.slo.within.base, test = 'LRT')
wcn.slo.within.prod <- glmer(Correct ~ Productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.prod)
anova(wcn.slo.within.prod, wcn.slo.within.model1, test = 'LRT')
wcn.slo.within.fhc <- glmer(Correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.fhc)
anova(wcn.slo.within.fhc, wcn.slo.within.model2, test = 'LRT')
wcn.slo.within.ihc <- glmer(Correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.ihc)
anova(wcn.slo.within.ihc, wcn.slo.within.model3, test = 'LRT')

#compare
wcn.slo.within.fhc.plus <- glmer(Correct ~ Productive + fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
anova(wcn.slo.within.fhc.plus, wcn.slo.within.fhc, test = 'LRT')
```

---

#US: Within-language analyses, NN Task
Build the models

##Model 0
```{r}
wcn.us.within.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)
summary(wcn.us.within.base)
```


##Model 1 (Productivity): Significant
```{r}
wcn.us.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)
summary(wcn.us.within.model1)
anova(wcn.us.within.model1, wcn.us.within.base, test = 'LRT')
```

##Model 2 (FHC): Significant predictor
```{r}
wcn.us.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)
summary(wcn.us.within.model2)
anova(wcn.us.within.model2, wcn.us.within.base, test = 'LRT')
```

##Model 3 (IHC): Significant predictor (*p* < .0001)
```{r}
wcn.us.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)
summary(wcn.us.within.model3)
anova(wcn.us.within.model3, wcn.us.within.base, test = 'LRT')
```

##Large Model comparison: Productivity, FHC, and IHC
We have three significant predictors of performance on the Unit task (Productivity, FHC and IHC). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the NN Task. 

###Productivity and FHC: Productivity does not explain additional variance
```{r}
##Productive and FHC##
wcn.us.within.plus1 <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.us.within)
wcn.us.within.plus2 <- glmer(Correct ~ Productive + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.us.within)
wcn.us.within.plus3 <- glmer(Correct ~ ihc.c + Productive + fhc.c + count_range + age.c + 
                               (1|SID), family = "binomial", data = wcn.us.within)
anova(wcn.us.within.plus3, wcn.us.within.plus2, wcn.us.within.plus1, test = 'LRT') #Productivity does not explain additional variance
summary(wcn.us.within.plus3)
```

---

#India English: Within-language analyses, NN task

Build the models
```{r}
#Base Model
wcn.ind.eng.within.base <- glmer(Correct ~ count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
#Productivity
wcn.ind.eng.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
#FHC
wcn.ind.eng.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
#IHC
wcn.ind.eng.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
```

##India - English WCN Models 
Summary
```{r}
mtable.ind.eng <- mtable('Base Model' = wcn.ind.eng.within.base,
            'Model 1: Productivity' = wcn.ind.eng.within.model1,
            'Model 2: FHC' = wcn.ind.eng.within.model2,
            'Model 3: IHC' = wcn.ind.eng.within.model3,
            summary.stats = c('R-squared','F','p','N'))
mtable.ind.eng
```

##Model comparisons

```{r}
anova(wcn.ind.eng.within.model1, wcn.ind.eng.within.base, test = 'LRT')
anova(wcn.ind.eng.within.model2, wcn.ind.eng.within.base, test = 'LRT')
anova(wcn.ind.eng.within.model3, wcn.ind.eng.within.base, test = 'LRT')
```

##Large Model - Comparison of FHC and IHC

```{r}
##IHC and FHC##
wcn.ind.eng.within.plus1 <- glmer(Correct ~ ihc.c + count_range + age.c + starting_num.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.ind.eng.within)
wcn.ind.eng.within.plus2 <- glmer(Correct ~ fhc.c + ihc.c + count_range + age.c + starting_num.c + (1|SID), 
                            family = "binomial", data = wcn.ind.eng.within)
anova(wcn.ind.eng.within.plus2, wcn.ind.eng.within.plus1, test = 'LRT') #FHC significantly adds to model
summary(wcn.ind.eng.within.plus2)
```

---

#Hindi: Within-language analyses, NN

##Model 0 (base)
```{r}
wcn.hindi.within.base <- glmer(Correct ~ count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                            data = wcn.hindi.within)
summary(wcn.hindi.within.base)
```

##Model 1 (Productivity): Not a significant predictor (*p* = .24)
```{r}
wcn.hindi.within.model1 <- glmer(Correct ~ Productive + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                            data = wcn.hindi.within)
summary(wcn.hindi.within.model1)
anova(wcn.hindi.within.model1, wcn.hindi.within.base, test = 'LRT')
```

##Model 2 (Final Highest Count): Significant predictor (*p* < .0001)
````{r}
wcn.hindi.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                            data = wcn.hindi.within)
summary(wcn.hindi.within.model2)
anova(wcn.hindi.within.model2, wcn.hindi.within.base, test = 'LRT')
````

##Model 3 (Initial Highest Count): Significant predictor (*p* < .0001)
```{r}
wcn.hindi.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                            data = wcn.hindi.within)
summary(wcn.hindi.within.model3)
anova(wcn.hindi.within.model3, wcn.hindi.within.base, test = 'LRT')
```

##Large Model - Comparison of FHC and IHC
 
```{r}
##IHC and FHC##
# wcn.hindi.within.plus1 <- glmer(Correct ~ ihc.c + count_range + age.c + starting_num.c + (1|SID), 
#                              family = "binomial", 
#                            data = wcn.hindi.within)
# wcn.hindi.within.plus2 <- glmer(Correct ~ fhc.c + ihc.c + count_range + age.c + starting_num.c + (1|SID), 
#                             family = "binomial", data = wcn.hk.within)
# anova(wcn.hindi.within.plus2, wcn.hindi.within.plus1, test = 'LRT') 
# summary(wcn.hk.within.plus2)
```


---

##Productivity t-test of WCN performance
Using the Productive/Non-Productive categorical classification outlined above, we will compare performance
between both groups on the Next Number task using t-tests. We may do this by considering average performance
(averaring the 0s and 1s on each task for each participant).

###HK: Significant difference between productive and nonproductive counters (*p* = .001)
```{r}
#with mean performance
wcn.hk.mean.ms <- wcn.hk.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(wcn.hk.mean.ms, Productive == "Productive")$mean, 
       subset(wcn.hk.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

###SLO: Significant difference between groups (*p* < .0001)

```{r}
#with mean performance
wcn.slo.mean.ms <- wcn.slo.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(wcn.slo.mean.ms, Productive == "Productive")$mean, 
       subset(wcn.slo.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

###US: Significant difference between groups (*p* < .0001)

```{r}
#with mean performance
wcn.us.mean.ms <- wcn.us.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(wcn.us.mean.ms, Productive == "Productive")$mean, 
       subset(wcn.us.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```


---

#Cross-linguistic comparisons
Our second set of analyses is aimed at understanding cross-linguistic differences in performance on the Unit Task. To do this, we will analyze all participants, from all language groups, in a single model. We will then construct our models from above, but will add (a) a measure of Working Memory and (b) the interaction of Initial Highest Count and Language group to each model. These models therefore allow us to test whether (a) language; (b) counting ability; or (c) some interaction between the two predict unit performance. We include Working Memory in all cross-linguistic models with the intention of taking into account baseline differences in processing across samples.

Cross-Linguistic Models:
Model 0a (the Null Model): Unit.Performance~ Language*IHC + Within/Outside range + Age + WM
+ (1|subject)
Model 1a: Unit.Performance ~ Productivity + Language*IHC + Within/Outside range + Age + WM + (1|subject)
Model 2a: Unit.Performance ~ Final.Count + Language*IHC + Within/Outside range + Age + WM + (1|subject)
Model 3a: Unit.Performance ~ Highest.Contiguous.Next.Number + Language*IHC + Within/Outside range +
Age + WM + (1|subject)
Make model dfs


We will then compare Model 0a (the Null Model) to each of the models containing measures of productivity (1a, 2a, and 3a) using a likelihood ratio test in testing whether these measures of productivity significantly explain variance in childrens performance. Should effects of Language emerge, we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects (e.g., Unit.Performance ~ Productivity + IHC + Within/Outside range + Age + WM + (1|subject)). After running the four models above, any predictor that significantly (p &lt;.05) predicted Unit Task Performance will be added into Model 6a, which will be our Large model (containing all predictors that significantly predicted Unit Task Performance in the simple models). We will construct model 6a hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 6a). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

##Make model dfs
```{r}
##HK##
sf.df.cross <- all.data %>%
  filter(Task == "SF")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))
  
wcn.df.cross <- all.data %>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))
```

---

#Unit Task: Cross linguistic models

##Model 0 (base)
```{r}
sf.cross.base <- glmer(Correct ~ Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.base)
```

##Model 1 (Productivity): Not a signficant predictor 
NOTE: Model is currently failing to converge, may need to look at optimizer
```{r}
sf.cross.model1 <- glmer(Correct ~ Productive + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.model1)
anova(sf.cross.model1, sf.cross.base, test = 'LRT')
```

##Model 2 (Final Highest Count): Not a significant predictor
```{r}
sf.cross.model2 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.model2)
anova(sf.cross.model2, sf.cross.base, test = 'LRT')
```

##Model 3 (Highest Contiguous NN): Significant predictor (*p* = .012)
```{r}
sf.cross.model3 <- glmer(Correct ~ highest_contig.c + Language*ihc.c + count_range + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.model3)
anova(sf.cross.model3, sf.cross.base, test = 'LRT')
```


---

##WCN
Our third set of analyses is aimed at understanding cross-linguistic differences in performance on the next number task. To do this, we will analyze all participants, from all language groups, in a single model. As above, we add WM, and the language by IHC interaction.

Cross-Linguistic Models
-  Model 0b (the null model): Next.Number.Performance ~ Language*IHC + Within/Outside range + Age + WM +
(1|subject)
-  Model 1b: Next.Number.Performance ~ Productivity + Language*IHC + Within/Outside range + Age + WM +
(1|subject)
-  Model 2b: Next.Number.Performance ~ Final.Count + Language*IHC + Within/Outside range + Age + WM +
(1|subject)

We will construct Model 7b hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 7b). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

###Model 0 (base)
NB - this model is currently failing to converge, may need to look at optimizer
```{r}
wcn.cross.base <- glmer(Correct ~ Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross)
summary(wcn.cross.base)


```

###Model 1 (Productivity): Significant
```{r}
wcn.cross.model1 <- glmer(Correct ~ Productive + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
summary(wcn.cross.model1)
anova(wcn.cross.model1, wcn.cross.base, test = 'LRT')
```

##Model 2 (Final Highest Count): Significant predictor
NB this model is currently failing to converge, may need to look at optimizer
```{r}
wcn.cross.model2 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross, family = "binomial")
summary(wcn.cross.model2)
anova(wcn.cross.model2, wcn.cross.base, test = 'LRT')
```

##Large model
NOTE: Models failing to converge, may need to look at optimizer
Comparing productivity and FHC
```{r}
wcn.cross.plus1 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross)
wcn.cross.plus2 <- glmer(Correct ~ Productive + fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross)
anova(wcn.cross.plus1, wcn.cross.plus2, test = 'LRT')
```


```{r, include = FALSE}
wcn.nolang.base <- glmer(Correct ~ ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial")
wcn.nolang.model1 <- glmer(Correct ~ fhc.c + ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial")
anova(wcn.nolang.model1, wcn.nolang.base, test = 'LRT') #FHC is still significant, but just barely

```

---

#Counting distribution
We plan to conduct descriptive analyses to describe the ways in which Initial Highest Count differs across
languages.
```{r}
hc.df %>%
  group_by(Language)%>%
  summarise(mean = mean(IHC, na.rm = TRUE), 
            sd = sd(IHC, na.rm = TRUE), 
            median = median(IHC, na.rm = TRUE))
```

In addition, we plan to test whether children in transparent languages can become productive with less counting experience. To test this, we will consider non-productive counters (those who were labeled as non-Productive). We will then ask whether IHC for these non-productive counters differs across languages. We will only conduct these analyses if we have at least 30 non-productive counters in each language. If count-list transparency allows children to converge on a productive count rule more quickly, then children who learn a system with a transparent-count list should move to the productive counter category on the basis of relatively less experience than children who learn a system with an opaque- count list. This predicts that, when considering non-Productive counters, initial highest count should be higher for opaque languages (like English) than for Slovenian, and higher for Slovenian than for Cantonese. The model would like this: 

Model 1: IHC ~ Language + Age + WM, data = NonProductiveCounters

###Model: Nonproductive US English and Slovenians have significantly lower IHC than Cantonese speakers
```{r}
ihc.cross <- all.data %>%
  distinct(SID, Language, Age, sum_wppsi, Productive, IHC)%>%
  filter(Productive == "Nonproductive")%>%
  mutate(Language = factor(Language))%>%
  mutate(age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale = TRUE)))

ihc.model.1 = lm(IHC ~ Language + age.c + wppsi.c, data = ihc.cross)
summary(ihc.model.1)
```

In addition, we will test whether count-list transparency allows children to acquire some degree of productivity, even before they are labeled productive counters based on their overall counting performance. To test this, we will predict Highest Contiguous Next Number from Language. If transparent languages allow children to generate a productive counting rule, speakers of these transparent languages may perform better on the Next Number task than speakers of non- transparent languages, even when only considering non-productive counters. Model 2: Highest.Contiguous.NextNumber ~ Language + Age + WM + (1|subject), data = NonProductiveCounters

###Model: No effect of Language here
```{r}
wcn.model <- all.data %>%
  distinct(SID, Language, Age, sum_wppsi, Productive, highest_contig)%>%
  filter(Productive == "Nonproductive")%>%
  mutate(Language = factor(Language))%>%
  mutate(age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale = TRUE)))

highest_contig.model <- lm(highest_contig ~ Language + age.c + wppsi.c, data = wcn.model)
summary(highest_contig.model)
```

TO-do for RMS: 
- Follow up analysis for productivity:lang interactions: In the event that, when analyzing each language group separately, we find evidence that a particular counting/productivity measure (Next Number, Final HC, Productivity) improves model fit for one language group by not another, we will conduct a follow-up analysis testing whether productivity classification interacts with language group. We will compare the model containing an interaction to one that excludes the interaction. It is important to note that our critical effect of interest is not necessarily a [Productivity Measure]:[Language Group] interaction, although finding such an interaction may be interpretable (e.g., it may suggest that productivity predicts other measures to a greater degree in some languages vs. others): ProductivityLang: Unit ~ Productivity Measure (Highest NN, FHC, Productivity classification)*Language.Group +
Language*IHC + Within/Outside range + Age + WM (1|subject)
- Exploratory analyses
- Cluster analysis...
- Frequency of error types
- Test whether modes differ across languages
- Include vs. exclude memory check failure SF trials
- Highest contiguous Successor vs. Highest contiguous NN
- Teacher survey data...
- Comparison of numbers on NN and SF
- Comparison of above and below 100 for NN and SF
- 