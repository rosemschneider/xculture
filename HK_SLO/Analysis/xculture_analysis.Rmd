---
title: "XCulture Analysis"
author: "Rose M. Schneider"
date: "8/5/2018"
output: html_document
---
##To-dos:
Make sure ANOVAs are in the right order
Unit/NN by Prod*count range interaction


#Setup
```{r, include = FALSE}
rm(list = ls())
require("knitr")
opts_knit$set(root.dir = "~/Documents/Projects/xculture/HK_SLO/") #this is specific to RMS, change accordingly
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)
library(memisc)
'%!in%' <- function(x,y)!('%in%'(x,y))
```

#Load data
##Slovenian
```{r}
#slo data
slo.full.data <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/SLO_data.csv')%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  dplyr::select(-Response_single, -Response_double, -Mem_check_1_single, -Mem_check_1_double, 
                -Mem_check_2_single, -Mem_check_2_double, - X, - X.1)%>%
  dplyr::rename(Response = Response_final, 
                Mem_check_1 = Mem_check_1_final, 
                Mem_check_2 = Mem_check_2_final, 
                Exclude_trial_reason = Exclude_trial_single_reason)%>%
  mutate(Exclude_analysis = ifelse(is.na(Exclude_analysis), 0, as.numeric(as.character(Exclude_analysis))),
         Exclude_task = ifelse(is.na(Exclude_task), 0, as.numeric(as.character(Exclude_task))), 
         Trial_number = ifelse(Trial_number == '0', "Training", as.character(Trial_number)), 
         Task_item = factor(Task_item), 
         Response = ifelse(Task == "WPPSI", as.character(Correct), as.character(Response)),
         Age = as.numeric(as.character(Age)), 
         Correct = as.integer(as.character(Correct)), 
         Mem_check_1 = as.integer(as.character(Mem_check_1)), 
         Mem_check_2 = as.integer(as.character(Mem_check_2)))
  # filter(SID != "05112018-ZA", 
  #        SID != "RT02", 
  #        SID != "RT03", 
  #        SID != "RT04", 
  #        SID != "RT05", 
  #        SID != "RT06", 
  #        SID != "RT07", 
  #        SID != "RT08", 
  #        SID != "RT09") #temporary, until double coded

#slo highest count
slo.hc <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/SLO_HC.csv')%>%
  dplyr::select(-Special_count, -IHC, -FHC)%>%
  dplyr::rename(IHC = IHC_final, 
                FHC = FHC_final, 
                Last_successful = Last_Successful)%>%
  filter(Exclude != 1)%>%
  mutate(Language = "Slovenian", 
         Last_successful = as.integer(as.character(Last_successful)))

#sanity check for hc
slo.hc %>%
  distinct(SID, IHC, FHC)%>%
  group_by(SID)%>%
  summarise(n = n())%>%
  filter(n != 1)
```

##Cantonese
```{r}
#hk data
hk.full.data <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/HK_Data.csv')%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  dplyr::select(-Response_single, -Response_double, -Mem_check_1_single, -Mem_check_1_double, 
                -Mem_check_2_single, -Mem_check_2_double, -Exclude_trial_single, 
                -Exclude_trial_double, -Unit_task_repeat_alts)%>%
  dplyr::rename(Response = Response_final, 
                Correct = Correct_final, 
                Mem_check_1 = Mem_check_1_final, 
                Mem_check_2 = Mem_check_2_final,
                Exclude_trial = Exclude_trial_final)%>%
  mutate(Age = as.numeric(as.character(Age)), 
         Correct = as.integer(as.character(Correct)), 
         Mem_check_1 = as.integer(as.character(Mem_check_1)), 
         Mem_check_2 = as.integer(as.character(Mem_check_2)), 
         Response = ifelse(Task == "WPPSI", as.character(Correct), as.character(Response)),
         Exclude_analysis_reason = ifelse(Exclude_analysis_reason == 0, "", as.character(Exclude_analysis_reason)))

#hk highest count
hk.hc <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/HK_HC.csv')%>%
  dplyr::select(-Special_count, -IHC_single, -FHC_single, -hundred.syntax, 
                -raw.count)%>%
  dplyr::rename(IHC = IHC_double, 
                FHC = FHC_double)%>%
  filter(Exclude != 1)%>%
  mutate(Language = "Cantonese")

#sanity check for hc
hk.hc %>%
  distinct(SID, IHC, FHC)%>%
  group_by(SID)%>%
  summarise(n = n())%>%
  filter(n != 1)
```

##English - US
```{r}
us.full.data <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/US_Data.csv') %>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  dplyr::select(-Response_single, -Response_double, -Mem_check_1_single, -Mem_check_2_single, 
         -Mem_check_1_double, -Mem_check_2_double, -repeated.alts, -Location)%>%
  dplyr::rename(Response = Response_final, 
                Mem_check_1 = Mem_check_1_final, 
                Mem_check_2 = Mem_check_2_final)%>%
  mutate(Age = as.numeric(as.character(Age)), 
         Mem_check_1 = as.integer(as.character(Mem_check_1)), 
         Mem_check_2 = as.integer(as.character(Mem_check_2)), 
         Correct = as.integer(as.character(Correct)),
         Exclude_task = ifelse(is.na(Exclude_task), 0, as.character(Exclude_task)), 
         Exclude_trial = as.integer(as.character(Exclude_trial)),
         Exclude_task = as.integer(Exclude_task))

#highest count
us.hc <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/US_HC.csv')%>%
  dplyr::rename(IHC = IHC_final, 
                FHC = FHC_final)%>%
  filter(Exclude != 1)%>%
  mutate(Exclude = as.integer(as.character(Exclude)))%>%
  mutate(Special_Count = ifelse(Special_Count != "0", 1, 0), 
         Special_Count = as.integer(as.character(Special_Count)), 
         IHC = as.integer(as.character(IHC)), 
         FHC = as.integer(as.character(FHC)))%>%
  dplyr::select(-Special_Count, -IHC_single, -FHC_single, -Second_coder.notes) %>%
  mutate(Last_Successful = as.integer(as.character(Last_Successful)), 
         Language = "English (US)")%>%
  dplyr::rename(Last_successful = Last_Successful, 
                After_prompt = After_Prompt)

#sanity check for hc
us.hc %>%
  distinct(SID, IHC, FHC)%>%
  group_by(SID)%>%
  summarise(n = n())%>%
  filter(n != 1)
```

##India data
```{r}
india.full.data <- read.csv('/Users/roseschneider/Documents/Projects/xculture/India/Data/India_Data.csv')%>%
  filter(SID != "CopyPasteMe",
         Language != "ChangeMe")%>%
  droplevels()%>%
  dplyr::select(-Response_single, -Response_double, -Mem_check_1_single, 
         -Mem_check_1_double, -Mem_check_2_single, -Mem_check_2_double, -Exclude_trial_single,
         -Exclude_trial_double, -Exclude_trial_reason_single,
         -Exclude_trial_double, -Exclude_trial_reason_double)%>%
  mutate(Response = ifelse(Response == "<NA>", NA, as.character(Response)),
         Language = ifelse(Language == "English", "English (India)", as.character(Language)),
         Task = ifelse(Task == "WCN", "NN", as.character(Task)),
         Trial_number = ifelse(Trial_number == "training", "Training", as.character(Trial_number)), 
         Language = factor(Language))%>%
  dplyr::select(-Unit_task_repeat_alts)

#hc
india.hc <- read.csv("/Users/roseschneider/Documents/Projects/xculture/India/Data/India_HC.csv") %>%
  filter(Exclude != "1",
           Exclude != "HELP")%>%
  mutate(Last_successful = as.integer(as.character(Last_successful)))%>%
  dplyr::select(-Special_count, -IHC_single, -FHC_single, -Experimenter_missed, 
                -Coder)%>%
  dplyr::rename(IHC = IHC_final, 
                FHC = FHC_final, 
                Exclude_reason = Exclude.reason)%>%
  mutate(Exclude = as.integer(as.character(Exclude)))

#sanity check for hc
india.hc %>%
  distinct(SID, IHC, FHC)%>%
  group_by(SID)%>%
  summarise(n = n())%>%
  filter(n != 1)
```

##Bind together
```{r, warning = FALSE}
#regular data
all.data <- bind_rows(slo.full.data, hk.full.data, us.full.data, india.full.data)%>%
  mutate(Age = round(Age, 2), 
         Agegroup = cut(Age, breaks = c(3.49, 4, 4.5, 5, 5.5, 6, 6.66), 
                        labels = c("3.5-4", "4-4.5", "4.5-5", 
                                   "5-5.5", "5.5-6", "6-6.5")))%>%
  mutate(Language = factor(Language), 
         SID = factor(SID))%>%
  filter(SID != "")%>%
  mutate(Dataset = ifelse(Language == "English (US)" |
                            Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))

##now highest count, with caps for IHC and FHC
slo.hc %<>%
  filter(Exclude != 1)%>%
  mutate(IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))

hk.hc %<>%
  filter(Exclude != 1)%>%
  mutate(IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))

us.hc %<>%
  filter(Exclude != 1)%>%
  mutate(IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))

india.hc %<>%
  mutate(IHC = as.integer(as.character(IHC)), 
         FHC = as.integer(as.character(FHC)), 
         IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))%>%
  mutate(Language = factor(Language), 
         Last_successful)

#bind hk and slo hc data
hc.df <- bind_rows(slo.hc, hk.hc, us.hc, india.hc)%>%
  mutate(Language = factor(Language))%>%
  filter(SID != "")

#get unique SIDs from HC
unique_hc <- as.vector(unique(hc.df$SID))
```

##Check to make sure everything coded as correct is actually correct
Don't need to run this anymore!!
```{r, eval = FALSE}
check.coding <- function(df) {
  tmp <- mutate(df, id = rownames(df))
  # tmp <- DF_slofulldata#slo.full.data
  
  #given
  given.check <- tmp %>%
    filter(Task == "GiveN")%>%
    mutate(Response = as.integer(as.character(Response)), 
           Task_item = as.integer(as.character(Task_item)))%>%
    mutate(Correct.check = ifelse(Response == Task_item, 1, 0))%>%
    mutate(Task_item = factor(Task_item), 
           Response = as.character(Response), 
           Correct.check = as.character(Correct.check))
  
  #sf, nn
  sf.nn.check <- tmp %>%
    filter(Task == "SF" | 
           Task == "NN")%>%
    mutate(Response = ifelse(Response == "IDK", -1000, as.character(Response)))%>%
    mutate(Response = as.integer(as.character(Response)), 
           Task_item = as.integer(as.character(Task_item)))%>%
    mutate(Correct.check = ifelse(Response == Task_item + 1, 1, 0))%>%
    dplyr::select(SID, Task, Task_item, Correct, Correct.check, Response, id)%>%
    mutate(Task_item = factor(Task_item), 
           Response = as.character(Response), 
           Correct.check = as.character(Correct.check))
  
  #wppsi
  wppsi.check <- tmp %>%
    filter(Task == "WPPSI")%>%
    mutate(Correct.check = as.character(Response))
  
  #tmp.all <- bind_rows(given.check, sf.nn.check, wppsi.check)
  tmp.all <- bind_rows(given.check, sf.nn.check, wppsi.check)%>%
    dplyr::select(id, Correct.check)
  #z <- slo.full.data
  #y <- right_join(slo.full.data, tmp.all, by = "SID")
  data.checked <- full_join(tmp, tmp.all, by = "id")%>%
    dplyr::select(-id)
  
  return(data.checked)
  
}

#add check to full data
all.data <- check.coding(all.data)

#check to make sure this worked
check <- all.data %>%
  filter(Correct != Correct.check)%>%
  dplyr::select(SID, Task, Task_item, Response, Correct, Correct.check)

#replace correct with correct check
all.data %<>%
  dplyr::select(-Correct)%>%
  dplyr::rename(Correct = Correct.check)

#mutate SID to factor
all.data %<>%
  mutate(SID = factor(SID))%>%
  mutate(Correct = as.integer(as.character(Correct)))
```

---
#Exclusions
##Global exclusions
Children were excluded from the analysis only if a) they did not complete the highest count task, or b) their exclusion was noted by the experimenter. Note that there are currently participants excluded from the Slovenian dataset due to not having enough data from the WPPSI. These children may be added back in, but we're currently in a position to replace them. 
```{r}
all.data %>%
  filter(Exclude_analysis == 1)%>%
  distinct(SID, Exclude_analysis, Exclude_analysis_reason, Language)%>%
  group_by(Language, Exclude_analysis_reason)%>%
  summarise(n = n())%>%
  kable()

#get exclude kids, exclude from hc
excluded_all_sids <- as.vector(unique(subset(all.data, Exclude_analysis == 1)$SID))

hc.df %<>%
  filter(SID %!in% excluded_all_sids)

#exclude from full dataset
all.data %<>%
  filter(Exclude_analysis != 1)

#Manual exclusions - these are participants who did not receive the correct number of trials in WPPSI. Manually excluded for now because we're in a position to replace them. 

#slovenian
all.data %<>%
filter(SID != "11072018-L",
           SID != "12072018-I",
           SID != "19072018-J",
           SID != "19072018-M",
           SID != "19072018-P",
           SID != "Naj16",
           SID != "Sol07", 
         SID != "Naj14")

all.data %<>%
  filter(!is.na(Language))%>%
  filter(SID != "")

#sanity checks
unique.sid <- all.data%>%
  distinct(SID)
# 
##check against HC
unique.hc <- as.vector(unique(hc.df$SID))
# 
unique.sid %>%
  filter(SID %!in% unique.hc)
```

###Task exclusions
TO-DO RMS: Automate this in code
Children were excluded from a given task if they did not complete at least TWO trials of that task (in addition to the training trial). In order to be considered as having completed a trial of the task, a child must at least say "I don't know."  These children were excluded manually.
```{r}
all.data %>%
  filter(Exclude_task == 1)%>%
  distinct(SID, Language, Exclude_task, Excluded_task, Exclude_task_reason)%>%
  group_by(Language, Exclude_task_reason)%>%
  summarise(n = n())%>%
  kable()

#exclude
all.data %<>%
  filter(Exclude_task != 1)

#check to make sure there aren't other kids who snuck in
check_wppsi <- all.data %>%
  filter(Task == "WPPSI")%>%
  filter(Exclude_trial != 1)%>%
  mutate(Trial_number = factor(Trial_number))%>%
  filter(Trial_number != "sample item A", 
         Trial_number != "sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != '1', 
         Trial_number != '2', 
         Trial_number != '7', 
        Trial_number != '8')%>%
  group_by(SID)%>%
  summarise(n = n())%>%
  mutate(WPPSI_exc = ifelse(n < 3, 'EXCLUDE', 'KEEP'))%>%
  filter(WPPSI_exc == 'EXCLUDE')

exclude_wppsi_SIDs <- as.vector(unique(check_wppsi$SID))

#what about for other tasks?
check_all <- all.data %>%
  filter(Trial_number != "Training")%>%
  group_by(SID, Task)%>%
  summarise(n = n())%>%
  mutate(GiveN_exc = ifelse(Task == "GiveN" & n < 2, 'EXCLUDE', 'KEEP'), 
         SF_exc = ifelse(Task == "SF" & n < 2, 'EXCLUDE', 'KEEP'), 
         NN_exc = ifelse(Task == "NN" & n < 2, 'EXCLUDE', 'KEEP'))%>%
  filter(GiveN_exc == 'EXCLUDE' |
           SF_exc == "EXCLUDE" |
           NN_exc == 'EXCLUDE')

#exclude any kids who missed manual coding
all.data %<>%
  mutate(Exclude_task = ifelse(SID %in% exclude_wppsi_SIDs, 1, as.integer(as.character(Exclude_task))))
```

##Excluded trials
Trials where a participant gave no response were excluded from analysis.
```{r}
all.data %>%
  filter(Exclude_trial == 1)%>%
  group_by(Task, Exclude_trial_reason)%>%
  summarise(n = n())

all.data %<>%
  filter(Exclude_trial != 1)

#how many trials do we have for each task?
all.data %>%
  filter(Task == "SF" | 
         Task == "NN")%>%
  group_by(Language, Task, Task_item)%>%
  summarise(n = n())
```

##Exclude practice trials for SF and NN
Practice trials are excluded from analysis. 
```{r}
#how many kids failed the practice trials on these tasks?
all.data %>%
  filter(Task == "SF" | Task == "NN")%>%
  filter(Task_item == "1", 
         Correct == 0)%>%
  group_by(Language, Task)%>%
  summarise(n = n())

#Get kids who failed NN for highest contiguous
failed.nn <- all.data %>%
  filter(Task == "NN", 
         Correct == 0, 
         Trial_number == "Training")

failed.nn.sids <- unique(as.vector(failed.nn$SID))

#exclude practice trials
all.data %<>%
  filter(Trial_number != "Training")

```

##Track exclusions
```{r, warnings = FALSE}
slo.ex <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/SLO_Exclusions.csv')
hk.ex <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/HK_Exclusions.csv')%>%
  mutate(HC = factor(HC))
us.ex <- read.csv('/Users/roseschneider/Documents/Projects/xculture/HK_SLO/Data/US_Exclusions.csv')%>%
  mutate(Age = as.numeric(as.character(Age)))
india.ex <- read.csv('/Users/roseschneider/Documents/Projects/xculture/India/Data/India_Exclusions.csv')%>%
  mutate(Age = as.numeric(as.character(Age)))

exclusions.all <- bind_rows(slo.ex, hk.ex, us.ex, india.ex)%>%
  mutate(Dataset = ifelse(Language == "Cantonese" | Language == "Slovenian" |
                            Language == "English (US)", "HK/SLO/US", "India"))%>%
  mutate(Language = factor(Language, levels = c("Cantonese", "Slovenian", "English (US)", "Hindi", 
                                                "Gujarati", "English (India)")))

#total number of kids by dataset
x <- exclusions.all %>%
  group_by(Language, Dataset)%>%
  summarise(n = n())%>%
  group_by(Language)%>%
  mutate(total.n.lang = sum(n)) %>%
  group_by(Dataset)%>%
  mutate(total.n.dataset = sum(n))

##total included
tot.incl <- exclusions.all %>%
  filter(Exclude_analysis == "0")%>%
  group_by(Language, Dataset)%>%
  summarise(n = n())%>%
  group_by(Dataset)%>%
  mutate(total.n = sum(n))

#total exclusions
y <- exclusions.all %>%
  filter(Exclude_analysis != "0")%>%
  group_by(Dataset, Exclude_analysis_reason)%>%
  summarise(n = n())%>%
  group_by(Dataset)%>%
  mutate(total.ex = sum(n))
```

#Sanity check - does anyone have crazy low number of trials?
```{r}
#total number of possible trials = 4 + 12 + 12 + 3 = 31
all.data %>%
  group_by(SID)%>%
  summarise(n = n())%>%
  mutate(prop = n/31)%>%
  filter(prop < .8)
##Decision - Indian English, excluding kids who do not have NN.

```

---

#Classifications
##CP or subset-knower
Children are classified as subset-knowers if they got all 4 numbers requested correct (on either the first or the second try).
```{r}
cp.df <- all.data %>%
  filter(Task == "GiveN")%>%
  group_by(SID)%>%
  summarise(sum_correct = sum(Correct, na.rm = TRUE))%>%
  mutate(Knower.level = ifelse(sum_correct >= 4, "CP-knower", "Subset-knower"))%>%
  dplyr::select(-sum_correct)

all.data <- full_join(all.data, cp.df, by = "SID")
```

##WPPSI score
WPPSI score is just the total correct items by participant, excluding feedback/training trials
```{r}
 #get sum per SID, add to sf and wcn for CROSS-LINGUISTIC models
 wppsi.sid <- all.data %>%
  filter(Task == "WPPSI")%>%
  filter(Exclude_trial != 1)%>%
  mutate(Trial_number = factor(Trial_number))%>%
  filter(Trial_number != "sample item A", 
         Trial_number != "sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != '1', 
         Trial_number != '2', 
         Trial_number != '7', 
        Trial_number != '8')%>%
   group_by(SID)%>%
   summarise(sum_wppsi = sum(Correct, na.rm = TRUE))

all.data <- full_join(all.data, wppsi.sid, by = "SID")
```


##Productivity
Children are classified as productive if they are able to count at least 2 decades higher than an error without making more than 3 errors along the way, OR if they are able to count to 140 without making an error.
```{r, warning = FALSE}
hc.df %<>%
  mutate(Last_successful = ifelse(Last_successful == "Is quiet", "IDK", Last_successful))%>%
  filter(Exclude != 1)%>%
  filter(SID != "CH-VC-1", 
         SID != "SR-8-MP", 
         SID != "CH-MV-14", 
         SID != 'GV-21-SB', 
         SID != 'RT09', 
         SID != 'SK-M-4-GJ')#excluding these kids because they break my productivity code

hc <- hc.df %>% # replace with your local path
  dplyr::select(SID, Last_successful, IHC, FHC, Language) %>%
  mutate_at(c('Last_successful','IHC','FHC'),
            function(col) as.integer(str_replace_all(col,'\\D',''))) %>% # some of these included '?', so i remove any char thats not a digit
  mutate(Last_successful = ifelse(is.na(Last_successful), 140, Last_successful))%>%
  filter(!is.na(IHC))

# 
# function for determining productivity
is.productive = function(subject){
  # takes as input the data for a single subject
  # RULES:
  # - counts to 120 unaided = productive
  # - after making first error, counts >= 20 higher, with no more than 3 errors on way
  if(subject$IHC[1] >= 140){
    # if they get to 120 on first try, = productive
    return(TRUE)
  } else if(subject$FHC[1] == 140 & nrow(subject) < 4) {
    return(TRUE)
  } else if(subject$FHC[1] < 140 & nrow(subject) == 1 
            & subject$FHC[1] == subject$IHC[1]) {
    return(FALSE)
  } else if((subject$FHC[1] - subject$IHC[1]) >= 20){
    # if their final is >= 20 larger than their intial...
    if(nrow(subject) < 4){
      # and they've made 3 or fewer total errors, = productive
      return(TRUE)
    } 
    else {
      for(i in 1:nrow(subject)){ # start at row 2
        # check if they ever made it >= 20 counts & <= 3 errors after an error
        runLength = 0 # they just made an error, so no post-error successes yet
        numErrors = 0 # first row was an error if it's not finalCount == 120
        prev = subject$Last_successful[i]
        for (j in i+1:nrow(subject)){ # from current row until end...
          numErrors = numErrors + 1 # new row means new error
          runLength = runLength + (subject$Last_successful[j] - prev)
          # ^ add difference between current count and last count to run length
          prev = subject$Last_successful[j] # update last count
          if(runLength >= 20 & numErrors < 4){
            # if at any point the productivity conditions are met...
            return(TRUE) # = productive
          }
        }
      }
      # productivity conditions were never met (because we got to this point) so...
      return(FALSE) # != productive
    }
  } else {
    # highest is not >= 20 greater than initial
    return(FALSE)
  }
}
# 
#make function to run for all participants
unique_SIDs <- as.vector(unique(hc.df$SID))
# 
class_prod <- function(vector) {
  temp_data <- data.frame()
  for (i in vector) {
    prod.class <- data.frame(i, is.productive(subset(hc, SID == i)))
    # print(i) # for debugging
    names(prod.class) <- c("SID", "productive")
    temp_data <- bind_rows(temp_data, prod.class)
  }
  return(temp_data)
}
# 

productive <- class_prod(unique_SIDs)%>%
  dplyr::rename(check_prod = productive)%>%
  mutate(check_prod = ifelse(check_prod == TRUE, "Productive", "Nonproductive"))

#manually add child who broke productivity code: CH-VC-1, IHC 20, FHC 56, nonproductive, 
#SR-8-MP, IHC = 19, FHC = 39, Nonproductive
#CH-MV-14, IHC = 48, FHC = 68, Nonproductive
#GV-21-SB, IHC = 20, FHC = 40, nonproductive
#RT09, IHC = 20, FHC = 43, Nonproductive
#SK-M-4-GJ, IHC = 20, FHC = 44, Nonproductive

hc %<>%
  dplyr::select(-Last_successful)

productive <- full_join(productive, hc, by = "SID")%>%
  distinct(SID, IHC, FHC, check_prod)%>%
  dplyr::rename(Productive = check_prod)

#manually add back in kids who break the code
productive <- rbind(productive, c('CH-VC-1', 'Nonproductive', 20, 56))
productive <- rbind(productive, c('SR-8-MP', 'Nonproductive', 19, 39))
productive <- rbind(productive, c('CH-MV-14', 'Nonproductive', 48, 68))
productive <- rbind(productive, c("GV-21-SB", 'Nonproductive', 20, 40))
productive <- rbind(productive, c('RT09', 'Nonproductive', 20, 43))
productive <- rbind(productive, c('SK-M-4-GJ', 'Nonproductive', 20, 44))

all.data <- full_join(all.data, productive, by = "SID")%>%
  mutate(IHC = as.integer(IHC), 
         FHC = as.integer(FHC))%>%
  filter(!is.na(Productive))

 
# # for sanity checks - trying to make sure we're not leaving people out
# unique.sid <- all.data %>%
#   distinct(SID)
# 
# unique.hc <- hc.df %>%
#   distinct(SID)
# 
# tmp <- unique.sid %>%
#   filter(SID %!in% unique.hc$SID)
# 
# l <- unique.sid %>%
#   filter(SID %!in% tmp$SID)
# 
# 
# tmp <- unique.hc %>%
#   filter(SID %in% unique.sid$SID)
```

##TEMPORARY
Re-remove Slovenians that we are manually removing for now
```{r}
all.data %<>%
filter(SID != "11072018-L",
           SID != "12072018-I",
           SID != "19072018-J",
           SID != "19072018-M",
           SID != "19072018-P",
           SID != "Naj16",
           SID != "Sol07", 
         SID != "Naj14")
```

##Highest Contiguous NN
Highest Contiguous NN is a measure of productivity. This is the highest number for which a child was correct on the Next Number task, provided that all the previous numbers had also been correct.
```{r, warning = FALSE}
#get unique ids
unique.nn <- all.data %>%
  filter(Task == "NN")%>%
  distinct(SID)

unique.nn <- as.vector(unique.nn$SID)
nextnums <- as.vector(c(5, 7, 16, 24, 52, 71, 105, 107, 116, 224, 252, 271))

#this is a function that pulls out the largest number for which a participant had a correct consecutive
get_contiguous <- function(){
  contig <- data.frame()
  for (sub in unique.nn) {
    tmp <- all.data %>%
      mutate(Task_item= as.integer(as.character(Task_item)))%>%
      filter(Task == "NN",
             SID == sub, 
             Correct == 0)%>%
      mutate(Task_item = sort(as.integer(as.character(Task_item))))
    if (length(tmp$SID) == 0) {
      highest_contig = 271
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else if (sub %in% failed.nn.sids) {
      highest_contig = 0
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else if (length(tmp$Task_item) > 0 & min(as.integer(as.character(tmp$Task_item))) == 5) {
      highest_contig = 1
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else {
      min.nn <- min(as.integer(as.character(tmp$Task_item)))
      prev_correct <- nextnums[nextnums < min.nn]
      highest_contig <- max(prev_correct)
    
      sub_contig <- data.frame(sub,
                             highest_contig)
      contig <- bind_rows(contig, sub_contig)
    }
  }
  return(contig)
}

highest_contiguous_nn <- get_contiguous()%>%
  dplyr::rename(SID = sub)

#add this to df 
all.data <- full_join(all.data, highest_contiguous_nn, by = "SID")

# #how many kids don't have a highest contiguous NN? 
# all.data %>%
#   filter(is.na(Language))
#   filter(is.na(highest_contig))%>%
#   distinct(Language, SID)%>%
#   group_by(Language)%>%
#   summarise(n = n())%>%
#   kable()

#Check - does anyone have NA for HCNN? Yes, 
all.data %>%
  filter(is.na(highest_contig))
```

##Within/outside count range
Each trial on the Unit or WCN task was determined to be either within or outside a child's unprompted count range (IHC).
```{r}
all.data %<>%
  mutate(count_range = ifelse((Task == "SF" | Task == "NN") & as.numeric(as.character(Task_item)) <= IHC, "Within", "Outside"))
```

##Productivity gradient
```{r}
all.data %<>%
  mutate(delta.hc = FHC-IHC, 
         prod.gradient = delta.hc/(140-IHC), 
         prod.gradient = ifelse(IHC == 140, 1, as.numeric(prod.gradient)))
```

---

##Memory checks - NAs to 1
Some participants have NAs rather than 1 for their first memory check. Also, if first mem check is a 0, and second is NA, change that second one to 1.
```{r}
all.data %<>%
  mutate(Task = factor(Task))%>%
  mutate(Mem_check_1 = ifelse(Task == "SF" & is.na(Mem_check_1), 1, Mem_check_1))%>%
  mutate(Mem_check_2 = ifelse(Task == "SF" & is.na(Mem_check_2) & Mem_check_1 == 0, 1, Mem_check_2))
```

---

#Demographics
```{r, warning = FALSE}
all.data %<>%
  filter(!is.na(Language))

#demos by age group, Language
all.data %>%
  distinct(SID, Language, Agegroup, Age)%>%
  group_by(Language, Agegroup)%>%
  summarise(n = n(), 
            Mean_age = mean(Age, na.rm = TRUE), 
            SD_age = sd(Age, na.rm = TRUE))%>%
  kable()

#demos by Language
all.data %>%
  distinct(SID, Language, Age)%>%
  group_by(Language)%>%
  summarise(n = n(),
            Mean_age = mean(Age, na.rm = TRUE), 
            SD_age = sd(Age, na.rm = TRUE))%>%
  kable()

#sex
all.data %>%
  distinct(SID, Language, Sex)%>%
  group_by(Language, Sex)%>%
  summarise(n = n())%>%
  group_by(Language)%>%
  mutate(total.n = sum(n))%>%
  kable()

  
#histogram of age
all.data %>%
  distinct(SID, Language, Age)%>%
ggplot(aes(x = Age, fill = Language)) +
  geom_histogram(binwidth = .5, colour = "black") +
  theme_bw() + 
  facet_wrap(~Language) + 
  theme(panel.grid.minor = element_blank()) +
  scale_x_continuous(breaks = c(3.5, 4, 4.5, 5, 5.5, 6, 6.5)) +
  scale_fill_brewer(palette = "Dark2") + 
  guides(fill = FALSE) +
  labs(y = "Count", title = "Number of children in age bin by language")
```

##Productivity by language
```{r}
all.data %>%
  distinct(SID, Language, Productive)%>%
  group_by(Language, Productive)%>%
  summarise(n = n())%>%
  kable()

all.data %<>% 
  filter(!is.na(Language))
```

#Simple log regression, prod. by Language
```{r}
class.data <- all.data %>%
  filter(Language == "English (US)" |
           Language == "Cantonese" | 
           Language == "Slovenian")%>%
  distinct(SID, Productive, Language)%>%
  mutate(Productive = factor(Productive))
  

prod.lang <- glm(Productive ~ Language, family = "binomial", data = class.data)
summary(prod.lang)

#english v. slovenian
class.data <- all.data %>%
  filter(Language == "English (US)" |
           Language == "Cantonese" | 
           Language == "Slovenian")%>%
  distinct(SID, Productive, Language)%>%
  mutate(Productive = factor(Productive), 
         Language = factor(Language, levels = c("Slovenian", "Cantonese", "English (US)")))
  

prod.lang <- glm(Productive ~ Language, family = "binomial", data = class.data)
summary(prod.lang)

##English v. Hindi/Gujarati
class.data <- all.data %>%
  filter(Language == "English (India)" |
           Language == "Hindi" | 
           Language == "Gujarati")%>%
  distinct(SID, Productive, Language)%>%
  mutate(Productive = factor(Productive), 
         Language = factor(Language, levels = c("English (India)", "Hindi", "Gujarati")))
  

prod.lang <- glm(Productive ~ Language, family = "binomial", data = class.data)
summary(prod.lang)
```

###Productivity descriptives
```{r}
productivity.pal <- c("#666666","#00b8e6")

all.data %<>%
  mutate(IHC = as.integer(IHC), 
         FHC = as.integer(FHC), 
         delta.hc = FHC-IHC, 
         prod.gradient = delta.hc/(140-IHC), 
         prod.gradient = ifelse(IHC == 140 & FHC == 140, 1, as.numeric(prod.gradient)))

all.data %>%
  filter(!is.na(Productive))%>% #filtering out cases with no productivity classification
  filter(!is.na(Language))%>%
  distinct(SID, Age, Productive, Language, IHC, FHC)%>%
  group_by(Language, Productive)%>%
  summarise(n = n(),
            mean_IHC = round(mean(IHC), 2), 
            sd_IHC = round(sd(IHC), 2), 
            median_IHC = round(median(IHC), 2), 
            mean_FHC = round(mean(FHC), 2), 
            sd_FHC = round(sd(FHC), 2), 
            median_FHC = round(median(FHC), 2))%>%
  kable()

#what about productivity gradient?
all.data %>%
  distinct(SID, Age, Productive, Language, prod.gradient, delta.hc)%>%
  group_by(Language, Productive)%>%
  summarise(n =n(), 
            mean_prod.gradient = mean(prod.gradient), 
            sd_prod.gradient = sd(prod.gradient), 
            mean_delta.hc = mean(delta.hc), 
            sd_delta.hc = sd(delta.hc))%>%
  kable()

#mean ihc/fhc by language
all.data %>%
  distinct(SID, Age, Language, IHC, FHC)%>%
  group_by(Language)%>%
  summarise(mean_IHC = mean(IHC), 
           sd_IHC = sd(IHC), 
           mean_FHC = mean(FHC), 
           sd_FHC = sd(FHC))

#how many prompts do productive and nonproductive counters need? and what kind of errors do they make?
#bind productive and hc.df 
productive %<>% 
  dplyr::select(SID, Productive)

error.freq <- full_join(hc.df, productive, by = "SID")%>%
  filter(!is.na(Last_successful))%>%
  mutate(Error_type = ifelse((Language == "Cantonese" | 
                                Language == "Slovenian" |
                                Language == "English (India)" |
                                Language == "English (US)") & Last_successful %% 10 == 9 , "Decade end", 
                             ifelse(Last_successful %% 10 == 0, "Decade beginning",
                                    ifelse(Last_successful %% 10 == 8 & (Language == "Hindi" | Language == "Gujarati"), "Hindi/Gujarati pre-decade transition", "Mid-decade"))))

#mean number of prompts by Language, productivity
mean_prompts.type <- error.freq %>%
  group_by(Language, Error_type, Productive)%>%
  summarise(n = n())%>%
  group_by(Language, Productive)%>%
  mutate(total.n = sum(n), 
            prop = n/total.n)

mean_prompts.type.prod <- error.freq %>%
  group_by(Language, Error_type, Productive)%>%
  filter(Productive == "Productive")%>%
  summarise(n = n())%>%
  group_by(Language, Productive)%>%
  mutate(total.n = sum(n), 
            prop = n/total.n)

mean_prompts.type.nonprod <- error.freq %>%
  group_by(Language, Error_type, Productive)%>%
  filter(Productive == "Nonproductive")%>%
  summarise(n = n())%>%
  group_by(Language, Productive)%>%
  mutate(total.n = sum(n), 
            prop = n/total.n)

#frequency of error types
#exp. 1
# mean_prompts.type %>%
#   filter(!is.na(Error_type), 
#          Language == "English (US)" |
#            Language == "Cantonese" | 
#            Language == "Slovenian")%>%
#   ggplot(aes(x = Error_type, y = prop, fill = Productive)) + 
#   geom_bar(stat = "identity") +
#   theme_bw(base_size = 13) + 
#   facet_grid(~Language) +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1), 
#         panel.grid.minor = element_blank(),
#         panel.grid.major = element_blank(), 
#         legend.position = "bottom") +
#   scale_fill_manual(values = productivity.pal) + 
#   labs(x = "Error type", y = "Proportion of errors")
# 
# #exp. 2
# mean_prompts.type %>% 
#   filter(!is.na(Error_type))%>%
#   filter(Language == "English (US)" |
#            Language == "English (India)" |
#            Language == "Hindi" |
#            Language == "Gujarati")%>%
#   ggplot(aes(x = Error_type, y = prop, fill = Productive)) + 
#   geom_bar(stat = "identity") +
#   theme_bw(base_size = 13) + 
#   facet_grid(~Language, scale = "free_x") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1), 
#         panel.grid.minor = element_blank(),
#         panel.grid.major = element_blank(), 
#         legend.position = "bottom") +
#   scale_fill_manual(values = productivity.pal) + 
#   labs(x = "Error type", y = "Proportion of errors")
```

#Where are errors happening? - in progress, how can we visualize these?
#IDEA - frequency by decade, frequency within decade
```{r}
error.freq.decade <- error.freq %>%
  mutate(error.decade = ifelse(Last_successful < 10, 0, 
                               ifelse(Last_successful >= 10 & Last_successful < 20, 10, 
                                      ifelse(Last_successful >= 20 & Last_successful < 30, 20, 
                                             ifelse(Last_successful >= 30 & Last_successful < 40, 30, 
                                                    ifelse(Last_successful >=40 & Last_successful < 50, 40, 
                                                           ifelse(Last_successful >= 50 & Last_successful < 60, 50, 
                                                                  ifelse(Last_successful >= 60 & Last_successful < 70, 60, 
                                                                         ifelse(Last_successful >= 70 & Last_successful < 80, 70, 
                                                                                ifelse(Last_successful >= 80 & Last_successful < 90, 80, 
                                                                                       ifelse(Last_successful >= 90 & Last_successful < 100, 90, 
                                                                                              ifelse(Last_successful >= 100 & Last_successful < 110, 100, 
                                                                                                     ifelse(Last_successful >= 110 & Last_successful < 120, 110, 
                                                                                                            ifelse(Last_successful >= 120 & Last_successful < 130, 120,130)))))))))))))) %>%
  mutate(error.base = (error.decade - Last_successful) * -1, 
         error.base = ifelse(Last_successful == 140, 0, as.numeric(error.base)))

error.freq.decade %>%
  filter(Language == "Cantonese" | 
           Language == "English (US)" |
           Language == "Slovenian")%>%
  mutate(Language = factor(Language, levels = c("English (US)", "Slovenian", "Cantonese")), 
         Productive = factor(Productive, levels = c("Productive", "Nonproductive"))) %>%
  mutate(error.decade = factor(error.decade, levels = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 
                                                        90, 100, 110, 120, 130)),
         error.base = factor(error.base))%>%
  mutate(Lang.prod = paste0(as.character(Language), " ", as.character(Productive), collapse = NULL))%>%
  group_by(Language, Productive, error.decade)%>%
  summarise(n = n())%>% 
  group_by(Language, Productive)%>%
  mutate(total.n = sum(n), 
         prop = n/total.n)%>%
  mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
  ggplot(aes(x = error.decade, y = Language)) +
  geom_tile(aes(fill = round(prop, 2))) +
  geom_text(aes(label = as.character(round(prop, 2))), 
            size = 3.5) +
  coord_equal() +
  scale_fill_gradient2(low = "white", high = "red", "Proportion") + 
  theme_bw(base_size = 13) + 
  labs(x = "Decade of error") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "bottom", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  facet_grid(rows = vars(Productive))

error.freq.decade %>%
  filter(Language == "Hindi" | 
           Language == "English (India)" |
           Language == "English (US)" |
           Language == "Gujarati")%>%
  mutate(Language = factor(Language, levels = c("English (US)", "English (India)", "Hindi", "Gujarati")), 
         Productive = factor(Productive, levels = c("Productive", "Nonproductive"))) %>%
  mutate(error.decade = factor(error.decade, levels = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 
                                                        90, 100, 110, 120, 130)),
         error.base = factor(error.base))%>%
  mutate(Lang.prod = paste0(as.character(Language), " ", as.character(Productive), collapse = NULL))%>%
  group_by(Language, Productive, error.decade)%>%
  summarise(n = n())%>% 
  group_by(Language, Productive)%>%
  mutate(total.n = sum(n), 
         prop = n/total.n)%>%
  ggplot(aes(x = error.decade, y = Language)) +
  geom_tile(aes(fill = round(prop, 2))) +
  geom_text(aes(label = as.character(round(prop, 2))), 
            size = 3.5) +
  coord_equal() +
  scale_fill_gradient2(low = "white", high = "red", "Proportion") + 
  theme_bw(base_size = 13) + 
  labs(x = "Decade of error") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "bottom", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  facet_grid(rows = vars(Productive))

###woooo now let's do it for units
error.freq.decade %>%
  filter(Last_successful <= 140)%>% #filter out trials where kid kept going beyond 140
  filter(Language == "Cantonese" | 
           Language == "English (US)" |
           Language == "Slovenian")%>%
  mutate(Language = factor(Language, levels = c("English (US)", "Slovenian", "Cantonese")), 
         Productive = factor(Productive, levels = c("Productive", "Nonproductive"))) %>%
  mutate(error.base = factor(error.base))%>%
  mutate(Lang.prod = paste0(as.character(Language), " ", as.character(Productive), collapse = NULL))%>%
  group_by(Language, Productive, error.base)%>%
  summarise(n = n())%>% 
  group_by(Language, Productive)%>%
  mutate(total.n = sum(n), 
         prop = n/total.n)%>%
  mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
  ggplot(aes(x = error.base, y = Language)) +
  geom_tile(aes(fill = round(prop, 2))) +
  geom_text(aes(label = as.character(round(prop, 2))), 
            size = 3.5) +
  coord_equal() +
  scale_fill_gradient2(low = "white", high = "red", "Proportion") + 
  theme_bw(base_size = 13) + 
  labs(x = "Unit of error") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "bottom", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  facet_grid(rows = vars(Productive))

error.freq.decade %>%
  filter(Last_successful <= 140)%>% #filter out trials where kid kept going beyond 140
  filter(Language == "Hindi" | 
           Language == "English (US)" |
           Language == "English (India)" |
           Language == "Gujarati")%>%
  mutate(Language = factor(Language, levels = c("English (US)", "English (India)", "Hindi", "Gujarati")), 
         Productive = factor(Productive, levels = c("Productive", "Nonproductive"))) %>%
  mutate(error.base = factor(error.base))%>%
  mutate(Lang.prod = paste0(as.character(Language), " ", as.character(Productive), collapse = NULL))%>%
  group_by(Language, Productive, error.base)%>%
  summarise(n = n())%>% 
  group_by(Language, Productive)%>%
  mutate(total.n = sum(n), 
         prop = n/total.n)%>%
  mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
  ggplot(aes(x = error.base, y = Language)) +
  geom_tile(aes(fill = round(prop, 2))) +
  geom_text(aes(label = as.character(round(prop, 2))), 
            size = 3.5) +
  coord_equal() +
  scale_fill_gradient2(low = "white", high = "red", "Proportion") + 
  theme_bw(base_size = 13) + 
  labs(x = "Unit of error") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "bottom", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  facet_grid(rows = vars(Productive))
```

##How many errors on average by language?
```{r}
error.freq %>%
  filter(Last_successful != 140)%>%
  group_by(SID, Language, Productive)%>%
  summarise(n = n())%>%
  group_by(Language, Productive)%>%
  summarise(mean_prompts = mean(n, na.rm = TRUE),
            sd_prompts = sd(n, na.rm = TRUE))%>%
  kable()
```

#Prod gain and IHC by language
```{r}
all.data %>%
  distinct(SID, Language, IHC, FHC, Productive, prod.gradient)%>%
  ggplot(aes(x = prod.gradient, y = IHC, colour = Productive)) +
  geom_point() + 
  theme_bw() +
  facet_wrap(~Language, ncol = 2)
```

##Scatterplot of Unit and prod.gain
```{r}
all.data %>%
  filter(Task == "SF")%>%
  group_by(SID, Language, Productive, prod.gradient)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = prod.gradient, y = mean)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_bw() +
  facet_wrap(~Language, ncol = 2)
  
```

---

#Task visualizations
##Highest count
###Histogram Initial and Final Highest Count

```{r}
unique.hc.data <- all.data %>%
  distinct(SID, IHC, FHC, Productive, Language, Dataset)%>%
  gather(IHC_FHC,highest_count, IHC:FHC)%>%
  mutate(highest_count = as.integer(highest_count), 
         IHC_FHC = factor(IHC_FHC, levels = c("IHC", "FHC"), 
                          labels = c("Initial Highest Count", "Final Highest Count")))

#Initial/Final, HK/SLO/US
unique.hc.data %>%
  filter(Language == "English (US)" |
           Language == "Cantonese" |
           Language == "Slovenian")%>%
ggplot(aes(x=highest_count, fill=Productive)) + 
  geom_histogram(binwidth = 10, colour = "black") +
  theme_bw(base_size = 10)+
  facet_grid(IHC_FHC~Language) +
  scale_x_continuous(breaks = seq(0, 140, 10))+
  scale_fill_manual(values = productivity.pal) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.minor = element_blank(), 
        legend.title = element_blank())+
  theme(legend.position = "bottom") + 
  labs(x = "Highest count", y = "Frequency")

#Initial/Final, India
unique.hc.data %>%
  filter(Dataset == "India")%>%
ggplot(aes(x=highest_count, fill=Productive)) + 
  geom_histogram(binwidth = 10, colour = "black") +
  theme_bw(base_size = 10)+
  facet_grid(IHC_FHC~Language) +
  scale_x_continuous(breaks = seq(0, 140, 10))+
  scale_fill_manual(values = productivity.pal) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.minor = element_blank(), 
        legend.title = element_blank()) +
  theme(legend.position = "bottom") + 
  labs(x = "Highest count", y = "Frequency")

```


###Scatterplot of IHC and FHC
```{r}
initial_final <- all.data %>%
  filter(!is.na(Productive))%>%
  distinct(SID, Language, IHC, FHC, Productive, Dataset, prod.gradient, delta.hc)%>%
  mutate(IHC = as.numeric(IHC), 
         FHC = as.numeric(FHC))

#IHC/FHC scatter, HK/SLO/US
initial_final %>%
  filter(Language == "English (US)" |
           Language == "Cantonese" |
           Language == "Slovenian")%>%
ggplot(aes(x = IHC, y = FHC, 
                          color = Productive)) +
  geom_point(size = 1) + geom_jitter(width = .1) +
  labs(x = "Initial highest count", y = "Final highest count", 
                      color = "", title = "") +
  theme_bw(base_size = 13) + 
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) + 
  theme(panel.grid.minor = element_blank(), 
        legend.position = "bottom", 
        legend.text = element_text(size = 8)) + 
  facet_wrap(~Language, ncol = 3) + 
  scale_colour_manual(values = productivity.pal) +
  theme(legend.position = "bottom") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#IHC/FHC scatter, India
initial_final %>%
  filter(Language == "English (US)" |
           Language == "English (India)" |
           Language == "Hindi" |
           Language == "Gujarati")%>%
ggplot(aes(x = IHC, y = FHC, 
                          color = Productive)) +
  geom_point(size = 1) + geom_jitter(width = .1) +
  labs(x = "Initial highest count", y = "Final highest count", 
                      color = "", title = "") +
  theme_bw(base_size = 13) + 
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) + 
  theme(panel.grid.minor = element_blank(), 
        legend.position = "bottom", 
        legend.text = element_text(size = 8)) + 
  facet_wrap(~Language, ncol = 4) + 
  scale_colour_manual(values = productivity.pal) +
  theme(legend.position = "bottom") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


#Gaussian mixture modeling
##Test for multiple modes, quantify each mode
First, get density of IHC in each language
```{r}
initial_final %>%
  dplyr::select(IHC, Language)%>%
  mutate(Dataset = ifelse(Language == "Cantonese" |
                            Language == "Slovenian" |
                            Language == "English (US)", "HK/SLO/US", "India"))%>%
  ggplot(aes(x = IHC, colour= Language)) + geom_density(adjust = .3) + 
  scale_x_continuous(breaks = seq(0, 140, 10)) +
  facet_grid(~Dataset) +
  theme_bw() +
  theme(legend.position = "bottom") +
  scale_colour_brewer(palette = "Dark2")
```

##Get number of clusters (modes) for each language, mean and variance of each cluster
```{r}
library(mclust)
#Cantonese
cant.df <- initial_final %>%
  filter(Language == "Cantonese")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(cant.df)
plot(BIC)

summary(BIC)
mod.cant <- Mclust(cant.df, x = BIC)
summary(mod.cant, parameters = TRUE)

plot(mod.cant, what = "classification")

#Slovenian
slo.df <- initial_final %>%
  filter(Language == "Slovenian")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(slo.df)
plot(BIC)

summary(BIC)
mod.slo <- Mclust(slo.df, x = BIC)
summary(mod.slo, parameters = TRUE)

plot(mod.slo, what = "classification")

#English
us.df <- initial_final %>%
  filter(Language == "English (US)")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(us.df)
plot(BIC)

summary(BIC)
mod.us <- Mclust(us.df, x = BIC)
summary(mod.us, parameters = TRUE)

plot(mod.us, what = "classification")

#Hindi
hindi.df <- initial_final %>%
  filter(Language == "Hindi")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(hindi.df)
plot(BIC)

summary(BIC)
mod.hindi <- Mclust(hindi.df, x = BIC)
summary(mod.hindi, parameters = TRUE)

plot(mod.hindi, what = "classification")

#Gujarati
gujarati.df <- initial_final %>%
  filter(Language == "Gujarati")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(gujarati.df)
plot(BIC)

summary(BIC)
mod.gujarati <- Mclust(gujarati.df, x = BIC)
summary(mod.gujarati, parameters = TRUE)

plot(mod.gujarati, what = "classification")

#Indian English
ind.eng.df <- initial_final %>%
  filter(Language == "English (India)")%>%
  dplyr::select(IHC)

BIC <- mclustBIC(ind.eng.df)
plot(BIC)

summary(BIC)
mod.ind.eng <- Mclust(ind.eng.df, x = BIC)
summary(mod.ind.eng, parameters = TRUE)

plot(mod.ind.eng, what = "classification")
```

##Test for multiple modes, quantify each mode - FHC
First, get density of FHC in each language
```{r}
initial_final %>%
  dplyr::select(FHC, Language)%>%
  mutate(Dataset = ifelse(Language == "Cantonese" |
                            Language == "Slovenian" |
                            Language == "English (US)", "HK/SLO/US", "India"))%>%
  ggplot(aes(x = FHC, colour= Language)) + geom_density(adjust = .3) + 
  scale_x_continuous(breaks = seq(0, 140, 10)) +
  facet_grid(~Dataset) +
  theme_bw() +
  theme(legend.position = "bottom") +
  scale_colour_brewer(palette = "Dark2")
```

##Get number of clusters (modes) for each language, mean and variance of each cluster
```{r}
library(mclust)
#Cantonese
cant.df <- initial_final %>%
  filter(Language == "Cantonese")%>%
  dplyr::select(FHC)

BIC <- mclustBIC(cant.df)
plot(BIC)

summary(BIC)
mod.cant <- Mclust(cant.df, x = BIC)
summary(mod.cant, parameters = TRUE)

plot(mod.cant, what = "classification")

#Slovenian
slo.df <- initial_final %>%
  filter(Language == "Slovenian")%>%
  dplyr::select(FHC)

BIC <- mclustBIC(slo.df)
plot(BIC)

summary(BIC)
mod.slo <- Mclust(slo.df, x = BIC)
summary(mod.slo, parameters = TRUE)

plot(mod.slo, what = "classification")

#English
us.df <- initial_final %>%
  filter(Language == "English (US)")%>%
  dplyr::select(FHC)

BIC <- mclustBIC(us.df)
plot(BIC)

summary(BIC)
mod.us <- Mclust(us.df, x = BIC)
summary(mod.us, parameters = TRUE)

plot(mod.us, what = "classification")

#Hindi
hindi.df <- initial_final %>%
  filter(Language == "Hindi")%>%
  dplyr::select(FHC)

BIC <- mclustBIC(hindi.df)
plot(BIC)

summary(BIC)
mod.hindi <- Mclust(hindi.df, x = BIC)
summary(mod.hindi, parameters = TRUE)

plot(mod.hindi, what = "classification")

#Gujarati
gujarati.df <- initial_final %>%
  filter(Language == "Gujarati")%>%
  dplyr::select(FHC)

BIC <- mclustBIC(gujarati.df)
plot(BIC)

summary(BIC)
mod.gujarati <- Mclust(gujarati.df, x = BIC)
summary(mod.gujarati, parameters = TRUE)

plot(mod.gujarati, what = "classification")

#Indian English
ind.eng.df <- initial_final %>%
  filter(Language == "English (India)")%>%
  dplyr::select(FHC)

BIC <- mclustBIC(ind.eng.df)
plot(BIC)

summary(BIC)
mod.ind.eng <- Mclust(ind.eng.df, x = BIC)
summary(mod.ind.eng, parameters = TRUE)

plot(mod.ind.eng, what = "classification")
```

#Identifying clusters from IHC-FHC by language, predicting Unit from cluster membership
```{r}
#make a function to identify cluster membership
prod.clust <- function(df) {
  languages <- c("English (US)", "English (India)", "Hindi", "Gujarati", "Slovenian", "Cantonese")
  
  all.clust <- data.frame()
  for (lang in languages) {
    #filter down to correct language
    tmp.df <- df %>%
      filter(Language == lang)%>%
      distinct(SID, IHC, FHC)%>%
      dplyr::select(-SID)
    
    #run cluster analysis
    BIC <- mclustBIC(tmp.df)
    tmp.mclust <- Mclust(tmp.df, x = BIC)
    tmp.df$CLUST <- tmp.mclust$classification
    tmp.df$id <- row.names(tmp.df)
    
    #add SIDs back in
    tmp.sids <- df %>%
      filter(Language == lang)%>%
      distinct(SID, IHC, FHC)
    
    tmp.sids$id <- row.names(tmp.sids)
    
    tmp.all <- right_join(tmp.sids, tmp.df, by = "id")
    tmp.all$Language <- lang
    
    #add to large df to get back at end
    all.clust <- bind_rows(all.clust, tmp.all)
  }
  return(all.clust)
}

clusters <- prod.clust(all.data)%>%
  dplyr::select(SID, IHC.x, FHC.x, CLUST, Language)%>%
  dplyr::rename(IHC = IHC.x, 
                FHC = FHC.x)

#add clusters to all.data
all.data <- full_join(all.data, clusters, by = "SID")

check <- all.data %>%
  filter(IHC.x != IHC.y |
           FHC.x != FHC.y) # all good

all.data %<>%
  dplyr::select(-IHC.y, -FHC.y, -Language.y)%>%
  dplyr::rename(IHC = IHC.x,
                FHC = FHC.x, 
                Language = Language.x)

```


---

##Unit Task
###How many kids failed the memory checks in each dataset by number
```{r}
#for SF
sf.df <- all.data %>%
  filter(Task == "SF")%>%
  mutate(mem_check_status = ifelse((Mem_check_1 == 1 & is.na(Mem_check_2)), "Needed_1_passed_1",
                                    ifelse((Mem_check_1 == 0 & Mem_check_2 == 0), "Needed_2_failed_2",
                                           ifelse((Mem_check_1 == 1 & Mem_check_2 == 1),
                                                  "unclear_pass1_pass2",
                                                  ifelse((Mem_check_1 == 1 & Mem_check_2 == 0),
                                                         "unclear_passed1_failed2",
                                                         ifelse((Mem_check_1 == 0 & Mem_check_2 == 1),
                                                                "failed1_passed2", "other"))))))

#by number
sf.mem.num.ms <- sf.df %>%
  mutate(Task_item = factor(Task_item, levels = c("5", '7', '16', '24', '52', '71', '105', '107', '116', '224', '252', '271')))%>%
  filter(!is.na(Productive))%>%
  group_by(Task_item, mem_check_status, Language, Productive)%>%
  summarise(n = n())

ggplot(subset(sf.mem.num.ms), aes(x = Task_item, y = n, fill = mem_check_status)) + 
  geom_bar(stat = "identity") + 
  facet_grid(Productive~Language) +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Number queried", y = "Number of trials", title = "Memory checks by number in Unit Task")
```

###Overall performance by Language
```{r}
all.data %>%
  filter(Task == "SF")%>%
 mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, Language, Dataset, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black", 
               show.legend = FALSE) +
  geom_violin(alpha = .1, 
              show.legend = FALSE) +
  guides(shape = "none") + 
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  ggtitle("Overall mean correct on Unit Task") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2") +
  scale_colour_manual(values = productivity.pal) +
  facet_grid(~Dataset, scale = "free_x")
```

###With individual prod. points
```{r}
india.pal <- c("#E7298A","#66A61E","#E6AB02", "#D95F02")

#HK/SLO/US
all.data %>%
  filter(Task == "SF")%>%
  filter(Dataset == "HK/SLO/US") %>%
  group_by(SID, Language, Dataset, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black", 
               show.legend = FALSE) +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  geom_point(aes(x = Language, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=2,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  guides(shape = "none") + 
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  # ggtitle("Overall mean correct on Unit Task") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2", guide = "none") +
  scale_colour_manual(values = productivity.pal) +
  guides(size = "none")

#India
all.data %>%
  filter(Task == "SF")%>%
  filter(Language == "English (US)" |
           Language == "Hindi" |
           Language == "Gujarati" |
           Language == "English (India)") %>%
  mutate(Language = factor(Language, levels = c("Hindi", "Gujarati", "English (India)", "English (US)")))%>%
  group_by(SID, Language, Dataset, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black", 
               show.legend = FALSE) +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  geom_point(aes(x = Language, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=2,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  guides(shape = "none") + 
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  # ggtitle("Overall mean correct on Unit Task") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = india.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal) +
  guides(size = "none")
```

###Performance by language, productivity
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "SF")%>%
  group_by(SID, Productive, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  facet_grid(Productive~Dataset, scale = "free_x")+
  theme_bw() + 
  theme(legend.position = "none") +
  ggtitle("Performance on Unit Task by language, productivity") +
  theme(text = element_text(size = 12)) +
  ylim(0, 1.0) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank())



```

####With individual prod points
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "SF", 
         Dataset == "HK/SLO/US")%>%
  group_by(SID, Productive, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  geom_violin(alpha = .1) +
  geom_point(aes(x = Language, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  facet_grid(~Productive, scale = "free_x")+
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  # ggtitle("Performance on Unit Task by language, productivity") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2", guide = "none") +
  scale_colour_manual(values = productivity.pal) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#India
all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "SF",
           Language == "English (US)" |
           Language == "Hindi" |
           Language == "Gujarati" |
           Language == "English (India)") %>%
  mutate(Language = factor(Language, levels = c("Hindi", "Gujarati", "English (India)", "English (US)")))%>%
  group_by(SID, Productive, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  geom_violin(alpha = .1) +
  geom_point(aes(x = Language, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  facet_grid(~Productive, scale = "free_x")+
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  # ggtitle("Performance on Unit Task by language, productivity") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = india.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

###By productivity and count range
####All together
```{r}
all.data %>%
  filter(Task == "SF")%>%
 mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, count_range, Language, Productive, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Language)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black", 
               show.legend = FALSE) +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Language), 
             size=1.5,
             alpha = .9,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE) +
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 10) + 
  theme(legend.position = "bottom") +
  ggtitle("Performance on Unit Task by language, within/outside IHC") +
  theme(text = element_text(size = 10)) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2", guide = "none") + 
  scale_colour_manual(values = productivity.pal) +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom") +
  facet_grid(~Dataset) 
  
```

####Split by productivity
```{r}
all.data %>%
  filter(Task == "SF")%>%
 mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, count_range, Language, Productive, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Language)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black", 
               show.legend = FALSE) +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Language), 
             size=1.5,
             alpha = .9,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE) +
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 10) + 
  theme(legend.position = "bottom") +
  ggtitle("Performance on Unit Task by language, within/outside IHC") +
  theme(text = element_text(size = 10)) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2", guide = "none") + 
  scale_colour_manual(values = productivity.pal) +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom") +
  facet_grid(Dataset~Productive) 

#India
all.data %>%
  filter(Task == "SF",
           Language == "English (US)" |
           Language == "Hindi" |
           Language == "Gujarati" |
           Language == "English (India)") %>%
  mutate(Language = factor(Language, levels = c("Hindi", "Gujarati", "English (India)", "English (US)")))%>%
  group_by(SID, count_range, Language, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Language)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black", 
               show.legend = FALSE) +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Language), 
             size=1.5,
             alpha = .9,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE) +
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 10) + 
  theme(legend.position = "bottom") +
  theme(text = element_text(size = 10)) +
  ylim(0, 1.0) +
  scale_fill_manual(values = india.pal, guide = "none") + 
  scale_colour_manual(values = productivity.pal) +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom", 
        legend.title = element_blank()) +
  facet_grid(~Productive) 
```

###Item performance by productivity, Unit Task - need to remap colors
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
   mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "SF", 
         Dataset != "India")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  group_by(Productive, Task_item, Language, Dataset)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_grid(~Productive) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

all.data %>%
  filter(!is.na(Productive))%>%
   mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "SF", 
         Dataset == "India")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  group_by(Productive, Task_item, Language, Dataset)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_grid(Dataset~Productive) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance", title = "Mean Unit Task performance by language and Productivity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

###By knower-level
```{r}
knower.pal <- brewer.pal(n = 9, "Paired")[3:9]

all.data %>%
  filter(!is.na(Knower.level))%>%
   mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "SF")%>%
  group_by(SID, Knower.level, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=Knower.level)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  ggtitle("Performance on Unit Task by language, knower-level") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = knower.pal) + 
  facet_grid(~Dataset, scale = "free_x")
```

---

##WCN
###Overall performance by language
####With individual prod. points
```{r}
all.data %>%
  filter(Task == "NN")%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, Language, Dataset, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black", 
               show.legend = FALSE) +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  geom_point(aes(x = Language, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=2,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  guides(shape = "none") + 
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  ggtitle("Overall mean correct on NN Task") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2", guide = "none") +
  scale_colour_manual(values = productivity.pal) +
  facet_grid(~Dataset, scale = "free_x") + 
  guides(size = "none")
```

####Without prod. points
```{r}
all.data %>%
  filter(Task == "NN")%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, Language, Dataset, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black", 
               show.legend = FALSE) +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  guides(shape = "none") + 
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  ggtitle("Overall mean correct on NN Task") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2", guide = "none") +
  facet_grid(~Dataset, scale = "free_x") 
```

###Performance by language, productivity
####With individual prod. points
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "NN", 
         Dataset == "HK/SLO/US")%>%
  group_by(SID, Productive, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  geom_violin(alpha = .1) +
  geom_point(aes(x = Language, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9, 
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  facet_grid(~Productive, scale = "free_x")+
  theme_bw(base_size = 10) + 
  theme(legend.position = "bottom") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2", guide = "none") +
  scale_colour_manual(values = productivity.pal) + 
  theme(axis.text.x = element_text(angle = 25, hjust = 1))

#India
all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "NN", 
         Language == "English (India)" |
           Language == "Hindi" |
           Language == "Gujarati" |
           Language == "English (US)")%>%
  mutate(Language = factor(Language, levels = c("Hindi", "Gujarati", "English (India)", "English (US)")))%>%
  group_by(SID, Productive, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  geom_violin(alpha = .1) +
  geom_point(aes(x = Language, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9, 
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  facet_grid(~Productive, scale = "free_x")+
  theme_bw(base_size = 10) + 
  theme(legend.position = "bottom") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = india.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal) + 
  theme(axis.text.x = element_text(angle = 25, hjust = 1))
  
  
```

####Without prod. points
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "NN")%>%
  group_by(SID, Productive, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  facet_grid(Productive~Dataset, scale = "free_x")+
  theme_bw(base_size = 13) + 
  theme(legend.position = "none") +
  ggtitle("Performance on NN Task by language, productivity") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank()) +
  ylim(0, 1.0) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

###Performance by count range
```{r}
count_range_pal <- brewer.pal(n = 9, "Spectral")[8:9]

all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "NN")%>%
  group_by(SID, count_range, Language, Dataset, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = count_range, y = mean, fill=Language)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  ggtitle("Performance on NN Task by language, within/outside IHC") +
  theme(text = element_text(size = 12),
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom") +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2") +
facet_grid(Productive~Dataset)
```

####With prod. points, split by productivity
```{r}
#HK/SLO/US
all.data %>%
  filter(Task == "NN")%>%
 mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Dataset == "HK/SLO/US")%>%
  mutate(count_range = factor(count_range, levels = c("Within", "Outside")))%>%
  group_by(SID, count_range, Language, Productive, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Language)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black", 
               show.legend = FALSE) +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Language), 
             size=1.5,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE) +
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 10) + 
  theme(legend.position = "bottom") +
  theme(text = element_text(size = 10)) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2", guide = "none") + 
  scale_colour_manual(values = productivity.pal) +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom", 
        legend.title = element_blank()) +
  facet_grid(~Productive) 

#India
all.data %>%
  filter(Task == "NN")%>%
 mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, count_range, Language, Productive, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Language)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black", 
               show.legend = FALSE) +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Language), 
             size=1.5,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE) +
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 10) + 
  theme(legend.position = "bottom") +
  ggtitle("Performance on NN Task by language, within/outside IHC") +
  theme(text = element_text(size = 10)) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2", guide = "none") + 
  scale_colour_manual(values = productivity.pal) +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom") +
  facet_grid(Dataset~Productive) 
```

####With prod points, all together
```{r}
all.data %>%
  filter(Task == "NN")%>%
 mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, count_range, Language, Productive, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Language)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black", 
               show.legend = FALSE) +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Language), 
             size=1.5,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE) +
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 10) + 
  theme(legend.position = "bottom") +
  ggtitle("Performance on NN Task by language, within/outside IHC") +
  theme(text = element_text(size = 10)) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2", guide = "none") + 
  scale_colour_manual(values = productivity.pal) +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom") +
  facet_grid(~Dataset) 
```

###By item, productivity
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "NN", 
         Dataset != "India")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  group_by(Productive, Task_item, Language, Dataset)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_grid(~Productive) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "NN", 
         Dataset == "India")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  group_by(Productive, Task_item, Language, Dataset)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 13) + 
  facet_grid(Productive~Dataset) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance", title = "Mean WCN Task performance by language and Productivity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

###By knower level
```{r}
knower.pal <- brewer.pal(n = 9, "Paired")[3:9]

all.data %>%
  filter(!is.na(Knower.level))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "NN")%>%
  group_by(SID, Knower.level, Language, Dataset)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Language, y = mean, fill=Knower.level)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  ggtitle("Performance on NN Task by language, knower-level") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = knower.pal)+
  facet_grid(~Dataset, scale= "free_x")
```

---

##SF and NN together
###By-item performance - this is a mess, do it separately for India/HK
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "NN" | Task == "SF")%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  filter(Dataset != "India")%>%
  group_by(Task, Productive, Task_item, Language, Dataset)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 10) + 
  facet_grid(Task~Productive) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance", title = "Mean Unit and NN Task performance by language and Productivity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

all.data %>%
  filter(!is.na(Productive))%>%
  filter(Task == "NN" | Task == "SF")%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Dataset == "India")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "7", "16", "24", "52", "71", 
                                                  "105", "107", "116", "224", "252", "271")))%>%
  group_by(Task, Productive, Task_item, Language, Dataset)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 10) + 
  facet_grid(Task~Productive) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Number queried", y = "Mean performance", title = "Mean Unit and NN Task performance by language and Productivity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

##WPPSI
```{r, warning = FALSE}
##histogram of WPPSI scores
wppsi.ms <- all.data %>%
  filter(Task == "WPPSI")%>%
  filter(Trial_number != "Sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != "1", 
         Trial_number != '2', 
         Trial_number != '7', 
         Trial_number != '8')%>%
  mutate(Trial_number = as.numeric(as.character(Trial_number)))%>%
  group_by(SID, Language)%>%
  summarise(sum_wppsi = sum(as.numeric(as.character(Correct)), na.rm = TRUE), 
            num_trials = n())
 
 ggplot(wppsi.ms, aes(x = sum_wppsi, fill = Language)) +
   geom_histogram(binwidth = 1, colour = "black") +
   theme_bw() + 
   facet_grid(~Language)+
   scale_fill_brewer(palette = "Dark2") + 
   labs(title = "Frequency of WPPSI scores by language") +
   guides(fill = FALSE)
 
##Mean WPPSI scores 
all.data %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "WPPSI")%>%
  filter(Trial_number != "Sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != "1", 
         Trial_number != '2', 
         Trial_number != '7', 
         Trial_number != '8')%>%
  mutate(Trial_number = as.numeric(as.character(Trial_number)))%>%
  group_by(SID, Language, Dataset)%>%
  summarise(mean = mean(sum_wppsi, na.rm=TRUE),
            sd = sd(sum_wppsi, na.rm=TRUE)) %>%
  ggplot(aes(x = Language, y = mean, fill=factor(Language))) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean WPPSI score") + 
  xlab('') + 
  theme_bw(base_size = 12) + 
  theme(legend.position = "none") +
  ggtitle("Mean WPPSI score by Language") +
  theme(text = element_text(size = 12),
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank()) +
  geom_violin(alpha = .1) + 
  scale_fill_brewer(palette = "Dark2")+
  facet_grid(~Dataset, scale = "free_x")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
 
```


---

##IHC to NN and Unit task mean performance
```{r}
all.data %>%
  filter(Task == "SF") %>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(!is.na(Productive))%>%
  group_by(SID, IHC, Language, Dataset)%>%
  summarise(mean_unit = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = IHC, y = mean_unit, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 12) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  theme(legend.position = "bottom")+
  labs(title = "Mean Unit Task Performance and IHC by Language", x = "IHC", 
       y = "Mean Unit Task Performance")+
  facet_grid(~Dataset) +
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

all.data %>%
  filter(Task == "NN")%>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, IHC, Language, Dataset)%>%
  summarise(mean_nn = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = IHC, y = mean_nn, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 12) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean NN Task Performance and IHC by Language", x = "IHC", 
       y = "Mean NN Task Performance") + 
  facet_grid(~Dataset)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

all.data %>%
  filter(Task == "SF") %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, IHC, Language, Productive, Dataset)%>%
  summarise(mean_unit = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = IHC, y = mean_unit, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 12) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean Unit Task Performance and IHC by Language", x = "IHC", 
       y = "Mean Unit Task Performance")+
  facet_grid(Productive~Dataset, scale = "free_x")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

all.data %>%
  filter(Task == "NN")%>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, IHC, Language, Productive, Dataset)%>%
  summarise(mean_nn = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = IHC, y = mean_nn, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 12) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean NN Task Performance and IHC by Language", x = "IHC", 
       y = "Mean NN Task Performance") + 
  facet_grid(Productive~Dataset, scale = "free_x")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


##FHC to NN and Unit task mean performance
```{r}
all.data %>%
  filter(Task == "SF") %>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(!is.na(Productive))%>%
  group_by(SID, FHC, Language, Dataset)%>%
  summarise(mean_unit = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = FHC, y = mean_unit, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 12) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean Unit Task Performance and FHC by Language", x = "FHC", 
       y = "Mean Unit Task Performance") +
  facet_grid(~Dataset)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

all.data %>%
  filter(Task == "NN")%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(!is.na(Productive))%>%
  group_by(SID, FHC, Language, Dataset)%>%
  summarise(mean_nn = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = FHC, y = mean_nn, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 12) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean NN Task Performance and FHC by Language", x = "FHC", 
       y = "Mean NN Task Performance") + 
  facet_grid(~Dataset)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

all.data %>%
  filter(Task == "SF") %>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, FHC, Language, Productive, Dataset)%>%
  summarise(mean_unit = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = FHC, y = mean_unit, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 12) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean Unit Task Performance and FHC by Language", x = "FHC", 
       y = "Mean Unit Task Performance") +
  facet_grid(Productive~Dataset, scale = "free_x")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

all.data %>%
  filter(Task == "NN")%>%
  filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, FHC, Language, Productive, Dataset)%>%
  summarise(mean_nn = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = FHC, y = mean_nn, colour = Language, group = Language)) +
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw(base_size = 12) +
  scale_color_brewer(palette = "Dark2")+
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  coord_cartesian(ylim = seq(0,1, .2), expand = TRUE) +
  theme(legend.position = "bottom")+
  labs(title = "Mean NN Task Performance and FHC by Language", x = "FHC", 
       y = "Mean NN Task Performance") +
  facet_grid(Productive~Dataset, scale = "free_x")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

##Unit performance by highest contiguous NN for each language
```{r}
all.data %>%
  filter(!is.na(Productive))%>%
  filter(!is.na(highest_contig))%>% #filter out kids who do not have NN
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  filter(Task == "SF")%>%
  mutate(highest_contig = factor(highest_contig))%>%
  group_by(highest_contig, Language, Dataset)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = highest_contig, y = mean, colour = Language, group= Language)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 12) + 
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(x = "Highest contiguous NN", y = "Mean Unit Task performance", title = "Unit Task performance by Highest Contiguous NN") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + facet_grid(~Dataset, scale = "free_x")

```

##Unit performance by mean NN performance for each language
```{r}
all.data %>%
  filter(Task == "SF" |
           Task == "NN")%>% filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  group_by(SID, Task, Dataset, Language)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))%>%
  spread(Task, mean)%>%
  ggplot(aes(x = SF, y = NN, colour = Language, group = Language))+
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = FALSE) + 
  theme_bw(base_size = 12)+
  scale_colour_brewer(palette = "Dark2")+
  facet_grid(~Dataset) +
  labs(title = "Mean Unit perf. by mean NN perf.", x = "Mean NN performance",
       y = "Mean Unit performance") +
  theme(legend.position = "bottom")
```

---

#Main analyses
#Within-language analyses

###Make model analysis dfs
Note that there is a lot more variability in highest counts and highest contiguous NN than in categorical variables. I am centering age, and centering and scaling FHC, IHC, and highest contiguous NN (which has the most variability).
```{r, include = FALSE}
##HK##
sf.hk.within <- all.data%>%
  filter(Task == "SF")%>%
  filter(Language== "Cantonese")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))
  
wcn.hk.within <- all.data%>%
  filter(Task == "NN")%>%
  filter(Language == "Cantonese")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))

##SLO##
sf.slo.within <- all.data%>%
  filter(Task == "SF")%>%
  filter(Language == "Slovenian")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))%>%
  filter(!is.na(highest_contig.c))

wcn.slo.within <- all.data%>%
  filter(Language == "Slovenian")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))%>%
  filter(!is.na(highest_contig.c))

##US
sf.us.within <- all.data%>%
  filter(Task == "SF")%>%
  filter(Language == "English (US)")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))%>%
  filter(!is.na(highest_contig.c))

wcn.us.within <- all.data%>%
  filter(Language == "English (US)")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Task_item = as.integer(as.character(Task_item)))%>%
  filter(!is.na(highest_contig.c))

##English - India
sf.ind.eng.within <- all.data %>%
  filter(Task == "SF")%>%
  filter(Language == "English (India)")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

wcn.ind.eng.within <- all.data %>%
  filter(Language == "English (India)")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

#Hindi
sf.hindi.within <- all.data %>%
  filter(Task == "SF")%>%
  filter(Language == "Hindi")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

wcn.hindi.within <- all.data %>%
  filter(Language == "Hindi")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))


#Gujarati
sf.gujarati.within <- all.data %>%
  filter(Task == "SF")%>%
  filter(Language == "Gujarati")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

wcn.gujarati.within <- all.data %>%
  filter(Language == "Gujarati")%>%
  filter(Task == "NN")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))
```

###Unit Task

This first set of analyses replicates, in Cantonese English and Slovenian speaking samples, analyses similar to those previously conducted on English-speaking subjects. To identify whether there is connection between counting experience and Unit Task performance for participants within particular language groups, we will conduct four initial analyses (plus the null model) within each language, predicting Unit Task performance from (1) Productivity (defined above); (2) Final Highest Count; (3) Initial Highest Count; and (4) Highest Contiguous Next Number.

All models will be logistic mixed effects models, predicting performance on the unit task (0 or 1) on a trial as a function of the following predictors, with a random intercept for subject. In R, the formula will beglmer(predicted ~ (predictor) + age + within/outside range + (1|subject), family = binomial).

In each language, after running these first four models, any predictor that significantly (p &lt;.05) predicts Unit TaskPerformance (as assessed by running a likelihood ratio test on the Null Model (Model 0) and Models 1, 2, 3, and 4) will be added into Model 5, which will be our Large model. We will construct model 5 hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 5). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.


-  Model 0 (null model): Unit.Performance ~ Within/Outside range + Age + (1|subject)
-  Model 1: Unit.Performance ~ Productivity + Within/Outside range + Age + (1|subject)
-  Model 2: Unit.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
-  Model 3: Unit.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)
-  Model 4: Unit.Performance ~ Highest.Contiguous.Next.Number + Within/Outside range + Age + (1|subject)

#Hong Kong: Within-language models, Unit Task
Build the models

##Build the models
```{r}
#base
sf.hk.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
#Productivity
sf.hk.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
#FHC
sf.hk.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
#IHC
sf.hk.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
#Highest contig.
sf.hk.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)

##Exploratory - productivity gradient
sf.hk.within.model.pg <- glmer(Correct ~ prod.gradient + count_range + starting_num.c + age.c + (1|SID), 
                               family = "binomial", data = sf.hk.within)

#exp - cluster
sf.hk.within.model.clust <- glmer(Correct ~ CLUST + count_range + starting_num.c + age.c + (1|SID), 
                               family = "binomial", data = sf.hk.within)
```

##Hong Kong: Unit task models
```{r}
mtable.sf.hk <- mtable('Base Model' = sf.hk.within.base,
            'Model 1: Productivity' = sf.hk.within.model1,
            'Model 2: FHC' = sf.hk.within.model2,
            'Model 3: IHC' = sf.hk.within.model3,
            'Model 4: Highest Contig.' = sf.hk.within.model4,
            'EXP: Prod. Gradient' = sf.hk.within.model.pg,
            'EXP: Cluster' = sf.hk.within.model.clust,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.hk
```

##Model comparisons
###Base v. productivity - NS, Chisq(1) = 0.064. p = .880
```{r}
anova(sf.hk.within.base, sf.hk.within.model1, test = 'LRT') #ns
```

###Base v. FHC - Sig, Chisq(1) = 11.78, p = 0.0006, AIC = 1614.6
```{r}
anova(sf.hk.within.base, sf.hk.within.model2, test = 'LRT')
```

###Base v. IHC - Sig, Chisq(1) = 39.16, p < .0001, AIC = 1587.2
```{r}
anova(sf.hk.within.base, sf.hk.within.model3, test = 'LRT')
```

###Base v. Highest Contiguous NN - Sig, Chisq(1) = 14.337, p = .0002, AIC = 1612.1
```{r}
anova(sf.hk.within.base, sf.hk.within.model4, test = 'LRT')
```

#Exploratory - productivity gain - Marginal, Chisq(1) = 3.87, p = .05, AIC = 1622.5; Cluster
```{r}
anova(sf.hk.within.base, sf.hk.within.model.pg, test = 'LRT')
anova(sf.hk.within.base, sf.hk.within.model.clust, test = 'LRT')
```

##Large model
We have three significant predictors of performance on the Unit task (FHC, IHC, and Highest Contiguous NN). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task.

The simple model with the lowest AIC is IHC, so we will begin with that as our base term. 
```{r}
#Base = IHC
sf.hk.within.plus1 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)

#IHC and Highest Contiguous
sf.hk.within.plus2.hc <- glmer(Correct ~ highest_contig.c + ihc.c+ count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)

#IHC and FHC
sf.hk.within.plus2.fhc <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)

#IHC and FHC and HCNN
sf.hk.within.plus3 <- glmer(Correct ~ highest_contig.c + fhc.c + ihc.c + count_range + starting_num.c + age.c + 
                              (1|SID), family = "binomial", data = sf.hk.within)


#comparison of 3 (minus HCNN)
anova(sf.hk.within.plus1, sf.hk.within.plus2.fhc, sf.hk.within.plus3, test = 'LRT') 
#comparison of 3 (minus FHC)
anova(sf.hk.within.plus1, sf.hk.within.plus2.hc, sf.hk.within.plus3, test = 'LRT') 

mtable.sf.hk.large <- mtable('IHC alone' = sf.hk.within.plus1,
            'Highest Contig + IHC' = sf.hk.within.plus2.hc,
            'FHC + IHC' = sf.hk.within.plus2.fhc,
            'Highest Contig. + FHC + IHC' = sf.hk.within.plus3,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.hk.large
```


##HK Unit Task within-language results: IHC emerges as best predictor of performance on Unit Task


---

#SLO: Within-language models, Unit Task

##Build the models
```{r}
#base
sf.slo.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID) , family = "binomial", 
                           data = sf.slo.within)
#productivity
sf.slo.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
#FHC
sf.slo.within.model2 <- glmer(Correct ~ fhc.c + count_range + age.c + starting_num.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
#IHC
sf.slo.within.model3 <- glmer(Correct ~ ihc.c + count_range + age.c + starting_num.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within)
#highest contiguous NN
sf.slo.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within) 

#exploratory - productivity gradient
sf.slo.within.model.pg <- glmer(Correct ~ prod.gradient + count_range + starting_num.c + age.c + (1|SID), 
                                family = "binomial", data = sf.slo.within)

#exp - cluster
sf.slo.within.model.clust <- glmer(Correct ~ CLUST + count_range + starting_num.c + age.c + (1|SID), 
                                family = "binomial", data = sf.slo.within)
```

##SLO: Unit task models
```{r}
mtable.sf.slo <- mtable('Base Model' = sf.slo.within.base,
            'Model 1: Productivity' = sf.slo.within.model1,
            'Model 2: FHC' = sf.slo.within.model2,
            'Model 3: IHC' = sf.slo.within.model3,
            'Model 4: Highest Contig.' = sf.slo.within.model4,
            'EXP: Prod. Gradient' = sf.slo.within.model.pg,
            'EXP: Cluster' = sf.slo.within.model.clust,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.slo
```

##Model Comparisons
###Base v. Productivity - sig, Chis(1) = 9.242, p = .002
```{r}
anova(sf.slo.within.base, sf.slo.within.model1, test = 'LRT')
```

  ###Base v. FHC - Sig, Chisq(1) = 11.679, p = .0006, AIC = 1317.5
```{r}
anova(sf.slo.within.base, sf.slo.within.model2, test = 'LRT')
```

###Base v. IHC - NS
```{r}
anova(sf.slo.within.base, sf.slo.within.model3, test = 'LRT')
````

###Base v. Highest Contiguous NN - Sig, Chisq(1) = 21.12, p < .0001, AIC = 1308.1
```{r}
anova(sf.slo.within.base, sf.slo.within.model4, test = 'LRT')
```

###Exploratory - Cluster
```{r}
anova(sf.slo.within.base, sf.slo.within.model.clust, test = 'LRT')
```

##Large model

```{r}
sf.slo.within.plus1 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
sf.slo.within.plus2.fhc <- glmer(Correct ~ fhc.c + highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
sf.slo.within.plus2.prod <- glmer(Correct ~ Productive + highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
sf.slo.within.plus3 <- glmer(Correct ~ Productive + fhc.c + highest_contig.c + count_range + starting_num.c + age.c + 
                               (1|SID), family = "binomial", data = sf.slo.within)
#comparison of 3, minus prod
anova(sf.slo.within.plus1, sf.slo.within.plus2.fhc,  sf.slo.within.plus3, test = 'LRT') 
#comparison of 3, minus fhc
anova(sf.slo.within.plus1, sf.slo.within.plus2.prod,  sf.slo.within.plus3, test = 'LRT') 


mtable.sf.slo.large <- mtable('Highest Contig. alone' = sf.slo.within.plus1,
            'Highest Contig + FHC' = sf.slo.within.plus2.fhc,
            'Highest Contig + IHC' = sf.slo.within.plus2.prod,
            'Highest Contig + FHC + IHC' = sf.slo.within.plus3,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.slo.large
```

--- 

#English (US): Within-language models, Unit Task

##Build the models
```{r}
#base
sf.us.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.us.within)
#productivity
sf.us.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.us.within)
#FHC
sf.us.within.model2 <- glmer(Correct ~ fhc.c + count_range +  starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.us.within)
#IHC
sf.us.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c +  age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.us.within, control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#Highest contiguous
sf.us.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.us.within) 
#Exploratory, Prod. gradient
sf.us.within.model.gain <- glmer(Correct ~ prod.gradient + count_range + starting_num.c +age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.us.within) #ns

sf.us.within.model.clust <- glmer(Correct ~ CLUST + count_range + starting_num.c +age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.us.within)

```

##English (US): Unit task models
```{r}
mtable.sf.us <- mtable('Base Model' = sf.us.within.base,
            'Model 1: Productivity' = sf.us.within.model1,
            'Model 2: FHC' = sf.us.within.model2,
            'Model 3: IHC' = sf.us.within.model3,
            'Model 4: Highest Contig.' = sf.us.within.model4,
            'Exp. model: Prod. gradient' = sf.us.within.model.gain,
            'Exp. model: Cluster' = sf.us.within.model.clust,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.us
```

##Model comparisons
###Base v. Productivity - NS, Chisq(1) = 1.23, p = .27
```{r}
anova(sf.us.within.base, sf.us.within.model1, test = 'LRT')
```

###Base v. FHC - Sig, Chisq(1) = 18.86, p < .0001, AIC = 1512.5
```{r}
anova(sf.us.within.base, sf.us.within.model2, test = 'LRT')
```

###Base v. IHC - Sig, Chisq(1) = 49.07, p < .0001, AIC = 1497.6
```{r}
anova(sf.us.within.base, sf.us.within.model3, test = 'LRT')
````

###Base v. Highest Contig. - Sig, Chisq(1) = 19.6, p < .0001, AIC = 1511.8
```{r}
anova(sf.us.within.base, sf.us.within.model4, test = 'LRT')
```

###Post-hoc: Prod.gradient - Sig, Chisq(1) = 4.3153, p = .04, AIC = 1526.8
```{r}
anova(sf.us.within.base, sf.us.within.model.gain, test = 'LRT')
anova(sf.us.within.base, sf.us.within.model.clust, test = 'LRT') 
```

##Large model
Base = IHC (AIC = 1473.8)
```{r}
#IHC
sf.us.within.plus1 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.us.within, family = "binomial", 
                            control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#IHC + FHC
sf.us.within.plus2.fhc <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.us.within, family = "binomial", 
                             control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#IHC + HCNN
sf.us.within.plus2.highest.contig <- glmer(Correct ~ highest_contig.c + ihc.c + starting_num.c + count_range + age.c + (1|SID), 
                             data = sf.us.within, family = "binomial", 
                             control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
# sf.us.within.plus2.gain <- glmer(Correct ~ prod.gradient + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
#                              data = sf.us.within, family = "binomial", 
#                              control=glmerControl(optimizer="bobyqa",
#                          optCtrl=list(maxfun=2e4)))

#IHC + FHC + HCNN
sf.us.within.plus3 <- glmer(Correct ~ highest_contig.c + fhc.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             data = sf.us.within, family = "binomial", 
                            control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))


#compare 3, minus hcnn
anova(sf.us.within.plus1, sf.us.within.plus2.fhc, sf.us.within.plus3, test = 'LRT') 
#compare 3, minus fhc
anova(sf.us.within.plus1, sf.us.within.plus2.highest.contig, sf.us.within.plus3, test = 'LRT') 
#regression table
mtable.sf.us.large <- mtable('IHC' = sf.us.within.plus1,
            'FHC + IHC' = sf.us.within.plus2.fhc,
            'Highest Contig + IHC' = sf.us.within.plus2.highest.contig,
            # 'Prod. gradient + IHC' = sf.us.within.plus2.gain,
            'Highest Contig + FHC + IHC' = sf.us.within.plus3,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.us.large


```

##US Unit Task within-language results: IHC best predictor of performance on Unit Task

---

#English (India): Within-language models, Unit Task (recall that these models include starting magnitude, centered)

##Build the models
```{r}
#base
sf.ind.eng.within.base <- glmer(Correct ~ count_range + starting_num.c +age.c + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within)
#productivity
sf.ind.eng.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within)
#FHC
sf.ind.eng.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c  + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within)
#IHC
sf.ind.eng.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within)
#Highest contiguous
sf.ind.eng.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within)

#exploratory - prod. gradient
sf.ind.eng.within.model.gain <- glmer(Correct ~ prod.gradient + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within) #sig

sf.ind.eng.within.model.clust <- glmer(Correct ~ CLUST + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.ind.eng.within) #sig
```


##English (India): Unit task models
```{r}
mtable.sf.ind.eng <- mtable('Base Model' = sf.ind.eng.within.base,
            'Model 1: Productivity' = sf.ind.eng.within.model1,
            'Model 2: FHC' = sf.ind.eng.within.model2,
            'Model 3: IHC' = sf.ind.eng.within.model3,
            'Model 4: Highest Contig.' = sf.ind.eng.within.model4,
            'Exp: Prod. Gradient' = sf.ind.eng.within.model.gain,
            'Exp: Cluster' = sf.ind.eng.within.model.clust,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.ind.eng
```

##Model comparisons
###Base v. productivity - marginal (p = .09)
```{r}
anova(sf.ind.eng.within.base, sf.ind.eng.within.model1, test = 'LRT')
```

###Base v. FHC - significant, Chisq(1) = 9.66, p = .002, AIC = 760.1
```{r}
anova(sf.ind.eng.within.base, sf.ind.eng.within.model2, test = 'LRT')
```

###Base v. IHC - Sig, Chisq(1) = 6.87, p = .008, AIC = 762.89
```{r}
anova(sf.ind.eng.within.base, sf.ind.eng.within.model3, test = 'LRT')
```

###Base v. Highest Contiguous NN - sig, Chisq(1) = 5, p = .03, AIC = 764.8
```{r}
anova(sf.ind.eng.within.base, sf.ind.eng.within.model4, test = 'LRT')
```

###Exploratory: Base v. Prod.gradient - Sig, Chisq(1) = 7.42, p = .006
```{r}
anova(sf.ind.eng.within.base, sf.ind.eng.within.model.gain, test = 'LRT')
anova(sf.ind.eng.within.base, sf.ind.eng.within.model.clust, test = 'LRT')
```

##Large model
```{r}
#FHC
sf.ind.eng.within.plus1 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.ind.eng.within)

#HCNN + FHC
sf.ind.eng.within.plus2.hc <- glmer(Correct ~ highest_contig.c + fhc.c + count_range + starting_num.c + age.c + starting_num.c + (1|SID), 
                            family = "binomial", data = sf.ind.eng.within)

#IHC + FHC
sf.ind.eng.within.plus2.ihc <- glmer(Correct ~ ihc.c + fhc.c + count_range + starting_num.c + age.c  +(1|SID), 
                            family = "binomial", data = sf.ind.eng.within)

#HCNN + IHC + FHC
sf.ind.eng.within.plus3 <- glmer(Correct ~ highest_contig.c + ihc.c + fhc.c + count_range + age.c + starting_num.c + (1|SID), 
                            family = "binomial", data = sf.ind.eng.within)


#comparison of 3, minus ihc
anova(sf.ind.eng.within.plus1, sf.ind.eng.within.plus2.hc, sf.ind.eng.within.plus3, test = 'LRT')
anova(sf.ind.eng.within.plus1, sf.ind.eng.within.plus2.ihc, sf.ind.eng.within.plus3, test = 'LRT')

mtable.sf.ind.eng.large <- mtable('FHC alone' = sf.ind.eng.within.plus1,
            'Highest Contig. + FHC' = sf.ind.eng.within.plus2.hc,
            'IHC + FHC' = sf.ind.eng.within.plus2.ihc,
            'Highest Contig. + IHC + FHC' = sf.ind.eng.within.plus3, 
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.ind.eng.large
```

##English (India) Unit Task within-language results: FHC emerges as best predictor of performance on Unit Task

---

#Hindi: Within-language models, Unit Task
##Build the models
```{r}
#Base
sf.hindi.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
#Productivity
sf.hindi.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c  + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
#FHC
sf.hindi.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
#IHC
sf.hindi.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)
#Highest contig
sf.hindi.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.hindi.within)

#Exploratory - prod. gradient 
sf.hindi.within.model.gain <- glmer(Correct ~ prod.gradient + count_range + starting_num.c + age.c +
                                      (1|SID), family = "binomial", data = sf.hindi.within)

#Exploratory - cluster
sf.hindi.within.model.clust <- glmer(Correct ~ CLUST + count_range + starting_num.c + age.c +
                                      (1|SID), family = "binomial", data = sf.hindi.within)
```

##Hindi: Unit task models
```{r}
mtable.sf.hindi <- mtable('Base Model' = sf.hindi.within.base,
            'Model 1: Productivity' = sf.hindi.within.model1,
            'Model 2: FHC' = sf.hindi.within.model2,
            'Model 3: IHC' = sf.hindi.within.model3,
            'Model 4: Highest Contig.' = sf.hindi.within.model4,
            'Exp: Prod. gradient' = sf.hindi.within.model.gain,
            'Exp: Cluster' = sf.hindi.within.model.clust,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.hindi
```

##Model comparisons
###Base v. Productivity - marginal, Chisq(1) = 3.33, p = .07, AIC = 1316.1
```{r}
anova(sf.hindi.within.base, sf.hindi.within.model1, test = 'LRT')
```

###Base v. FHC - sig, Chisq(1) = 20.97, p < .0001, AIC = 1298.5
```{r}
anova(sf.hindi.within.base, sf.hindi.within.model2, test = 'LRT')
```

###Base v. IHC - Sig, chisq(1) = 27.66, p < .0001, AIC = 1291.8
```{r}
anova(sf.hindi.within.base, sf.hindi.within.model3, test = 'LRT')
```

###Base v. Highest contig. - Sig, Chisq(1) = 26.642, p < .0001, AIC = 1292.8
```{r}
anova(sf.hindi.within.base, sf.hindi.within.model4, test = 'LRT')
```

###Exploratory - prod. gradient
```{r}
anova(sf.hindi.within.base, sf.hindi.within.model.gain, test = 'LRT')
```

##Large model -- Warning, convergence issues for IHC + FHC model

IHC v. FHC v. Highest Contig
```{r}
#IHC
sf.hindi.within.plus1 <- glmer(Correct ~ ihc.c + count_range +  starting_num.c + age.c  + (1|SID), 
                             family = "binomial", 
                           data = sf.hindi.within)
#HCNN + IHC 
sf.hindi.within.plus2.hc <- glmer(Correct ~ highest_contig.c + ihc.c + count_range + starting_num.c + age.c +  (1|SID), 
                            family = "binomial", data = sf.hindi.within)

#FHC + IHC
sf.hindi.within.plus2.fhc <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = sf.hindi.within)

#HCNN + FHC + IHC
sf.hindi.within.plus3 <- glmer(Correct ~ highest_contig.c + fhc.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = sf.hindi.within)

#Exploratory - prod. gain v. IHC
sf.hindi.within.plus.gain <- glmer(Correct ~ prod.gradient + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = sf.hindi.within)

#Comparison of 3 minus fhc
anova(sf.hindi.within.plus1, sf.hindi.within.plus2.hc, sf.hindi.within.plus3, test = 'LRT')
#Comparison of 3 minus HCNN
anova(sf.hindi.within.plus1, sf.hindi.within.plus2.fhc, sf.hindi.within.plus3, test = 'LRT')

mtable.sf.hindi.large <- mtable('IHC alone' = sf.hindi.within.plus1,
            'Highest Contig. + IHC' = sf.hindi.within.plus2.hc,
            'FHC + IHC' = sf.hindi.within.plus2.fhc,
            'Highest Contig. + FHC + IHC' = sf.hindi.within.plus3, 
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.hindi.large

```

##Hindi Unit Task (interim) within-language results: IHC, and Highest Contig. emerge as best predictor of performance on Unit Task
---

#Gujarati: Within-language models, Unit Task
##Build the models
```{r}
#Base
sf.gujarati.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c +  (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
#Productivity
sf.gujarati.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
#FHC
sf.gujarati.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c +  (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
#IHC
sf.gujarati.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.gujarati.within)
#Highest contig.
sf.gujarati.within.model4 <- glmer(Correct ~ highest_contig.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                           data = sf.gujarati.within)

#Exploratory - prod.gradient
sf.gujarati.within.model.gain <- glmer(Correct ~ prod.gradient + count_range + starting_num.c + age.c + 
                                         (1|SID), family = "binomial", data = sf.gujarati.within)

#Exploratory - cluster
sf.gujarati.within.model.clust <- glmer(Correct ~ CLUST + count_range + starting_num.c + age.c + 
                                         (1|SID), family = "binomial", data = sf.gujarati.within)
```

##Gujarati: Unit task models
```{r}
mtable.sf.gujarati <- mtable('Base Model' = sf.gujarati.within.base,
            'Model 1: Productivity' = sf.gujarati.within.model1,
            'Model 2: FHC' = sf.gujarati.within.model2,
            'Model 3: IHC' = sf.gujarati.within.model3,
            'Model 4: Highest Contig.' = sf.gujarati.within.model4,
            'Exp.: Prod. gradient' = sf.gujarati.within.model.gain,
            'Exp.: Cluster' = sf.gujarati.within.model.clust,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.gujarati
```

##Model comparisons
###Base v. productivity - NS
```{r}
anova(sf.gujarati.within.base, sf.gujarati.within.model1, test = 'LRT')
```

###Base v. FHC - NS
```{r}
anova(sf.gujarati.within.base, sf.gujarati.within.model2, test = 'LRT')
```

###Base v. IHC
```{r}
anova(sf.gujarati.within.base, sf.gujarati.within.model3, test = 'LRT')
```

###Base v. Highest contig
```{r}
anova(sf.gujarati.within.base, sf.gujarati.within.model4, test = 'LRT')
```

###Exploratory - prod.gradient
```{r}
anova(sf.gujarati.within.base, sf.gujarati.within.model.gain, test = 'LRT')
```

##Large model - no need, no significant predictors

How many Gujarati speakers have trials within their count range?
```{r}
sf.gujarati.within %>%
  group_by(count_range)%>%
  summarise(n = n())

sf.hindi.within %>%
  ggplot(aes(x = highest_contig, y = Correct)) + 
  geom_point()
```



---

##Productivity t-test of Unit Task performance
Using the Productive/Non-Productive categorical classification outlined above, we will compare performance
between both groups on the Unit task using t-tests. We may do this by considering average performance
(averaring the 0s and 1s on each task for each participant); should doing so provide greater precision, we may also compare Highest Contiguous Number.

###HK: Marginally significant difference between groups (*p* = .086)
```{r}
#with mean performance
sf.hk.mean.ms <- sf.hk.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(sf.hk.mean.ms, Productive == "Productive")$mean, 
       subset(sf.hk.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #marginally significant difference between productive and nonproductive counters for performance on Unit Task
```

###SLO
```{r}
#with mean performance
sf.slo.mean.ms <- sf.slo.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(sf.slo.mean.ms, Productive == "Productive")$mean, 
       subset(sf.slo.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #significant difference in performance between productive and nonproductive counters
```

###US
```{r}
#with mean performance
sf.us.mean.ms <- sf.us.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(sf.us.mean.ms, Productive == "Productive")$mean, 
       subset(sf.us.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #significant difference in performance between productive and nonproductive counters
```

---

##Productivity t-test of Highest contiguous NN
###HK: Significant difference between groups (*p* = .002)
```{r}
sf.hk.mean.nn <- sf.hk.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.hk.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.hk.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```

###SLO - sig, p < .0001
```{r}
sf.slo.mean.nn <- sf.slo.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.slo.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.slo.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```


###US - sig, p < .0001
```{r}
sf.us.mean.nn <- sf.us.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.us.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.us.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```

###India-Eng
```{r}
sf.ind.eng.mean.nn <- sf.ind.eng.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.ind.eng.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.ind.eng.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```

###Hindi
```{r}
sf.hindi.mean.nn <- sf.hindi.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.hindi.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.hindi.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```


###Gujarati
```{r}
sf.gujarati.mean.nn <- sf.gujarati.within %>%
  group_by(SID, Productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.gujarati.mean.nn, Productive == "Productive")$mean_nn, 
       subset(sf.gujarati.mean.nn, Productive == "Nonproductive")$mean_nn, var.equal = TRUE)
```


---

#WCN Task- within-language analyses, simple models

All models will be logistic mixed effects models, predicting next number performance (0 or 1) on a trial as a function of the following predictors, with a random intercept for subject. In R, the formula will be glmer(predictedSF_correct ~ (predictor) + age + within/outside range + (1|subject), family = binomial).

-  Model 0 (null model): NextNumber.Performance ~ Within/Outside range + Age + (1|subject)
-  Model 1: Next.Number.Performance ~ Productivity + Within/Outside range + Age + (1|subject)
-  Model 2: Next.Number.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
-  Model 3: Next.Number.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)

In each language, after running these first three models, any predictor that significantly (p <.05) predicted Next Number Performance (as assessed by running a likelihood ratio test on the Null Model (Model 0) and Models 1, 2, and 3) will be added into Model 6, which will be our Large model (containing all predictors that significantly predicted Next Number Task Performance in the simple models). We will construct model 6 hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 6). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

#HK: Within-language analyses, Next Number Task
##Build the models
```{r}
#base
wcn.hk.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
#productivity
wcn.hk.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
#FHC
wcn.hk.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
#IHC
wcn.hk.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)

#exp - prod gradient
wcn.hk.within.model.gain <- glmer(Correct ~ prod.gradient + count_range + starting_num.c + age.c + (1|SID), 
                                  family = "binomial", data = wcn.hk.within)
```

##Hong Kong: NN task models
```{r}
mtable.wcn.hk <- mtable('Base Model' = wcn.hk.within.base,
            'Model 1: Productivity' = wcn.hk.within.model1,
            'Model 2: FHC' = wcn.hk.within.model2,
            'Model 3: IHC' = wcn.hk.within.model3,
            'Exp: Prod. gradient' = wcn.hk.within.model.gain,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.hk
```

##Model comparisons
###Base v. Productivity - NS, p = .42
```{r}
anova(wcn.hk.within.base, wcn.hk.within.model1, test = 'LRT')
```

###Base v. FHC - Sig, Chisq(1) = 31.08, p < .0001, AIC = 1133.1
````{r}
anova(wcn.hk.within.base, wcn.hk.within.model2, test = 'LRT')
````

###Base v. IHC = Sig, Chisq(1) = 66.20, p < .0001, AIC = 1098
```{r}
anova(wcn.hk.within.base, wcn.hk.within.model3, test = 'LRT')
```

###Exploratory - prod. gradient
```{r}
anova(wcn.hk.within.base, wcn.hk.within.model.gain, test = 'LRT')
```

##Large Model
```{r}
#IHC
wcn.hk.within.plus1 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.hk.within)
#IHC + FHC
wcn.hk.within.plus2 <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = wcn.hk.within)

anova(wcn.hk.within.plus1, wcn.hk.within.plus2, test = 'LRT') 

mtable.wcn.hk.large <- mtable('FHC alone' = wcn.hk.within.plus1,
            'IHC + FHC' = wcn.hk.within.plus2,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.hk.large
```

##HK NN Task within-language results: IHC emerge as best predictor of performance on Unit Task

---

#SLO: Within-language analyses, NN Task
##Build the models
```{r}
#Base
wcn.slo.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
#Productivity
wcn.slo.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
#FHC
wcn.slo.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
#IHC
wcn.slo.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)

#Explore - prod gradient
wcn.slo.within.model.gain <- glmer(Correct ~ prod.gradient + count_range + starting_num.c + age.c + (1|SID), 
                                   family = "binomial", data = wcn.slo.within)
```

##SLO: NN task models
```{r}
mtable.wcn.slo <- mtable('Base Model' = wcn.slo.within.base,
            'Model 1: Productivity' = wcn.slo.within.model1,
            'Model 2: FHC' = wcn.slo.within.model2,
            'Model 3: IHC' = wcn.slo.within.model3,
            'Exp: Prod. gradient' = wcn.slo.within.model.gain,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.slo
```

##Model comparisons
###Base v. Productivity - Sig, Chisq(1) = 25.05, p < .0001, AIC = 791.81
```{r}
anova(wcn.slo.within.base, wcn.slo.within.model1, test = 'LRT')
```

###Base v. FHC - Sig, Chisq(1) = 43.104, p < .0001, AIC = 773.76
```{r}
anova(wcn.slo.within.base, wcn.slo.within.model2, test = 'LRT')
```

###Base v. IHC - Sig, Chisq(1) = 14 p = .0002, AIC = 802.86
```{r}
anova(wcn.slo.within.base, wcn.slo.within.model3, test = 'LRT')
```

##Large Model comparison
```{r}
#FHC
wcn.slo.within.plus1 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.slo.within)
#IHC + FHC
wcn.slo.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)
#Prod + FHC
wcn.slo.within.plus2.prod <- glmer(Correct ~ Productive + fhc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)
#IHC + PROD + FHC
wcn.slo.within.plus3 <- glmer(Correct ~ ihc.c + Productive + fhc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)

#Compare3 minus Prod
anova(wcn.slo.within.plus1, wcn.slo.within.plus2, wcn.slo.within.plus3, test = 'LRT') 
#Compare3 minus FHC
anova(wcn.slo.within.plus1, wcn.slo.within.plus2.prod, wcn.slo.within.plus3, test = 'LRT') 

summary(wcn.slo.within.plus2)

mtable.wcn.slo.large <- mtable('FHC alone' = wcn.slo.within.plus1,
            'IHC + FHC' = wcn.slo.within.plus2,
            'Prod. + FHC' = wcn.slo.within.plus2.prod,
            'IHC + Prod. + FHC' = wcn.slo.within.plus3,
             summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.slo.large
```

##SLO NN Task (interim) within-language results: FHC emerges as best predictors of performance on Unit Task

---

#US: Within-language analyses, NN Task
##Build the models
```{r}
#base
wcn.us.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)
#productivity
wcn.us.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)
#FHC
wcn.us.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)
#IHC
wcn.us.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)

#Explore - prod gradient
wcn.us.within.model.gain <- glmer(Correct ~ prod.gradient + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.us.within)
```

##English (US): NN Task models
```{r}
mtable.wcn.us <- mtable('Base Model' = wcn.us.within.base,
            'Model 1: Productivity' = wcn.us.within.model1,
            'Model 2: FHC' = wcn.us.within.model2,
            'Model 3: IHC' = wcn.us.within.model3,
            'Exp: Prod. gradient' = wcn.us.within.model.gain,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.us
```

##Model comparisons
###Base v. Productivity - Sig, Chisq(1) = 15.629, p < .0001, AIC = 1037.8
```{r}
anova(wcn.us.within.base, wcn.us.within.model1, test = 'LRT')
```

###Base v. FHC - Sig, Chisq(1) = 45.238, p < .0001, AIC = 1008.2
```{r}
anova(wcn.us.within.base, wcn.us.within.model2, test = 'LRT')
```

###Base v. IHC - Sig, Chisq(1) = 30.217, p < .0001, AIC = 1023.3
```{r}
anova(wcn.us.within.base, wcn.us.within.model3, test = 'LRT')
```

##Large Model comparison
```{r}
#FHC
wcn.us.within.plus1 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.us.within)
#IHC + FHC
wcn.us.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + starting_num.c + 
                               age.c + (1|SID), 
                            family = "binomial", data = wcn.us.within)
#Prod + FHC
wcn.us.within.plus2.prod <- glmer(Correct ~ Productive + fhc.c + count_range + starting_num.c + 
                                    age.c + (1|SID), 
                            family = "binomial", data = wcn.us.within)
#IHC + PROD + FHC
wcn.us.within.plus3 <- glmer(Correct ~ ihc.c + Productive + fhc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = wcn.us.within, 
                            control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

#Compare 3 minus Prod
anova(wcn.us.within.plus1, wcn.us.within.plus2, wcn.us.within.plus3, test = 'LRT') 
#Compare 3 minus IHC
anova(wcn.us.within.plus1, wcn.us.within.plus2.prod, wcn.us.within.plus3, test = 'LRT') 
summary(wcn.us.within.plus1)

mtable.wcn.us.large <- mtable('FHC alone' = wcn.us.within.plus1,
            'IHC + FHC' = wcn.us.within.plus2,
            'Prod. + FHC' = wcn.us.within.plus2.prod,
            'IHC + Prod. + FHC' = wcn.us.within.plus3,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.us.large
```

##US NN Task (interim) within-language results: FHC emerges as best predictor of performance on Unit Task

---

#India English: Within-language analyses, NN task

Build the models
```{r}
#Base Model
wcn.ind.eng.within.base <- glmer(Correct ~ count_range + starting_num.c +age.c +  (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
#Productivity
wcn.ind.eng.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c +age.c +  (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
#FHC
wcn.ind.eng.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c +age.c +  (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
#IHC
wcn.ind.eng.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c +age.c +  (1|SID), family = "binomial", 
                            data = wcn.ind.eng.within)
```

---

##English (India) WCN Models 
Summary
```{r}
mtable.ind.eng <- mtable('Base Model' = wcn.ind.eng.within.base,
            'Model 1: Productivity' = wcn.ind.eng.within.model1,
            'Model 2: FHC' = wcn.ind.eng.within.model2,
            'Model 3: IHC' = wcn.ind.eng.within.model3,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.ind.eng
```

##Model comparisons
###Base v. Productivity - NS
```{r}
anova(wcn.ind.eng.within.base, wcn.ind.eng.within.model1, test = 'LRT')
```

###Base v. FHC - Sig, Chisq(1) = 20.59, p < .0001, AIC = 662.18
```{r}
anova(wcn.ind.eng.within.base, wcn.ind.eng.within.model2, test = 'LRT')
```

###Base v. IHC - Sig, Chisq(1) = 18.75, p < .0001, AIC = 664.02
```{r}
anova(wcn.ind.eng.within.base, wcn.ind.eng.within.model3, test = 'LRT')
```

##Large Model

```{r}
#FHC
wcn.ind.eng.within.plus1 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c +  (1|SID), 
                             family = "binomial", 
                           data = wcn.ind.eng.within)
#IHC + FHC
wcn.ind.eng.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + starting_num.c + age.c +  (1|SID), 
                            family = "binomial", data = wcn.ind.eng.within)

anova(wcn.ind.eng.within.plus1, wcn.ind.eng.within.plus2,test = 'LRT') 

mtable.wcn.ind.eng.large <- mtable('FHC alone' = wcn.ind.eng.within.plus1,
            'IHC + FHC' = wcn.ind.eng.within.plus2,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.ind.eng.large
```

##English (India) NN Task (interim) within-language results: IHC and FHC emerge as best predictors of performance on Unit Task

---

#Hindi: Within-language analyses, NN
##Build the models
```{r}
#Base Model
wcn.hindi.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c  + (1|SID), family = "binomial", 
                            data = wcn.hindi.within)
#Productivity
wcn.hindi.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c + age.c +(1|SID), family = "binomial", 
                            data = wcn.hindi.within)
#FHC
wcn.hindi.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c +(1|SID), family = "binomial", 
                            data = wcn.hindi.within)
#IHC
wcn.hindi.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.hindi.within)

#Exp- prod.gradient
wcn.hindi.within.model.gain <- glmer(Correct ~ prod.gradient + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.hindi.within)

```

##Hindi: NN Task models 
Summary
```{r}
mtable.hindi <- mtable('Base Model' = wcn.hindi.within.base,
            'Model 1: Productivity' = wcn.hindi.within.model1,
            'Model 2: FHC' = wcn.hindi.within.model2,
            'Model 3: IHC' = wcn.hindi.within.model3,
            'Exp: Prod. gradient' = wcn.hindi.within.model.gain,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.hindi
```

##Model comparisons
###Base v. Productivity - sig, Chisq(1) = 4.30, p = .04, AIC = 835.31
```{r}
anova(wcn.hindi.within.base, wcn.hindi.within.model1, test = 'LRT')
```

###Base v. FHC - sig, Chisq(1) = 27.06, p < .0001, AIC = 812.54
```{r}
anova(wcn.hindi.within.base, wcn.hindi.within.model2, test = 'LRT')
```

###Base v. IHC - Sig, Chisq(1) = 33.542, p < .0001, AIC = 806.07
```{r}
anova(wcn.hindi.within.base, wcn.hindi.within.model3, test = 'LRT')
```

##Large Model
```{r}
#IHC
wcn.hindi.within.plus1 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.hindi.within)
#FHC + IHC
wcn.hindi.within.plus2 <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + (1|SID), 
                            family = "binomial", data = wcn.hindi.within)

#Prod + IHC
wcn.hindi.within.plus2.prod <- glmer(Correct ~ Productive + ihc.c + count_range + starting_num.c +age.c +  (1|SID), 
                            family = "binomial", data = wcn.hindi.within)

#IHC v. IHC+FHC
anova(wcn.hindi.within.plus1, wcn.hindi.within.plus2, test = 'LRT') 
#IHC v. Prod + FHC
anova(wcn.hindi.within.plus1, wcn.hindi.within.plus2.prod, test = 'LRT') 

mtable.wcn.hindi.large <- mtable('IHC alone' = wcn.hindi.within.plus1,
            'IHC + FHC' = wcn.hindi.within.plus2,
            'Prod. + iHC' = wcn.hindi.within.plus2.prod,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.hindi.large
```

##Hindi NN Task (interim) within-language results: IHC and FHC emerge as best predictors of performance on Unit Task

---

#Gujarati: Within-language analyses, NN
##Build the models
```{r}
#Base Model
wcn.gujarati.within.base <- glmer(Correct ~ count_range + starting_num.c + age.c +  (1|SID), family = "binomial", 
                            data = wcn.gujarati.within)
#Productivity
wcn.gujarati.within.model1 <- glmer(Correct ~ Productive + count_range + starting_num.c +age.c +  (1|SID), family = "binomial", 
                            data = wcn.gujarati.within)
#FHC
wcn.gujarati.within.model2 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c +  (1|SID), family = "binomial", 
                            data = wcn.gujarati.within)
#IHC
wcn.gujarati.within.model3 <- glmer(Correct ~ ihc.c + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.gujarati.within)

#Exp. - prod. gradient
wcn.gujarati.within.model.gain <- glmer(Correct ~ prod.gradient + count_range + starting_num.c + age.c + (1|SID), family = "binomial", 
                            data = wcn.gujarati.within)
```

##Gujarati: NN Task models 
Summary
```{r}
mtable.gujarati <- mtable('Base Model' = wcn.gujarati.within.base,
            'Model 1: Productivity' = wcn.gujarati.within.model1,
            'Model 2: FHC' = wcn.gujarati.within.model2,
            'Model 3: IHC' = wcn.gujarati.within.model3,
            'Exp: Prod. gradient' = wcn.gujarati.within.model.gain,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.gujarati
```

##Model comparisons
###Base v. Productivity - Sig, Chisq(1) = 9.67, p = .002, AIC = 775.42
```{r}
anova(wcn.gujarati.within.base, wcn.gujarati.within.model1, test = 'LRT')
```

###Base v. FHC - Sig, Chisq(1) = 35.62, p < .0001, AIC  749.46
```{r}
anova(wcn.gujarati.within.base, wcn.gujarati.within.model2, test = 'LRT')
```

###Base v. IHC = Sig, Chisq(1) = 32.94, p < .0001, AIC = 752.15
```{r}
anova(wcn.gujarati.within.base, wcn.gujarati.within.model3, test = 'LRT')
```

##Large Model
```{r}
#FHC
wcn.gujarati.within.plus1 <- glmer(Correct ~ fhc.c + count_range + starting_num.c + age.c +  (1|SID), 
                             family = "binomial", 
                           data = wcn.gujarati.within)
#IHC + FHC
wcn.gujarati.within.plus2 <- glmer(Correct ~ ihc.c + fhc.c + count_range + starting_num.c + age.c +  (1|SID), 
                            family = "binomial", data = wcn.gujarati.within)
#Prod + FHC
wcn.gujarati.within.plus2.prod <- glmer(Correct ~ Productive + fhc.c + count_range + starting_num.c +age.c +  (1|SID), 
                            family = "binomial", data = wcn.gujarati.within)

wcn.gujarati.within.plus3 <- glmer(Correct ~ ihc.c + Productive + fhc.c + count_range + age.c + starting_num.c + (1|SID), 
                            family = "binomial", data = wcn.gujarati.within)

#FHC v FHC+IHC
anova(wcn.gujarati.within.plus1, wcn.gujarati.within.plus2, test = 'LRT') 
#FHC v. FHC+Prod
anova(wcn.gujarati.within.plus1, wcn.gujarati.within.plus2.prod, test = 'LRT') 

mtable.wcn.gujarati.large <- mtable('FHC alone' = wcn.gujarati.within.plus1,
            'IHC + FHC' = wcn.gujarati.within.plus2,
            'Prod. + FHC' = wcn.gujarati.within.plus2.prod,
            'IHC + Prod. + FHC' = wcn.gujarati.within.plus3,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.gujarati.large
```

##Gujarati NN Task (interim) within-language results: FHC emerges as best predictors of performance on Unit Task

---

##Productivity t-test of WCN performance
Using the Productive/Non-Productive categorical classification outlined above, we will compare performance
between both groups on the Next Number task using t-tests. We may do this by considering average performance
(averaring the 0s and 1s on each task for each participant).

###HK: Significant difference between productive and nonproductive counters (*p* = .009)
```{r}
#with mean performance
wcn.hk.mean.ms <- wcn.hk.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(wcn.hk.mean.ms, Productive == "Productive")$mean, 
       subset(wcn.hk.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

###SLO: Significant difference between groups (*p* < .0001)

```{r}
#with mean performance
wcn.slo.mean.ms <- wcn.slo.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(wcn.slo.mean.ms, Productive == "Productive")$mean, 
       subset(wcn.slo.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

###US: Significant difference between groups (*p* < .0001)

```{r}
#with mean performance
wcn.us.mean.ms <- wcn.us.within %>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

t.test(subset(wcn.us.mean.ms, Productive == "Productive")$mean, 
       subset(wcn.us.mean.ms, Productive == "Nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```


---

#Cross-linguistic comparisons (HK/SLO/US)
Our second set of analyses is aimed at understanding cross-linguistic differences in performance on the Unit Task. To do this, we will analyze all participants, from all language groups, in a single model. We will then construct our models from above, but will add (a) a measure of Working Memory and (b) the interaction of Initial Highest Count and Language group to each model. These models therefore allow us to test whether (a) language; (b) counting ability; or (c) some interaction between the two predict unit performance. We include Working Memory in all cross-linguistic models with the intention of taking into account baseline differences in processing across samples.

Cross-Linguistic Models:
Model 0a (the Null Model): Unit.Performance~ Language*IHC + Within/Outside range + Age + WM
+ (1|subject)
Model 1a: Unit.Performance ~ Productivity + Language*IHC + Within/Outside range + Age + WM + (1|subject)
Model 2a: Unit.Performance ~ Final.Count + Language*IHC + Within/Outside range + Age + WM + (1|subject)
Model 3a: Unit.Performance ~ Highest.Contiguous.Next.Number + Language*IHC + Within/Outside range +
Age + WM + (1|subject)
Make model dfs


We will then compare Model 0a (the Null Model) to each of the models containing measures of productivity (1a, 2a, and 3a) using a likelihood ratio test in testing whether these measures of productivity significantly explain variance in childrens performance. Should effects of Language emerge, we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects (e.g., Unit.Performance ~ Productivity + IHC + Within/Outside range + Age + WM + (1|subject)). After running the four models above, any predictor that significantly (p &lt;.05) predicted Unit Task Performance will be added into Model 6a, which will be our Large model (containing all predictors that significantly predicted Unit Task Performance in the simple models). We will construct model 6a hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 6a). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

##Make model dfs
```{r, include = FALSE}
#currently for Exp 1
sf.df.cross <- all.data %>%
  filter(Task == "SF", 
         Language == "Cantonese" |
           Language == "Slovenian" | 
           Language == "English (US)")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Language = factor(Language, levels = c("Cantonese", "Slovenian", "English (US)"))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))%>%
  filter(!is.na(highest_contig.c)) #filter out kids who do not have HCNN
  
wcn.df.cross <- all.data %>%
  filter(Task == "NN",
         Language == "Cantonese" |
           Language == "Slovenian" | 
           Language == "English (US)")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))

##For India
sf.df.cross.india <- all.data %>%
  filter(Task == "SF", 
         Language == "English (US)" |
           Language == "Hindi" | 
           Language == "Gujarati")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Language = factor(Language, levels = c("English (US)", "Hindi", "Gujarati"))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))%>%
  filter(!is.na(highest_contig.c)) #filter out kids who do not have HCNN

wcn.df.cross.india <- all.data %>%
  filter(Task == "NN", 
         Language == "English (US)" |
           Language == "Hindi" | 
           Language == "Gujarati")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Language = factor(Language, levels = c("English (US)", "Hindi", "Gujarati"))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))%>%
  filter(!is.na(highest_contig.c)) #filter out kids who do not have HCNN

#followup with Indian English 
wcn.df.cross.india.follow <- all.data %>%
  filter(Task == "NN", 
         Language == "English (India)" |
           Language == "Hindi" | 
           Language == "Gujarati")%>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)), 
         Language = factor(Language, levels = c("English (India)", "Hindi", "Gujarati"))) %>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))%>%
  mutate(Language = factor(Language))%>%
  filter(!is.na(highest_contig.c)) #filter out kids who do not have HCNN
```

---

#Unit Task: Cross linguistic models - HK/SLO/US
##Build the models
```{r}
#base
sf.cross.base <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#productivity
sf.cross.model1 <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c +age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#fhc
sf.cross.model2 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#highest contig.
sf.cross.model3 <- glmer(Correct ~ highest_contig.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = sf.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

##exploratory - prod.gain
sf.cross.model.gain <- glmer(Correct ~ prod.gradient + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = sf.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
```

##Cross-linguistic model comparison
```{r}
mtable.sf.cross <- mtable('Base Model' = sf.cross.base,
            'Model 1: Productivity' = sf.cross.model1,
            'Model 2: FHC' = sf.cross.model2,
            'Model 3: Highest Contig.' = sf.cross.model3, 
            'Exp: Prod. gradient' = sf.cross.model.gain,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.cross
```

##Model Comparisons
###Base v. productivity - NS, p = .26
```{r}
anova(sf.cross.base, sf.cross.model1, test = 'LRT')
```

###Base v. FHC - NS
```{r}
anova(sf.cross.base, sf.cross.model2, test = 'LRT')
```

###Base v. Highest contig. - Sig, Chisq(1) = 16.665, p < .0001
```{r}
anova(sf.cross.base, sf.cross.model3, test = 'LRT')
```

##Large model - no model comparison needed, only sig. predictor above is HCNN
```{r}

summary(sf.cross.model3)

```

#Test if effects of language are significant
```{r}
sf.nolang.base <- glmer(Correct ~ highest_contig.c + ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                         data = sf.df.cross, family = "binomial", 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
sf.nolang.model1 <- glmer(Correct ~ highest_contig.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                         data = sf.df.cross, family = "binomial", 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
anova(sf.nolang.base, sf.nolang.model1, test = 'LRT') 
```

***
#Unit Task: Cross linguistic models - India (English/Hindi/Gujarati)
##Build the models
```{r}
#base
sf.cross.base.india <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#productivity
sf.cross.model1.india <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c +age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#fhc
sf.cross.model2.india <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#highest contig.
sf.cross.model3.india <- glmer(Correct ~ highest_contig.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = sf.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

##exploratory - prod.gain
sf.cross.model.gain.india <- glmer(Correct ~ prod.gradient + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = sf.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
```

##Cross-linguistic model comparison
```{r}
mtable.sf.cross.india <- mtable('Base Model' = sf.cross.base.india,
            'Model 1: Productivity' = sf.cross.model1.india,
            'Model 2: FHC' = sf.cross.model2.india,
            'Model 3: Highest Contig.' = sf.cross.model3.india, 
            'Exp: Prod. gradient' = sf.cross.model.gain.india,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.cross.india
```

##Model Comparisons
###Base v. productivity - NS, p = .76
```{r}
anova(sf.cross.base.india, sf.cross.model1.india, test = 'LRT')
```

###Base v. FHC - NS, p = .97
```{r}
anova(sf.cross.base.india, sf.cross.model2.india, test = 'LRT')
```

###Base v. Highest contig. - Sig, Chisq(1) = 6.98, p = .008, AIC = 3943.3
```{r}
anova(sf.cross.base.india, sf.cross.model3.india, test = 'LRT')
```

##Large model - no model comparison needed, only sig. predictor above is HCNN
```{r}

summary(sf.cross.model3.india)
```

#Cross-linguistic comparison of mean performance on unit task 
```{r}
sf.df.cross.india.ms <- sf.df.cross.india %>%
  group_by(SID, Language, age.c, wppsi.c)%>%
  summarise(mean_sf = mean(Correct, na.rm = TRUE))

lm.india <- lm(mean_sf ~ Language*age.c + wppsi.c, data = sf.df.cross.india.ms)
summary(lm.india)
```
---

##WCN India
##Build the models
```{r}
#base
wcn.cross.base.india <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#Productivity
wcn.cross.model1.india <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross.india, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#FHC
wcn.cross.model2.india <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross.india, family = "binomial", 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

```

##Cross-linguistic model comparison
```{r}
mtable.wcn.cross.india <- mtable('Base Model' = wcn.cross.base.india,
            'Model 1: Productivity' = wcn.cross.model1.india,
            'Model 2: FHC' = wcn.cross.model2.india,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.cross.india
```

##Model comparisons
###Base v. Productivity - Sig, Chisq(1) = 10.19, p = .001, AIC = 2520.5
```{r}
anova(wcn.cross.base.india, wcn.cross.model1.india, test = 'LRT')
```

###Base v. FHC - Sig, Chisq(1) = 23.457, p < .0001, AIC = 2507.2
```{r}
anova(wcn.cross.base.india, wcn.cross.model2.india, test = 'LRT')
```

##Large model
```{r}
#FHC
wcn.cross.plus1.india <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross.india, 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#Prod + FHC
wcn.cross.plus2.india <- glmer(Correct ~ Productive + fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross.india, 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

anova(wcn.cross.plus1.india, wcn.cross.plus2.india, test = 'LRT')

mtable.wcn.cross.large.india <- mtable('FHC alone' = wcn.cross.plus1,
            'Productive + FHC.' = wcn.cross.plus2,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.cross.large.india

#summary of final model
summary(wcn.cross.plus1.india)

```

#Test if effects of language are significant
```{r}
wcn.nolang.base <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial", 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
wcn.nolang.model1 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial", 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
anova(wcn.nolang.base, wcn.nolang.model1, test = 'LRT') 
```

##Build the models
```{r}
#base
wcn.cross.base <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#Productivity
wcn.cross.model1 <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#FHC
wcn.cross.model2 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross, family = "binomial", 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

```

##Cross-linguistic model comparison
```{r}
mtable.wcn.cross <- mtable('Base Model' = wcn.cross.base,
            'Model 1: Productivity' = wcn.cross.model1,
            'Model 2: FHC' = wcn.cross.model2,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.cross
```

##Model comparisons
###Base v. Productivity - Sig, Chisq(1) = 16.717, p < .0001, AIC = 2869.6
```{r}
anova(wcn.cross.base, wcn.cross.model1, test = 'LRT')
```

###Base v. FHC - Sig, Chisq(1) = 38.19, p < .0001, AIC = 2848.2
```{r}
anova(wcn.cross.base, wcn.cross.model2, test = 'LRT')
```

##Large model
```{r}
wcn.cross.plus1 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross, 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
wcn.cross.plus2 <- glmer(Correct ~ Productive + fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                           (1|SID), family = "binomial", data = wcn.df.cross, 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

anova(wcn.cross.plus1, wcn.cross.plus2, test = 'LRT')
mtable.wcn.cross.large <- mtable('FHC alone' = wcn.cross.plus1,
            'Productive + FHC.' = wcn.cross.plus2,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.cross.large

#summary of final model
summary(wcn.cross.plus1)

```

#Test if effects of language are significant
```{r}
wcn.nolang.base <- glmer(Correct ~ fhc.c + ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial", 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
wcn.nolang.model1 <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial", 
                         control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
anova(wcn.nolang.base, wcn.nolang.model1, test = 'LRT') 
```


---
#Followup with Indian English for NN
##Build the models
```{r}
#base
wcn.cross.base.india.follow <- glmer(Correct ~ Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross.india.follow, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#Productivity
wcn.cross.model1.india.follow <- glmer(Correct ~ Productive + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross.india.follow, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
#FHC
wcn.cross.model2.india.follow <- glmer(Correct ~ fhc.c + Language*ihc.c + count_range + starting_num.c + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross.india.follow, family = "binomial", 
                          control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))

```

##Cross-linguistic model comparison
```{r}
mtable.wcn.cross.india.follow <- mtable('Base Model' = wcn.cross.base.india.follow,
            'Model 1: Productivity' = wcn.cross.model1.india.follow,
            'Model 2: FHC' = wcn.cross.model2.india.follow,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.wcn.cross.india.follow
```

##Model comparisons
###Base v. Productivity - NS
```{r}
anova(wcn.cross.base.india.follow, wcn.cross.model1.india.follow, test = 'LRT')
```

###Base v. FHC - Sig, Chisq(1) = 8.09, p = .004, AIC = 2099.7
```{r}
anova(wcn.cross.base.india.follow, wcn.cross.model2.india.follow, test = 'LRT')
```

##Large model
```{r}
summary(wcn.cross.model2.india.follow)
```

---

#Cross-linguistic comparison for mean performance on NN task (India)
```{r}
nn.ms <- all.data %>%
  filter(Task == "NN", 
         Language == "English (India)" | 
           Language == "Gujarati" | 
           Language == "Hindi")%>%
  group_by(SID)%>%
  mutate(mean_nn = mean(Correct, na.rm = TRUE))

lm1 <- lm(mean_nn ~ Language*Age + sum_wppsi, data = nn.ms)
summary(lm1)
```

---

#Cross-linguistic comparison for mean performance on Unit task (India)
```{r}
sf.ms <- all.data %>%
  filter(Task == "SF", 
         Language == "English (India)" | 
           Language == "Gujarati" | 
           Language == "Hindi")%>%
  group_by(SID)%>%
  mutate(mean_sf = mean(Correct, na.rm = TRUE))

lm2 <- lm(mean_sf ~ Language*Age + sum_wppsi, data = sf.ms)
summary(lm2)
```

---

#Counting distribution
We plan to conduct descriptive analyses to describe the ways in which Initial Highest Count differs across
languages.
```{r}
hc.df %>%
  group_by(Language)%>%
  summarise(mean = mean(IHC, na.rm = TRUE), 
            sd = sd(IHC, na.rm = TRUE), 
            median = median(IHC, na.rm = TRUE))
```

In addition, we plan to test whether children in transparent languages can become productive with less counting experience. To test this, we will consider non-productive counters (those who were labeled as non-Productive). We will then ask whether IHC for these non-productive counters differs across languages. We will only conduct these analyses if we have at least 30 non-productive counters in each language. If count-list transparency allows children to converge on a productive count rule more quickly, then children who learn a system with a transparent-count list should move to the productive counter category on the basis of relatively less experience than children who learn a system with an opaque- count list. This predicts that, when considering non-Productive counters, initial highest count should be higher for opaque languages (like English) than for Slovenian, and higher for Slovenian than for Cantonese. The model would like this: 

Model 1: IHC ~ Language + Age + WM, data = NonProductiveCounters

###Model
```{r}
ihc.cross <- all.data %>%
   filter(!is.na(Productive))%>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  distinct(SID, Language, Age, sum_wppsi, Productive, IHC, Dataset)%>%
  filter(Productive == "Nonproductive")%>%
  mutate(Language = factor(Language))%>%
  mutate(age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale = TRUE)))

ihc.cross.hk.slo <- ihc.cross %>%
  filter(Dataset == "HK/SLO/US")

ihc.cross.model.hk.slo <- lm(IHC ~ Language + age.c + wppsi.c, data = ihc.cross.hk.slo)
summary(ihc.cross.model.hk.slo)

ihc.cross.ind <- ihc.cross %>%
  filter(Dataset == "India")

ihc.cross.model.ind <- lm(IHC ~ Language + age.c + wppsi.c, data = ihc.cross.ind)
summary(ihc.cross.model.ind)
```

In addition, we will test whether count-list transparency allows children to acquire some degree of productivity, even before they are labeled productive counters based on their overall counting performance. To test this, we will predict Highest Contiguous Next Number from Language. If transparent languages allow children to generate a productive counting rule, speakers of these transparent languages may perform better on the Next Number task than speakers of non- transparent languages, even when only considering non-productive counters. Model 2: Highest.Contiguous.NextNumber ~ Language + Age + WM + (1|subject), data = NonProductiveCounters

###Model: No effect of Language here
```{r}
wcn.model <- all.data %>%
  mutate(Dataset = ifelse(Language == "English (US)" | Language == "Cantonese" |
                            Language == "Slovenian", "HK/SLO/US", "India"))%>%
  distinct(SID, Language, Age, sum_wppsi, Productive, highest_contig, Dataset)%>%
  filter(Productive == "Nonproductive")%>%
  mutate(Language = factor(Language))%>%
  mutate(age.c = as.vector(scale(Age, center = TRUE, scale=FALSE)), 
         wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale = TRUE)))

wcn.model.hk.slo <- wcn.model %>%
  filter(Dataset == "HK/SLO/US")

highest_contig.model.hk.slo <- lm(highest_contig ~ Language + age.c + wppsi.c, data = wcn.model.hk.slo)
summary(highest_contig.model.hk.slo)

wcn.model.ind <- wcn.model %>%
  filter(Dataset == "India")

highest_contig.model.ind <- lm(highest_contig ~ Language + age.c + wppsi.c, data = wcn.model.ind)
summary(highest_contig.model.ind)

```
---

#Exploratory - predicting Unit Task from clustering
```{r}
#test with US English
tmp.English <- all.data %>%
  filter(Task == "SF", 
         Language == "English (US)")%>%
  distinct(SID, IHC, FHC)%>%
  group_by(SID)%>%
  summarise(n = n())%>%
  filter(n != 1)
```

TO-do for RMS: 
- Follow up analysis for productivity:lang interactions: In the event that, when analyzing each language group separately, we find evidence that a particular counting/productivity measure (Next Number, Final HC, Productivity) improves model fit for one language group by not another, we will conduct a follow-up analysis testing whether productivity classification interacts with language group. We will compare the model containing an interaction to one that excludes the interaction. It is important to note that our critical effect of interest is not necessarily a [Productivity Measure]:[Language Group] interaction, although finding such an interaction may be interpretable (e.g., it may suggest that productivity predicts other measures to a greater degree in some languages vs. others): ProductivityLang: Unit ~ Productivity Measure (Highest NN, FHC, Productivity classification)*Language.Group +
Language*IHC + Within/Outside range + Age + WM (1|subject)
- Exploratory analyses
- Cluster analysis...
- Frequency of error types
- Test whether modes differ across languages
- Include vs. exclude memory check failure SF trials
- Highest contiguous Successor vs. Highest contiguous NN
- Teacher survey data...
- Comparison of numbers on NN and SF
- Comparison of above and below 100 for NN and SF
- 