---
title: "XCulture Analysis"
author: "Rose M. Schneider"
date: "8/5/2018"
output: html_document
---
#Setup
```{r setup, include=FALSE}
rm(list = ls())
require("knitr")
opts_knit$set(root.dir = "~/Documents/Projects/xculture/HK_SLO") #this is specific to RMS, change accordingly
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)

'%!in%' <- function(x,y)!('%in%'(x,y))
```

##Load data
###Slovenian
```{r}
#demos
slo.demo <- read.csv('Data/slo_demo.csv')%>%
  mutate(dataset = "SLO")%>%
  filter(SID != "")
#give n
slo.gn <- read.csv("Data/slo_given.csv")%>%
  mutate(dataset = "SLO")%>%
  select(-age)%>%
  filter(SID != "")
#highest count
slo.hc <- read.csv("Data/slo_hc.csv")%>%
  mutate(dataset = "SLO")%>%
  select(-age)%>%
  filter(SID != "")
#sf
slo.sf <- read.csv("Data/slo_sf.csv")%>%
  mutate(dataset = "SLO")%>%
  select(-age)%>%
  filter(SID != "")%>%
  mutate(num_answer = factor(num_answer))%>%
  mutate(mem_check_1 = factor(mem_check_1), 
         mem_check_2 = factor(mem_check_2))
#wcn
slo.wcn <- read.csv("Data/slo_wcn.csv")%>%
  mutate(dataset = "SLO")%>%
  select(-age)%>%
  filter(SID != "")%>%
  mutate(num_answer = factor(num_answer), 
         repeat_1 = factor(repeat_1), 
         repeat_2 = factor(repeat_2))
#wppsi
slo.wppsi <- read.csv("Data/slo_wppsi.csv")%>%
  mutate(dataset = "SLO")%>%
  filter(SID != "")%>%
  select(-age)
```

###Hong Kong 
```{r}
#demos
hk.demo <- read.csv('Data/hk_demo.csv')%>%
  mutate(dataset = "HK")%>%
  filter(SID != "")
#give n
hk.gn <- read.csv("Data/hk_given.csv")%>%
  mutate(dataset = "HK")%>%
  filter(SID != "")%>%
  select(-age)%>%
  mutate(trial = ifelse(trial == "second try", 6, trial))
#highest count
hk.hc <- read.csv("Data/hk_hc.csv")%>%
  mutate(dataset = "HK")%>%
  select(-age)%>%
  filter(SID != "")%>%
  mutate(last_successful = factor(last_successful))
#sf
hk.sf <- read.csv("Data/hk_sf.csv")%>%
  mutate(dataset = "HK")%>%
  select(-age)%>%
  filter(SID != "")%>%
  mutate(num_answer = factor(num_answer))%>%
  mutate(mem_check_1 = factor(mem_check_1), 
         mem_check_2 = factor(mem_check_2))
#wcn
hk.wcn <- read.csv("Data/hk_wcn.csv")%>%
  mutate(dataset = "HK")%>%
  select(-age)%>%
  filter(SID != "")%>%
  mutate(num_answer = factor(num_answer), 
         repeat_1 = factor(repeat_1), 
         repeat_2 = factor(repeat_2))
#wppsi
hk.wppsi <- read.csv("Data/hk_wppsi.csv")%>%
  mutate(dataset = "HK")%>%
  select(-age)%>%
  filter(SID != "")
```

###Bind these datasets together 
```{r, warning = FALSE}
#demos
demo.raw <- bind_rows(slo.demo, hk.demo)%>%
  mutate(SID = factor(SID))

#given
given.raw <- bind_rows(slo.gn, hk.gn)%>%
  mutate(SID = factor(SID))

#hc
hc.raw <- bind_rows(slo.hc, hk.hc)%>%
  mutate(SID = factor(SID))

#sf 
sf.raw <- bind_rows(slo.sf, hk.sf)%>%
  mutate(SID = factor(SID))

#wcn
wcn.raw <- bind_rows(slo.wcn, hk.wcn)%>%
  mutate(SID = factor(SID))

#wppsi
wppsi.raw <- bind_rows(slo.wppsi, hk.wppsi)%>%
  mutate(SID = factor(SID))

```

---
#Exclusions
##Global exclusions
```{r}
#first, get every exclusion from every df
#this is a function that filters down to to excluded participants
exclude <- function(df){
  exclusions <- df %>%
    filter(exclude == 1)%>%
    distinct(SID, exclude, exclude_reason, dataset)
  
    exclusions$dataframe = deparse(substitute(df))
    return(exclusions)
}

#run this function over every df
get_all_exclusions <- function(){
  demo.ex <- exclude(demo.raw)
  given.ex <- exclude(given.raw)
  hc.ex <- exclude(hc.raw)
  sf.ex <- exclude(sf.raw)
  wcn.ex <- exclude(wcn.raw)
  wppsi.ex <- exclude(wppsi.raw)
  all_excl <- bind_rows(demo.ex, given.ex, hc.ex, sf.ex, wcn.ex, wppsi.ex)
  return(all_excl)
}

all_exclusions <- get_all_exclusions()

##Now, filter these down to unique SIDs
##To-do for RMS: You need to standardize exclusion reasons later
unique_exclusions <- all_exclusions%>%
  distinct(SID, exclude_reason)
unique_exclusions

##Now, exclude these participants from all dataframes
exclude_SIDs <- as.vector(unique_exclusions$SID)
#demographics
demo.df <- demo.raw%>%
  filter(SID %!in% exclude_SIDs)%>%
  filter(SID != "19072018-E") #manual exclude - change later
#given
given.df <- given.raw%>%
  filter(SID %!in% exclude_SIDs)%>%
  filter(SID != "19072018-E") #manual exclude - change later
#hc
hc.df <- hc.raw%>%
  filter(SID %!in% exclude_SIDs)%>%
  filter(SID != "19072018-E") #manual exclude - change later
#sf 
sf.df <- sf.raw%>%
  filter(SID %!in% exclude_SIDs)%>%
  filter(SID != "19072018-E") #manual exclude - change later
#wcn
wcn.df <- wcn.raw%>%
  filter(SID %!in% exclude_SIDs)%>%
  filter(SID != "19072018-E") #manual exclude - change later
#wppsi
wppsi.df <- wppsi.raw%>%
  filter(SID %!in% exclude_SIDs)%>%
  filter(SID != "19072018-E") #manual exclude - change later

##all kids who needed to be globally excluded should now be
```

##Task exclusions for SF, WCN, and WPPSI
```{r}
sf.df %<>%
  mutate(exclude_task = ifelse(is.na(exclude_task), 0, 1))%>%
  filter(exclude_task != 1)

wcn.df %<>%
  mutate(exclude_task = ifelse(is.na(exclude_task), 0, 1))%>%
  filter(exclude_task != 1)

wppsi.df %<>%
  mutate(exclude_task = ifelse(is.na(exclude_task), 0, 1))%>%
  filter(exclude_task != 1)
```

##Trial exclusions
How many trials are we going to exclude from each task
```{r}
#get the SIDs that failed practice
sf.fail <- sf.df %>%
  filter(trial == "practice", 
         correct == 0)

sf.failed.SIDs <- as.vector(unique(sf.fail$SID))

sf.df %>%
  filter(exclude_trial == 1 |
           is.na(exclude_trial))%>%
  group_by(exclude_trial_reason)%>%
  summarise(n = n())%>%
  mutate(total = sum(n))

#get the SIDS that failed practice
wcn.fail <- wcn.df %>%
  filter(trial == "practice", 
         correct == 0)

wcn.failed.SIDs <- as.vector(unique(wcn.fail$SID))

wcn.df %>%
  filter(exclude_trial == 1 |
           is.na(exclude_trial))%>%
  group_by(exclude_trial_reason)%>%
  summarise(n = n())%>%
  mutate(total = sum(n))

```

##Exclude trials and practice trials, also participants that should be excluded from a particular task
```{r}
sf.df%<>%
  filter(exclude_trial != 1, 
         trial != "practice")%>%
  mutate(exclude_task = ifelse(is.na(exclude_task), 0, exclude_task))%>%
  filter(exclude_task != 1)
  

wcn.df %<>%
  filter(exclude_trial != 1, 
         trial != "practice")%>%
  mutate(exclude_task = ifelse(is.na(exclude_task), 0, exclude_task))%>%
  filter(exclude_task != 1)

given.df %<>%
  filter(exclude_trial != 1)
```

---
#Data manipulations
##Classify kids as CP or subset
```{r}
classify.cp <- function(){
  tmp <- given.df %>%
    group_by(SID, dataset)%>%
    summarise(sum.corr = sum(correct))%>%
    mutate(knower.level = ifelse(sum.corr >= 4, "CP", "subset"))%>%
    distinct(SID, dataset, knower.level)
}

cp.lookup <- classify.cp()

#number of subset and CP knowers by group
cp.lookup %>%
  group_by(knower.level, dataset)%>%
  summarise(n = n())

cp.lookup %<>%
  select(-dataset)

##Filtering out the NA datasets as we go, because there are kids excluded in particular tasks that might have data from other tasks
hc.df <- right_join(hc.df, cp.lookup, by = "SID")%>%
  mutate(SID = factor(SID))%>%
  filter(!is.na(dataset))
given.df <- right_join(given.df, cp.lookup, by = "SID")%>%
  mutate(SID = factor(SID))%>%
  filter(!is.na(dataset))
sf.df <- right_join(sf.df, cp.lookup, by = "SID")%>%
  mutate(SID = factor(SID))%>%
  filter(!is.na(dataset))
wcn.df <- right_join(wcn.df, cp.lookup, by = "SID")%>%
  mutate(SID = factor(SID))%>%
  filter(!is.na(dataset))
wppsi.df <- right_join(wppsi.df, cp.lookup, by = "SID")%>%
  mutate(SID = factor(SID))%>%
  filter(!is.na(dataset))
```


##Classify kids as productive or nonproductive
```{r, warning = FALSE}
hc.df %<>%
  mutate(last_successful = ifelse(last_successful == "Is quiet", "IDK", last_successful))

hc <- hc.df %>% # replace with your local path
  select(SID, last_successful, initial_highest, final_highest) %>%
  mutate_at(c('last_successful','initial_highest','final_highest'),
            function(col) as.integer(str_replace_all(col,'\\D',''))) %>% # some of these included '?', so i remove any char thats not a digit
  mutate(last_successful = ifelse(is.na(last_successful), 140, last_successful))%>%
  filter(!is.na(initial_highest))

tmp <- hc %>%
  distinct(SID, initial_highest)%>%
  group_by(SID)%>%
  summarise(n = n())%>%
  filter(n > 1)
# 
# 
is.productive = function(subject){
  # takes as input the data for a single subject
  # RULES:
  # - counts to 120 unaided = productive
  # - after making first error, counts >= 20 higher, with no more than 3 errors on way
  if(subject$initial_highest[1] >= 140){
    # if they get to 120 on first try, = productive
    return(TRUE)
  } else if(subject$final_highest[1] == 140 & nrow(subject) < 4) {
    return(TRUE)
  } else if(subject$final_highest[1] < 140 & nrow(subject) == 1 
            & subject$final_highest[1] == subject$initial_highest[1]) {
    return(FALSE)
  } else if((subject$final_highest[1] - subject$initial_highest[1]) >= 20){
    # if their final is >= 20 larger than their intial...
    if(nrow(subject) < 4){
      # and they've made 3 or fewer total errors, = productive
      return(TRUE)
    } 
    else {
      for(i in 1:nrow(subject)){ # start at row 2
        # check if they ever made it >= 20 counts & <= 3 errors after an error
        runLength = 0 # they just made an error, so no post-error successes yet
        numErrors = 0 # first row was an error if it's not finalCount == 120
        prev = subject$last_successful[i]
        for (j in i+1:nrow(subject)){ # from current row until end...
          numErrors = numErrors + 1 # new row means new error
          runLength = runLength + (subject$last_successful[j] - prev)
          # ^ add difference between current count and last count to run length
          prev = subject$last_successful[j] # update last count
          if(runLength >= 20 & numErrors < 4){
            # if at any point the productivity conditions are met...
            return(TRUE) # = productive
          }
        }
      }
      # productivity conditions were never met (because we got to this point) so...
      return(FALSE) # != productive
    }
  } else {
    # highest is not >= 20 greater than initial
    return(FALSE)
  }
}

# #issues: not working for multiple errors
# #last successful doesn't not always equal final highest count
# 
#make function to run for all participants
unique_SIDs <- as.vector(unique(hc.df$SID))
# 
class_prod <- function(vector) {
  temp_data <- data.frame()
  for (i in vector) {
   
    prod.class <- data.frame(i, is.productive(subset(hc, SID == i)))
    names(prod.class) <- c("SID", "productive")
    temp_data <- bind_rows(temp_data, prod.class)
  }
  return(temp_data)
}
# 

productive <- class_prod(unique_SIDs)%>%
  rename(check_prod = productive)%>%
  mutate(check_prod = ifelse(check_prod == TRUE, "productive", "nonproductive"))

productive_SIDS <- productive %>%
  filter(check_prod == "productive")%>%
  distinct(SID)

#assign these to a vector
prod_SIDS <- as.vector(productive_SIDS$SID)

#This is a function that checks a SID against the productive SIDs in the vector above, and then classifies a participant as Productive or Nonproductive
productivity_classification <- function(df) {
  tmp <- df %>%
    mutate(productive = ifelse(SID %in% prod_SIDS, "productive", "nonproductive"))
  return(tmp)
}

#Assign productivity across all tasks
sf.df <- productivity_classification(sf.df)%>%
  filter(!is.na(dataset))
wcn.df <- productivity_classification(wcn.df)%>%
  filter(!is.na(dataset))
hc.df <- productivity_classification(hc.df)%>%
  filter(!is.na(dataset))
given.df <- productivity_classification(given.df)%>%
  filter(!is.na(dataset))
wppsi.df <- productivity_classification(wppsi.df)%>%
  filter(!is.na(dataset))
```

##Make sure everything that is coded as correct is actually correct
```{r}
##SF##
tmp <- sf.df %>%
  mutate(correct_check = ifelse(as.numeric(num_answer) == (starting_num + 1), 1, 0))%>%
  mutate(check = ifelse(correct == correct_check, TRUE, FALSE))%>%
  filter(check == FALSE)

#review these, then run the following
sf.df %<>%
  mutate(correct = ifelse(as.numeric(num_answer) == (starting_num + 1), 1, 0))

##WCN##
tmp <- wcn.df %>%
  mutate(correct_check = ifelse(as.numeric(as.character(num_answer)) == (starting_num + 1), 1, 0))%>%
  mutate(check = ifelse(correct == correct_check, TRUE, FALSE))%>%
  filter(check == FALSE)

#review these, then run the following
wcn.df %<>%
  mutate(correct = ifelse(correct == 2, NA, correct))%>%
  filter(!is.na(correct))%>%
  mutate(correct = ifelse(as.numeric(as.character(num_answer)) == (starting_num + 1), 1, 0))
```

##Highest contiguous NN
```{r, warning = FALSE}
#get unique ids
unique.nn <- wcn.df %>%
  distinct(SID)

unique.nn <- as.vector(unique.nn$SID)
nextnums <- as.vector(c(5, 7, 16, 24, 52, 71, 105, 107, 116, 224, 252, 271))

#this is a function that pulls out the largest number for which a participant had a correct consecutive
get_contiguous <- function(){
  contig <- data.frame()
  for (sub in unique.nn) {
    tmp <- wcn.df %>%
      filter(SID == sub, 
             correct == 0)%>%
      mutate(starting_num = sort(starting_num))
    if (length(tmp$SID) == 0) {
      highest_contig = 271
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else if (sub %in% wcn.failed.SIDs) {
      highest_contig = 0
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else if (length(tmp$starting_num) > 0 & min(tmp$starting_num) == 5) {
      highest_contig = 1
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else {
      min.nn <- min(tmp$starting_num)
      prev_correct <- nextnums[nextnums < min.nn]
      highest_contig <- max(prev_correct)
    
      sub_contig <- data.frame(sub,
                             highest_contig)
      contig <- bind_rows(contig, sub_contig)
    }
  }
  return(contig)
}

highest_contiguous_nn <- get_contiguous()%>%
  dplyr::rename(SID = sub)

#spread this to other dfs
given.df <- right_join(given.df, highest_contiguous_nn, by = "SID")%>%
  filter(!is.na(dataset))
hc.df <- right_join(hc.df, highest_contiguous_nn, by = "SID")%>%
  filter(!is.na(dataset))
sf.df <- right_join(sf.df, highest_contiguous_nn, by = "SID")%>%
  filter(!is.na(dataset))
wcn.df <- right_join(wcn.df, highest_contiguous_nn, by = "SID")%>%
  filter(!is.na(dataset))
wppsi.df <- right_join(wppsi.df, highest_contiguous_nn, by = "SID")%>%
  filter(!is.na(dataset))
```

##Within/beyond count range for SF and WCN
```{r}
sf.df %<>%
  filter(!is.na(correct))

wcn.df %<>%
  filter(!is.na(correct))

#first, get initial highest count for each kiddo
#Make a lookup table with SID and initial highest count
lookup <- hc.df %>%
  distinct(SID, initial_highest)

#This is a function that, for each trial, checks the number queried. If number queried is above the child's initial highest count, marks that trial as beyond count range.
determine_count_range <- function(df) {
  tmp <- df
  for (row in 1:nrow(tmp)) {
    sub = as.character(tmp[row, "SID"])
    count_range = subset(lookup, SID == sub)$initial_highest
    tmp[row, "initial_highest_count"] = count_range
    if (tmp[row, "starting_num"] > count_range) {
      tmp[row, "count_range"] = "outside"
    } else {
      tmp[row, "count_range"] = "within"
    }
  }
  return(tmp)
}

#Run for each task
sf.df <- determine_count_range(sf.df)%>%
  filter(!is.na(dataset))
wcn.df <- determine_count_range(wcn.df)%>%
  filter(!is.na(dataset))
```

##Spread information from demo to every df
```{r, warning = FALSE}
# first, create a lookup of unique SIDs and demo information
demo_lookup <- demo.df%>%
  distinct(SID, age, sex, experimenter, location)

hc.df <- right_join(hc.df, demo_lookup, by = "SID")%>%
  filter(!is.na(dataset))
given.df <- right_join(given.df, demo_lookup, by = "SID")%>%
  filter(!is.na(dataset))
sf.df <- right_join(sf.df, demo_lookup, by = "SID")%>%
  filter(!is.na(dataset))
wcn.df <- right_join(wcn.df, demo_lookup, by = "SID")%>%
  filter(!is.na(dataset))
wppsi.df <- right_join(wppsi.df, demo_lookup, by = "SID")%>%
  filter(!is.na(dataset))
```

##Add final highest count 
```{r}
final <- hc.df %>%
  distinct(SID, final_highest)

sf.df <- right_join(sf.df, final, by = "SID")
wcn.df <- right_join(wcn.df, final, by = "SID")
```

###Get WPPSI score, add to SF and WCN
```{r}
 #get sum per SID, add to sf and wcn for CROSS-LINGUISTIC models
 wppsi.sid <- wppsi.df %>%
   mutate(trial = factor(trial))%>%
  filter(trial != "sample item A", 
         trial != "sample item B", 
         trial != "Sample item A", 
         trial != 1, 
         trial != 2, 
         trial != 7, 
         trial != 8)%>%
   group_by(SID, dataset)%>%
   summarise(sum_wppsi = sum(correct))

sf.df.cross <- right_join(sf.df, wppsi.sid, by = "SID")
wcn.df.cross <- right_join(wcn.df, wppsi.sid, by = "SID")
```

Remove NAs that snuck in 
```{r}
sf.df %<>%
  filter(!is.na(dataset))
wcn.df %<>%
  filter(!is.na(dataset))
```

###Round age
```{r}
round_age <- function(df) {
  df %<>%
    mutate(age = round(age, 2))
  return(df)
}

#round age for every task df
sf.df <- round_age(sf.df)
given.df <- round_age(given.df)
wcn.df <- round_age(wcn.df)
hc.df <- round_age(hc.df)
wppsi.df <- round_age(wppsi.df)

ggplot(demo.df, aes(x = age, fill = dataset))+
  geom_histogram(binwidth = .5, colour = "black")+
  facet_grid(~dataset) + 
  scale_x_continuous(breaks = seq(3.5, 6.5, .5))

demo.df %>%
  filter(!is.na(dataset))%>%
  group_by(dataset)%>%
  summarise(M_age = mean(age), 
            SD_age = sd(age),
            median_age = median(age),
            n = n())
```
---
#Task visualizations
##Highest count
###Histogram Initial and Final Highest Count
```{r}
hc.df %<>%
  filter(!is.na(dataset))%>%
  mutate(initial_highest = ifelse(initial_highest > 140, 140, initial_highest), 
         final_highest = ifelse(final_highest > 140, 140, final_highest))

unique.hc.data <- hc.df %>%
  distinct(SID, initial_highest, final_highest, productive, dataset)%>%
  gather(IHC_FHC,highest_count, initial_highest:final_highest)%>%
  mutate(highest_count = as.integer(highest_count), 
         IHC_FHC = factor(IHC_FHC, levels = c("initial_highest", "final_highest"), 
                          labels = c("Initial Highest Count", "Final Highest Count")))

#initial
ggplot(unique.hc.data, aes(x=highest_count, fill=productive)) + 
  geom_histogram(binwidth = 10, colour = "black") +
  theme_bw(base_size = 10)+
  labs(title = "Initial/Final Highest Counts by Productivity and Dataset") +
  facet_grid(IHC_FHC~dataset) +
  scale_x_continuous(breaks = seq(0, 140, 10))+
  scale_fill_brewer(palette = "Dark2") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.minor = element_blank())

hc.df %>%
  filter(is.na(dataset))
```
###Scatterplot of IHC and FHC
```{r}
initial_final <- hc.df %>%
  filter(!is.na(dataset))%>%
  distinct(SID, dataset, initial_highest, final_highest, productive)%>%
  mutate(initial_highest = as.numeric(initial_highest), 
         initial_final = as.numeric(final_highest))

ggplot(initial_final, aes(x = initial_highest, y = final_highest, 
                          color = productive)) +
  geom_point(size = 1) + geom_jitter(width = .1) +
  labs(x = "Initial highest count", y = "Final highest count", 
                      color = "", title = "") +
  theme_bw(base_size = 13) + 
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) + 
  theme(panel.grid.minor = element_blank(), 
        legend.position = "bottom", 
        legend.text = element_text(size = 8)) + 
  facet_grid(~dataset) + 
  scale_color_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


###Productivity descriptives
```{r}
hc.df %>%
  filter(!is.na(dataset))%>%
  distinct(SID, age, productive, dataset, initial_highest, final_highest)%>%
  group_by(dataset, productive)%>%
  summarise(n = n(),
            mean_IHC = mean(initial_highest), 
            sd_IHC = sd(initial_highest), 
            median_IHC = median(initial_highest), 
            mean_FHC = mean(final_highest), 
            sd_FHC = sd(final_highest), 
            median_FHC = median(final_highest))
```
---
##Unit Task
###How many kids failed the memory checks in each dataset by number

```{r}
sf.df %<>%
  mutate(mem_check_1 = ifelse(is.na(mem_check_1), 1, mem_check_1))


#for SF
sf.df %<>%
  mutate(mem_check_status = ifelse((mem_check_1 == 1 & is.na(mem_check_2)), "need_1_pass_1",
                                    ifelse((mem_check_1 == 0 & mem_check_2 == 0), "need_2_fail_2",
                                           ifelse((mem_check_1 == 1 & mem_check_2 == 1),
                                                  "unclear_pass1_pass2",
                                                  ifelse((mem_check_1 == 1 & mem_check_2 == 0),
                                                         "unclear_pass1_fail2",
                                                         ifelse((mem_check_1 == 0 & mem_check_2 == 1),
                                                                "fail1_pass2", "other"))))))

sf.mem.ms <- sf.df %>%
  group_by(mem_check_status, productive, dataset)%>%
  summarise(n = n())

ggplot(subset(sf.mem.ms), aes(x = mem_check_status, y = n, fill = productive)) + 
  geom_bar(stat = "identity", position = position_dodge()) + 
  facet_grid(~dataset) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + guides(fill=FALSE)

#what about by number?
sf.mem.num.ms <- sf.df %>%
  mutate(starting_num = factor(starting_num))%>%
  group_by(starting_num, mem_check_status, dataset, productive)%>%
  summarise(n = n())

ggplot(subset(sf.mem.num.ms), aes(x = starting_num, y = n, fill = mem_check_status)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(productive~dataset) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
###Raw performance by dataset
```{r}
sf.minus.2 <- sf.df %>%
  filter(correct != 2)%>%
  group_by(SID, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(sf.minus.2, aes(x = dataset, y = mean, fill = dataset)) + 
   theme_bw() + 
  geom_boxplot()+
   langcog::scale_fill_solarized("Dataset")
```

###By productivity and dataset
```{r}
sf.minus.2 <- sf.df %>%
  filter(correct != 2)%>%
  group_by(SID, productive, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(sf.minus.2, aes(x = productive, y = mean, fill = productive)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Dark2") + 
   facet_grid(~dataset) +
   guides(fill = FALSE)
```

###By productivity and count range
```{r}
sf.minus.2 <- sf.df %>%
  filter(correct != 2)%>%
  group_by(SID, productive, count_range, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(sf.minus.2, aes(x = count_range, y = mean, fill = productive)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Dark2") + 
   facet_grid(~dataset)
```

###SF performance by number and productivity
```{r}
sf.minus.2.num <- sf.df %>%
  filter(correct != 2)%>%
  mutate(starting_num = factor(starting_num))%>%
  group_by(productive, dataset, starting_num)%>%
  langcog::multi_boot_standard("correct", na.rm = TRUE)

 ggplot(sf.minus.2.num, aes(x = starting_num, y = mean, fill = productive)) + 
  geom_bar(stat = "identity", position= position_dodge()) + 
  geom_linerange(aes(ymin = ci_lower,
                      ymax = ci_upper),
                  size = .3,
                  show.legend = FALSE,
                 position=position_dodge(width = 0.9))+
   theme_bw() + 
  facet_grid(~dataset) + 
   scale_fill_brewer(palette = "Dark2") + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
   theme(legend.position = "bottom")

```

###By knower-level
```{r}
sf.know <- sf.df %>%
  filter(correct != 2)%>%
  group_by(SID, knower.level, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(sf.know, aes(x = knower.level, y = mean, fill = knower.level)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Paired") +
   facet_grid(~dataset) +
   guides(fill = FALSE)
```

---
##WCN
###Raw performance by dataset
```{r}
wcn.minus.2 <- wcn.df %>%
  filter(correct != 2)%>%
  group_by(SID, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(wcn.minus.2, aes(x = dataset, y = mean, fill = dataset)) + 
  geom_boxplot() + 
   theme_bw() + 
   langcog::scale_fill_solarized("Dataset")
```

###By productivity and dataset
```{r}
wcn.minus.2 <- wcn.df %>%
  filter(correct != 2)%>%
  group_by(SID, productive, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(wcn.minus.2, aes(x = productive, y = mean, fill = productive)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Dark2") +
   facet_grid(~dataset) +
   guides(fill = FALSE)
```

###WCN by productivity and count range
```{r}
wcn.minus.2 <- wcn.df %>%
  filter(correct != 2)%>%
  group_by(SID, productive, count_range, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(wcn.minus.2, aes(x = count_range, y = mean, fill = productive)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Dark2") + 
   facet_grid(~dataset)
```

###WCN performance by number and productivity
```{r}
wcn.minus.2.num <- wcn.df %>%
  filter(correct != 2)%>%
  mutate(starting_num = factor(starting_num))%>%
  group_by(productive, dataset, starting_num)%>%
  langcog::multi_boot_standard("correct", na.rm = TRUE)

 ggplot(wcn.minus.2.num, aes(x = starting_num, y = mean, fill = productive)) + 
  geom_bar(stat = "identity", position= position_dodge()) + 
  geom_linerange(aes(ymin = ci_lower,
                      ymax = ci_upper),
                  size = .3,
                  show.legend = FALSE,
                 position=position_dodge(width = 0.9))+
   theme_bw() + 
  facet_grid(~dataset) + 
   scale_fill_brewer(palette = "Dark2") + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
   theme(legend.position = "bottom")

```

###By knower level
```{r}
wcn.know <- wcn.df %>%
  filter(correct != 2)%>%
  group_by(SID, knower.level, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(wcn.know, aes(x = knower.level, y = mean, fill = knower.level)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Paired") +
   facet_grid(~dataset) +
   guides(fill = FALSE)
```
---
##WPPSI
```{r}
#get score
wppsi.ms <- wppsi.df%>%
  mutate(trial = factor(trial))%>%
  filter(trial != "sample item A", 
         trial != "sample item B", 
         trial != "Sample item A", 
         trial != 1, 
         trial != 2, 
         trial != 7, 
         trial != 8)%>%
  mutate(trial = as.numeric(as.character(trial)))%>%
  group_by(SID, dataset)%>%
  summarise(sum_wppsi = sum(correct), 
            num_trials = n())

 ggplot(wppsi.ms, aes(x = dataset, y = sum_wppsi, fill = dataset)) + 
  geom_bar(stat = "identity", position = position_dodge())+
   theme_bw() + 
   guides(fill = FALSE)
 
 ggplot(wppsi.ms, aes(x = sum_wppsi, fill = dataset)) +
   geom_histogram(binwidth = 1, colour = "black") +
   theme_bw() + 
   facet_grid(~dataset)

```
---
#Main analyses
##Within-language analyses - simple models

###Make model analysis dfs
Note that there is a lot more variability in highest counts and highest contiguous NN than in categorical variables. I am centering age, and centering and scaling FHC, IHC, and highest contiguous NN (which has the most variability).
```{r}
##HK##
sf.hk.within <- sf.df%>%
  filter(dataset == "HK")%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)))
  
wcn.hk.within <- wcn.df%>%
  filter(dataset == "HK")%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)))

##SLO##
sf.slo.within <- sf.df%>%
  filter(dataset == "SLO")%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))
wcn.slo.within <- wcn.df%>%
  filter(dataset == "SLO")%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))
```

###Unit Task

This first set of analyses replicates, in Cantonese English and Slovenian speaking samples, analyses similar to those previously conducted on English-speaking subjects. To identify whether there is connection between counting experience and Unit Task performance for participants within particular language groups, we will conduct four initial analyses (plus the null model) within each language, predicting Unit Task performance from (1) Productivity (defined above); (2) Final Highest Count; (3) Initial Highest Count; and (4) Highest Contiguous Next Number.

All models will be logistic mixed effects models, predicting performance on the unit task (0 or 1) on a trial as a function of the following predictors, with a random intercept for subject. In R, the formula will be
glmer(predicted ~ (predictor) + age + within/outside range + (1|subject), family = binomial).

In each language, after running these first four models, any predictor that significantly (p &lt;.05) predicts Unit TaskPerformance (as assessed by running a likelihood ratio test on the Null Model (Model 0) and Models 1, 2, 3, and 4) will be added into Model 5, which will be our “Large” model. We will construct model 5 hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 5). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.


Model 0 (null model): Unit.Performance ~ Within/Outside range + Age + (1|subject)
Model 1: Unit.Performance ~ Productivity + Within/Outside range + Age + (1|subject)
Model 2: Unit.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
Model 3: Unit.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)
Model 4: Unit.Performance ~ Highest.Contiguous.Next.Number + Within/Outside range + Age + (1|subject)

####Hong Kong
```{r}
sf.hk.within.base <- glmer(correct ~ count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.base)
sf.hk.within.model1 <- glmer(correct ~ productive + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model1)
sf.hk.within.model2 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model2)
sf.hk.within.model3 <- glmer(correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model3)
sf.hk.within.model4 <- glmer(correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model4)
```

Compare whether predictor significantly predicts performance on unit task
```{r}
##Productivity##
anova(sf.hk.within.model1, sf.hk.within.base, test = 'LRT') #Productivity classification does not significantly predict SF performance

##Final Highest Count##
anova(sf.hk.within.model2, sf.hk.within.base, test = 'LRT') #FHC does significantly predict SF performance

##Initial Highest Count##
anova(sf.hk.within.model3, sf.hk.within.base, test = 'LRT') #IHC does significantly predict SF performance

##Highest contiguous NN##
anova(sf.hk.within.model4, sf.hk.within.base, test = 'LRT') ##Highest contiguous NN does significantly predict SF performance
```

We have three significant predictors of performance on the Unit task (FHC, IHC, and Highest Contiguous NN). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task. 
```{r}
##IHC and Highest Contig NN##
sf.hk.within.plus1 <- glmer(correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
sf.hk.within.plus2 <- glmer(correct ~ ihc.c + highest_contig.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)
anova(sf.hk.within.plus2, sf.hk.within.plus1, test = 'LRT') #highest contiguous does not significantly explain additional variance

##IHC and FHC##
sf.hk.within.plus2 <- glmer(correct ~ ihc.c + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)
anova(sf.hk.within.plus2, sf.hk.within.plus1, test = 'LRT') #final highest count does not significantly explain additional variance
```

Best predictor of Unit Task performance in Cantonese dataset is Initial Highest Count
####SLO

```{r}
sf.slo.within.base <- glmer(correct ~ count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.base)
sf.slo.within.model1 <- glmer(correct ~ productive + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model1)
sf.slo.within.model2 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model2)
sf.slo.within.model3 <- glmer(correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model3)
sf.slo.within.model4 <- glmer(correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within) 
summary(sf.slo.within.model4)
```

Compare whether predictor significantly predicts performance on unit task
```{r}
##Productivity##
anova(sf.slo.within.model1, sf.slo.within.base, test = 'LRT') #Productivity is marginally significant in predicting SF performance

##Final Highest Count##
anova(sf.slo.within.model2, sf.slo.within.base, test = 'LRT') #FHC barely significant in predicting SF performance

##Initial Highest Count##
anova(sf.slo.within.model3, sf.slo.within.base, test = 'LRT') #IHC marginally significant in predicting SF performance

##Highest contiguous NN##
anova(sf.slo.within.model4, sf.slo.within.base, test = 'LRT') ##Highest contiguous NN does significantly predict SF performance
```

Highest contiguous and Final Highest count best predictors - compare
```{r}
sf.slo.within.plus1 <- glmer(correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
sf.slo.within.plus2 <- glmer(correct ~ highest_contig.c + fhc.c + count_range + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
anova(sf.slo.within.plus2, sf.slo.within.plus2, test = 'LRT') #highest contig does not significantly explain additional variance
```

Final Highest Count best predictor of Unit Task performance in Slovenian

##Productivity t-test of SF performance
Using the Productive/Non-Productive categorical classification outlined above, we will compare performance
between both groups on the Unit task using t-tests. We may do this by considering average performance
(averaring the 0’s and 1’s on each task for each participant); should doing so provide greater precision, we may also compare Highest Contiguous Number.

###HK
```{r}
#with mean performance
sf.hk.mean.ms <- sf.hk.within %>%
  group_by(SID, productive)%>%
  summarise(mean = mean(correct))

t.test(subset(sf.hk.mean.ms, productive == "productive")$mean, 
       subset(sf.hk.mean.ms, productive == "nonproductive")$mean, var.equal = TRUE) #marginally significant difference between productive and nonproductive counters for performance on Unit Task
```

###SLO
```{r}
#with mean performance
sf.slo.mean.ms <- sf.slo.within %>%
  group_by(SID, productive)%>%
  summarise(mean = mean(correct))

t.test(subset(sf.slo.mean.ms, productive == "productive")$mean, 
       subset(sf.slo.mean.ms, productive == "nonproductive")$mean, var.equal = TRUE) #significant difference in performance between productive and nonproductive counters
```

##Productivity t-test of Highest contiguous NN
###HK
```{r}
sf.hk.mean.nn <- sf.hk.within %>%
  group_by(SID, productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.hk.mean.nn, productive == "productive")$mean_nn, 
       subset(sf.hk.mean.nn, productive == "nonproductive")$mean_nn, var.equal = TRUE)
```

###SLO
```{r}
sf.slo.mean.nn <- sf.slo.within %>%
  group_by(SID, productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.slo.mean.nn, productive == "productive")$mean_nn, 
       subset(sf.slo.mean.nn, productive == "nonproductive")$mean_nn, var.equal = TRUE)

ggplot(sf.slo.mean.nn, aes(x = productive, y = mean_nn, fill = productive)) + 
  geom_boxplot()+
  theme_bw()+
  scale_fill_brewer(palette = "Dark2") #Significant difference in highest mean contiguous NN for productive vs. nonproductive counters
```

---
##WCN Task- simple models

Model 0 (null model): NextNumber.Performance ~ Within/Outside range + Age + (1|subject)
Model 1: Next.Number.Performance ~ Productivity + Within/Outside range + Age + (1|subject)
Model 2: Next.Number.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
Model 3: Next.Number.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)

###HK
```{r}
wcn.hk.within.base <- glmer(correct ~ count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.base)
wcn.hk.within.model1 <- glmer(correct ~ productive + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model1)
wcn.hk.within.model2 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model2)
wcn.hk.within.model3 <- glmer(correct ~ ihc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model3)
```

Compare whether predictor significantly predicts performance on WCN task
```{r}
##Productivity##
anova(wcn.hk.within.model1, wcn.hk.within.base, test = 'LRT') #Productivity classification does not significantly predict WCN performance

##Final Highest Count##
anova(wcn.hk.within.model2, wcn.hk.within.base, test = 'LRT') #FHC does significantly predict SF performance

##Initial Highest Count##
anova(wcn.hk.within.model3, wcn.hk.within.base, test = 'LRT') #IHC does significantly predict SF performance
```

We have two significant predictors of performance on the Unit task (FHC and IHC). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task. 
```{r}
##IHC and Highest Contig NN##
wcn.hk.within.plus1 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.hk.within)
wcn.hk.within.plus2 <- glmer(correct ~ ihc.c + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.hk.within)
anova(wcn.hk.within.plus2, wcn.hk.within.plus1, test = 'LRT') #Initial Highest Count explains additional variance in WCN performance
```

###SLO
```{r}
wcn.slo.within.base <- glmer(correct ~ count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.base)
wcn.slo.within.model1 <- glmer(correct ~ productive + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model1)
wcn.slo.within.model2 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model2)
wcn.slo.within.model3 <- glmer(correct ~ ihc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model3)
```

Compare whether predictor significantly predicts performance on WCN task
```{r}
##Productivity##
anova(wcn.slo.within.model1, wcn.slo.within.base, test = 'LRT') #Productivity classification does significantly predict WCN performance

##Final Highest Count##
anova(wcn.slo.within.model2, wcn.slo.within.base, test = 'LRT') #FHC does significantly predict SF performance

##Initial Highest Count##
anova(wcn.slo.within.model3, wcn.slo.within.base, test = 'LRT') #IHC does significantly predict SF performance
```

We have three significant predictors of performance on the Unit task (Productivity, FHC and IHC). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task. 

```{r}
##Productive and FHC##
wcn.slo.within.plus1 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.slo.within)
wcn.slo.within.plus2 <- glmer(correct ~ productive + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)
anova(wcn.slo.within.plus2, wcn.slo.within.plus1, test = 'LRT') #Productivity does not explain additional variance

##IHC and FHC##
wcn.slo.within.plus2 <- glmer(correct ~ ihc.c + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)
anova(wcn.slo.within.plus2, wcn.slo.within.plus1, test = 'LRT') ##IHC does not explain additional variance
```

##Productivity t-test of SF performance
Using the Productive/Non-Productive categorical classification outlined above, we will compare performance
between both groups on the Next Number task using t-tests. We may do this by considering average performance
(averaring the 0’s and 1’s on each task for each participant).

###HK

```{r}
#with mean performance
wcn.hk.mean.ms <- wcn.hk.within %>%
  group_by(SID, productive)%>%
  summarise(mean = mean(correct))

t.test(subset(wcn.hk.mean.ms, productive == "productive")$mean, 
       subset(wcn.hk.mean.ms, productive == "nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

###SLO

```{r}
#with mean performance
wcn.slo.mean.ms <- wcn.slo.within %>%
  group_by(SID, productive)%>%
  summarise(mean = mean(correct))

t.test(subset(wcn.slo.mean.ms, productive == "productive")$mean, 
       subset(wcn.slo.mean.ms, productive == "nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```
---
#Cross-linguistic comparisons
Our second set of analyses is aimed at understanding cross-linguistic differences in performance on the Unit Task. To do this, we will analyze all participants, from all language groups, in a single model. We will then construct our models from above, but will add (a) a measure of Working Memory and (b) the interaction of Initial Highest Count and Language group to each model. These models therefore allow us to test whether (a) language; (b) counting ability; or (c) some interaction between the two predict unit performance. We include Working Memory in all cross-linguistic models with the intention of taking into account baseline differences in processing across samples.

Cross-Linguistic Models:
Model 0a (the Null Model): Unit.Performance~ Language*IHC + Within/Outside range + Age + WM
+ (1|subject)
Model 1a: Unit.Performance ~ Productivity + Language*IHC + Within/Outside range + Age + WM + (1|subject)
Model 2a: Unit.Performance ~ Final.Count + Language*IHC + Within/Outside range + Age + WM + (1|subject)
Model 3a: Unit.Performance ~ Highest.Contiguous.Next.Number + Language*IHC + Within/Outside range +
Age + WM + (1|subject)
Make model dfs


We will then compare Model 0a (the Null Model) to each of the models containing measures of productivity (1a, 2a, and 3a) using a likelihood ratio test in testing whether these measures of productivity significantly explain variance in children’s performance. Should effects of Language emerge, we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects (e.g., Unit.Performance ~ Productivity + IHC + Within/Outside range + Age + WM + (1|subject)). After running the four models above, any predictor that significantly (p &lt;.05) predicted Unit Task Performance will be added into Model 6a, which will be our “Large” model (containing all predictors that significantly predicted Unit Task Performance in the simple models). We will construct model 6a hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 6a). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

##Make model dfs
```{r}
##HK##
sf.df.cross %<>%
  select(-dataset.x, -X)%>%
  dplyr::rename(dataset = dataset.y)%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)))
  
wcn.df.cross %<>%
select(-dataset.x, -X)%>%
  dplyr::rename(dataset = dataset.y)%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)))

sf.df.cross %<>%
  mutate(Language = ifelse(dataset == "HK", "Cantonese", "Slovene"), 
         Language = factor(Language))

wcn.df.cross %<>%
  mutate(Language = ifelse(dataset == "HK", "Cantonese", "Slovene"), 
         Language = factor(Language))

sf.df.cross %<>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))

wcn.df.cross %<>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))
```

##Unit Task: Cross linguistic models

```{r}
sf.cross.base <- glmer(correct ~ Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.base)
sf.cross.model1 <- glmer(correct ~ productive + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
sumamry(sf.cross.model1)
sf.cross.model2 <- glmer(correct ~ fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.model2)
sf.cross.model3 <- glmer(correct ~ highest_contig.c + Language*ihc.c + count_range + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.model3)
```

Model comparison
```{r}
##Productivity##
anova(sf.cross.model1, sf.cross.base, test = 'LRT')#productivity does not significantly improve model fit

###FHC###
anova(sf.cross.model2, sf.cross.base, test = 'LRT')#Neither does FHC

##Highest NN##
anova(sf.cross.model3, sf.cross.base, test = 'LRT') #Highest contiguous NN does
```

---
##WCN
Our third set of analyses is aimed at understanding cross-linguistic differences in performance on the next number task. To do this, we will analyze all participants, from all language groups, in a single model. As above, we add WM, and the language by IHC interaction.
C
ross-Linguistic Models
Model 0b (the null model): Next.Number.Performance ~ Language*IHC + Within/Outside range + Age + WM +
(1|subject)
Model 1b: Next.Number.Performance ~ Productivity + Language*IHC + Within/Outside range + Age + WM +
(1|subject)
Model 2b: Next.Number.Performance ~ Final.Count + Language*IHC + Within/Outside range + Age + WM +
(1|subject)

Should effects of Language emerge, we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects. Should effects of Language emerge, we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects (e.g., Unit.Performance ~ Productivity + IHC + Within/Outside range + Age + WM + (1|subject)). After running these three models, any predictor that significantly (p &lt;.05) predicted Next Number Performance (as assessed by running a likelihood ratio test on the Null Model (Model 0b) and Models 1b and 2b) will be added into Model 7b, which will be our “Large” model (containing all predictors that significantly predicted Next Number Performance in the simple models).

We will construct Model 7b hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 7b). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.
```{r}
wcn.cross.base <- glmer(correct ~ Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross)
summary(wcn.cross.base)
wcn.cross.model1 <- glmer(correct ~ productive + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
summary(wcn.cross.model1)
wcn.cross.model2 <- glmer(correct ~ fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross, family = "binomial")
summary(wcn.cross.model2)
```

Model comparison - productivity effects
```{r}
##PRODUCTIVITY##
anova(wcn.cross.model1, wcn.cross.base, test = 'LRT')#Productivity not signficant

##FHC#
anova(wcn.cross.model2, wcn.cross.base, test = 'LRT')#FHC significant
```

There is a significant effect of Language: we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects (e.g., WCN.Performance ~ Productivity + IHC + Within/Outside range + Age + WM + (1|subject)).
```{r}
wcn.nolang.base <- glmer(correct ~ ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial")
wcn.nolang.model1 <- glmer(correct ~ fhc.c + ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial")
anova(wcn.nolang.model1, wcn.nolang.base, test = 'LRT') #FHC is still significant

```