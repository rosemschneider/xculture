---
title: "XCulture Analysis"
author: "Rose M. Schneider"
date: "8/5/2018"
output: html_document
---
TO-DO

#Setup
```{r setup, include=FALSE}
rm(list = ls())
require("knitr")
opts_knit$set(root.dir = "~/Documents/Projects/xculture/HK_SLO") #this is specific to RMS, change accordingly
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)

'%!in%' <- function(x,y)!('%in%'(x,y))
```

##Load data
###Slovenian
```{r}
#slo data
slo.full.data <- read.csv('Data/SLO_data.csv')%>%
  mutate(Exclude_task = ifelse(is.na(Exclude_task), 0, as.numeric(as.character(Exclude_task))))%>%
  mutate(Trial_number = ifelse(Trial_number == '0', "Training", as.character(Trial_number)), 
         Task_item = factor(Task_item))

#slo highest count
slo.hc <- read.csv('Data/SLO_HC.csv')
```

###Cantonese
```{r}
#hk data
hk.full.data <- read.csv('Data/HK_data.csv')%>%
  filter(SID != "CopyPasteMe")%>%
  droplevels()%>%
  mutate(Age = as.numeric(as.character(Age)), 
         Correct = as.integer(as.character(Correct)), 
         Mem_check_1 = as.integer(as.character(Mem_check_1)), 
         Mem_check_2 = as.integer(as.character(Mem_check_2)))

#hk highest count
hk.hc <- read.csv('Data/HK_HC.csv')
```

##Bind together
```{r, warning = FALSE}
#regular data
all.data <- bind_rows(slo.full.data, hk.full.data)%>%
  mutate(Age = round(Age, 2), 
         Agegroup = cut(Age, breaks = c(3.5, 4, 4.5, 5, 5.5, 6, 6.6), 
                        labels = c("3.5-4", "4-4.5", "4.5-5", 
                                   "5-5.5", "5.5-6", "6-6.5")))
##highest count
slo.hc %<>%
  filter(Exclude != 1)%>%
  mutate(IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))

hk.hc %<>%
  filter(Exclude != 1)%>%
  mutate(IHC = ifelse(IHC > 140, 140, IHC), 
         FHC = ifelse(FHC > 140, 140, FHC))

#bind hk and slo hc data
slo.hc %<>%
  mutate(Language = "Slovenian")%>%
  dplyr::rename(Last_successful = Last_Successful)%>%
  mutate(Last_successful = as.integer(as.character(Last_successful)))

hk.hc %<>%
  mutate(Language = "Cantonese")

hc.df <- bind_rows(slo.hc, hk.hc)
```

#Classifications
##CP or subset-knower
```{r}
cp.df <- all.data %>%
  filter(Task == "GiveN")%>%
  group_by(SID)%>%
  summarise(sum_correct = sum(Correct))%>%
  mutate(Knower.level = ifelse(sum_correct >= 4, "CP-knower", "Subset-knower"))%>%
  select(-sum_correct)

all.data <- full_join(all.data, cp.df, by = "SID")

all.data %>%
  distinct(SID, Language, Knower.level)%>%
  group_by(Language, Knower.level)%>%
  summarise(n=n())%>%
  kable()
```
##WPPSI score
```{r}
 #get sum per SID, add to sf and wcn for CROSS-LINGUISTIC models
 wppsi.sid <- all.data %>%
  filter(Task == "WPPSI")%>%
  mutate(Trial_number = factor(Trial_number))%>%
  filter(Trial_number != "sample item A", 
         Trial_number != "sample item B", 
         Trial_number != "Sample item A", 
         Trial_number != '1', 
         Trial_number != '2', 
         Trial_number != '7', 
        Trial_number != '8')%>%
   group_by(SID)%>%
   summarise(sum_wppsi = sum(Correct, na.rm = TRUE))

all.data <- full_join(all.data, wppsi.sid, by = "SID")
```


##Productivity
```{r, warning = FALSE}
hc.df %<>%
  mutate(Last_successful = ifelse(Last_successful == "Is quiet", "IDK", Last_successful))

hc <- hc.df %>% # replace with your local path
  select(SID, Last_successful, IHC, FHC) %>%
  mutate_at(c('Last_successful','IHC','FHC'),
            function(col) as.integer(str_replace_all(col,'\\D',''))) %>% # some of these included '?', so i remove any char thats not a digit
  mutate(Last_successful = ifelse(is.na(Last_successful), 140, Last_successful))%>%
  filter(!is.na(IHC))

# 
# function for determining productivity
is.productive = function(subject){
  # takes as input the data for a single subject
  # RULES:
  # - counts to 120 unaided = productive
  # - after making first error, counts >= 20 higher, with no more than 3 errors on way
  if(subject$IHC[1] >= 140){
    # if they get to 120 on first try, = productive
    return(TRUE)
  } else if(subject$FHC[1] == 140 & nrow(subject) < 4) {
    return(TRUE)
  } else if(subject$FHC[1] < 140 & nrow(subject) == 1 
            & subject$FHC[1] == subject$IHC[1]) {
    return(FALSE)
  } else if((subject$FHC[1] - subject$IHC[1]) >= 20){
    # if their final is >= 20 larger than their intial...
    if(nrow(subject) < 4){
      # and they've made 3 or fewer total errors, = productive
      return(TRUE)
    } 
    else {
      for(i in 1:nrow(subject)){ # start at row 2
        # check if they ever made it >= 20 counts & <= 3 errors after an error
        runLength = 0 # they just made an error, so no post-error successes yet
        numErrors = 0 # first row was an error if it's not finalCount == 120
        prev = subject$Last_successful[i]
        for (j in i+1:nrow(subject)){ # from current row until end...
          numErrors = numErrors + 1 # new row means new error
          runLength = runLength + (subject$Last_successful[j] - prev)
          # ^ add difference between current count and last count to run length
          prev = subject$Last_successful[j] # update last count
          if(runLength >= 20 & numErrors < 4){
            # if at any point the productivity conditions are met...
            return(TRUE) # = productive
          }
        }
      }
      # productivity conditions were never met (because we got to this point) so...
      return(FALSE) # != productive
    }
  } else {
    # highest is not >= 20 greater than initial
    return(FALSE)
  }
}
# 
#make function to run for all participants
unique_SIDs <- as.vector(unique(hc.df$SID))
# 
class_prod <- function(vector) {
  temp_data <- data.frame()
  for (i in vector) {
    prod.class <- data.frame(i, is.productive(subset(hc, SID == i)))
    
    names(prod.class) <- c("SID", "productive")
    temp_data <- bind_rows(temp_data, prod.class)
  }
  return(temp_data)
}
# 

productive <- class_prod(unique_SIDs)%>%
  rename(check_prod = productive)%>%
  mutate(check_prod = ifelse(check_prod == TRUE, "Productive", "Nonproductive"))

hc %<>%
  select(-Last_successful)

productive <- full_join(productive, hc, by = "SID")%>%
  distinct(SID, IHC, FHC, check_prod)%>%
  dplyr::rename(Productive = check_prod)

all.data <- full_join(all.data, productive, by = "SID")
```

##Highest Contiguous NN
```{r, warning = FALSE}
failed.nn <- all.data %>%
  filter(Task == "NN", 
         Correct == 0, 
         Trial_number == "Training")

failed.nn.sids <- unique(as.vector(failed.nn$SID))

#get unique ids
unique.nn <- all.data %>%
  filter(Task == "NN")%>%
  distinct(SID)

unique.nn <- as.vector(unique.nn$SID)
nextnums <- as.vector(c(5, 7, 16, 24, 52, 71, 105, 107, 116, 224, 252, 271))

#this is a function that pulls out the largest number for which a participant had a correct consecutive
get_contiguous <- function(){
  contig <- data.frame()
  for (sub in unique.nn) {
    tmp <- all.data %>%
      mutate(Task_item= as.integer(Task_item))%>%
      filter(Task == "NN",
             SID == sub, 
             Correct == 0)%>%
      mutate(Task_item = sort(as.integer(Task_item)))
    if (length(tmp$SID) == 0) {
      highest_contig = 271
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else if (sub %in% failed.nn.sids) {
      highest_contig = 0
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else if (length(tmp$Task_item) > 0 & min(tmp$Task_item) == 5) {
      highest_contig = 1
      sub_contig <- data.frame(sub, highest_contig)
      contig <- bind_rows(contig, sub_contig)
    } else {
      min.nn <- min(tmp$Task_item)
      prev_correct <- nextnums[nextnums < min.nn]
      highest_contig <- max(prev_correct)
    
      sub_contig <- data.frame(sub,
                             highest_contig)
      contig <- bind_rows(contig, sub_contig)
    }
  }
  return(contig)
}

highest_contiguous_nn <- get_contiguous()%>%
  dplyr::rename(SID = sub)

#add this to df 
all.data <- full_join(all.data, highest_contiguous_nn, by = "SID")

#plot
all.data %>%
  filter(!is.na(Language))%>%
  mutate(highest_contig = factor(highest_contig, levels = c('0', '1', "5", '7', '16', '24', '52', '71', '105', '107', '116', '224', '252', '271')))%>%
  distinct(SID, highest_contig, Language)%>%
  ggplot(aes(x = highest_contig, fill = Language)) + 
  geom_histogram(stat = "count", colour = "black") +
  facet_wrap(~Language) + 
  labs(title = "Highest Contiguous NN by language") +
  theme_bw() + 
  scale_fill_brewer(palette = "Dark2") +
  labs(x = "Highest Contiguous NN", y = "Count") + 
  guides(fill = FALSE)

```

##Within/outside count range
```{r}
all.data %<>%
  mutate(count_range = ifelse((Task == "SF" | Task == "NN") & as.numeric(Task_item) <= IHC, "Within", 
                              ifelse((Task == "SF" | Task == "NN") & as.numeric(Task_item) > IHC, "Outside", 
                                     NA)))
```

#Exclusions
##Global exclusions
```{r}
all.data %>%
  filter(Exclude_analysis == 1)%>%
  distinct(SID, Exclude_analysis, Exclude_analysis_reason, Language)

#exclude
all.data %<>%
  filter(Exclude_analysis != 1)

#Manual exclusions - these are participants who did not receive the correct number of trials in WPPSI. 
all.data %<>%
filter(SID != "11072018-L",
           SID != "12072018-I",
           SID != "19072018-J",
           SID != "19072018-M",
           SID != "19072018-P",
           SID != "Naj16",
           SID != "Sol07", 
         SID != "Naj14")

all.data %<>%
  filter(!is.na(Language))%>%
  select(-X)
```

###Task exclusions
```{r}
all.data %>%
  filter(Exclude_task == 1)%>%
  distinct(SID, Language, Exclude_task, Excluded_task, Exclude_task_reason)

#exclude
all.data %<>%
  filter(Exclude_task != 1)
```

##Excluded trials
```{r}
all.data %>%
  filter(Exclude_trial == 1)%>%
  group_by(Task, Exclude_trial_reason)%>%
  summarise(n = n())

all.data %<>%
  filter(Exclude_trial != 1)

#how many trials do we have for each task?
all.data %>%
  filter(Task == "SF" | 
         Task == "NN")%>%
  group_by(Language, Task, Task_item)%>%
  summarise(n = n())
```

##Exclude practice trials for SF and NN
```{r}
#how many kids failed the practice trials on these tasks?
all.data %>%
  filter(Task == "SF" | Task == "NN")%>%
  filter(Task_item == 1, 
         Correct == 0)%>%
  group_by(Task)%>%
  summarise(n = n())

#exclude practice trials
all.data %<>%
  filter(Trial_number != "Training")
```

##Memory checks - NAs to 1
```{r}
all.data %<>%
  mutate(Mem_check_1 = ifelse(is.na(Mem_check_1), 1, Mem_check_1))
```

#Demographics
```{r, warning = FALSE}
#demos by age group, Language
all.data %>%
  distinct(SID, Language, Agegroup, Age)%>%
  group_by(Language, Agegroup)%>%
  summarise(n = n(), 
            Mean_age = mean(Age, na.rm = TRUE), 
            SD_age = sd(Age, na.rm = TRUE))%>%
  kable()

#demos by Language
all.data %>%
  distinct(SID, Language, Age)%>%
  group_by(Language)%>%
  summarise(n = n(),
            Mean_age = mean(Age, na.rm = TRUE), 
            SD_age = sd(Age, na.rm = TRUE))%>%
  kable()
  
#histogram of age
all.data %>%
  distinct(SID, Language, Age)%>%
ggplot(aes(x = Age, fill = Language)) +
  geom_histogram(binwidth = .5, colour = "black") +
  theme_bw() + 
  facet_wrap(~Language) + 
  scale_x_continuous(breaks = c(3.5, 4, 4.5, 5, 5.5, 6, 6.5)) +
  scale_fill_brewer(palette = "Dark2") + 
  guides(fill = FALSE) +
  labs(y = "Count", title = "Number of children in age bin by language")
```

##Productivity by language
```{r}
all.data %>%
  distinct(SID, Language, Productive)%>%
  group_by(Language, Productive)%>%
  summarise(n = n())%>%
  kable()

all.data %<>% 
  filter(!is.na(Language))
```

###Productivity descriptives
```{r}
all.data %>%
  filter(!is.na(Language))%>%
  distinct(SID, Age, Productive, Language, IHC, FHC)%>%
  group_by(Language, Productive)%>%
  summarise(n = n(),
            mean_IHC = round(mean(IHC), 2), 
            sd_IHC = round(sd(IHC), 2), 
            median_IHC = round(median(IHC), 2), 
            mean_FHC = round(mean(FHC), 2), 
            sd_FHC = round(sd(FHC), 2), 
            median_FHC = round(median(FHC), 2))%>%
  kable()
```

#Task visualizations
##Highest count
###Histogram Initial and Final Highest Count

```{r}
unique.hc.data <- all.data %>%
  distinct(SID, IHC, FHC, Productive, Language)%>%
  gather(IHC_FHC,highest_count, IHC:FHC)%>%
  mutate(highest_count = as.integer(highest_count), 
         IHC_FHC = factor(IHC_FHC, levels = c("IHC", "FHC"), 
                          labels = c("Initial Highest Count", "Final Highest Count")))

#initial
ggplot(unique.hc.data, aes(x=highest_count, fill=Productive)) + 
  geom_histogram(binwidth = 10, colour = "black") +
  theme_bw(base_size = 10)+
  labs(title = "Initial/Final Highest Counts by Productivity and Dataset") +
  facet_grid(IHC_FHC~Language) +
  scale_x_continuous(breaks = seq(0, 140, 10))+
  scale_fill_brewer(palette = "Set1") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.minor = element_blank())

```

###Scatterplot of IHC and FHC
```{r}
initial_final <- all.data %>%
  distinct(SID, Language, IHC, FHC, Productive)%>%
  mutate(IHC = as.numeric(IHC), 
         FHC = as.numeric(FHC))

ggplot(initial_final, aes(x = IHC, y = FHC, 
                          color = Productive)) +
  geom_point(size = 1) + geom_jitter(width = .1) +
  labs(x = "Initial highest count", y = "Final highest count", 
                      color = "", title = "") +
  theme_bw(base_size = 13) + 
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) + 
  theme(panel.grid.minor = element_blank(), 
        legend.position = "bottom", 
        legend.text = element_text(size = 8)) + 
  facet_grid(~Language) + 
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

###Plotting distance between Initial and Final Highest Counts (~Pierina's graph) for Productive counters
```{r}
ggplot(subset(unique.hc.data, Productive == "Productive"), aes(x = SID, y = highest_count)) + 
  facet_grid(rows = vars(Productive)) +
  geom_line() + 
  geom_point(aes(shape = IHC_FHC, colour = IHC_FHC), 
             size = 2, stroke = 1.5) +
  scale_color_brewer(palette="Paired", direction = 1) +
  scale_shape_manual(values = c(4,5,20)) +
  labs(title="Distance between initial and final highest counts",
       x = "Each line = individual kids",
       y="Highest Count by Count Type") +
  theme_bw(base_size = 7) + 
  theme(legend.position="bottom", 
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~Language, scales = "free_x")
```




---

##Unit Task
###How many kids failed the memory checks in each dataset by number

```{r}
#for SF
sf.df <- all.data %>%
  filter(Task == "SF")%>%
  mutate(mem_check_status = ifelse((Mem_check_1 == 1 & is.na(Mem_check_2)), "Needed_1_passed_1",
                                    ifelse((Mem_check_1 == 0 & Mem_check_2 == 0), "Needed_2_failed_2",
                                           ifelse((Mem_check_1 == 1 & Mem_check_2 == 1),
                                                  "unclear_pass1_pass2",
                                                  ifelse((Mem_check_1 == 1 & Mem_check_2 == 0),
                                                         "unclear_passed1_failed2",
                                                         ifelse((Mem_check_1 == 0 & Mem_check_2 == 1),
                                                                "failed1_passed2", "other"))))))

#by number
sf.mem.num.ms <- sf.df %>%
  mutate(Task_item = factor(Task_item, levels = c("5", '7', '16', '24', '52', '71', '105', '107', '116', '224', '252', '271')))%>%
  filter(!is.na(Productive))%>%
  group_by(Task_item, mem_check_status, Language, Productive)%>%
  summarise(n = n())

ggplot(subset(sf.mem.num.ms), aes(x = Task_item, y = n, fill = mem_check_status)) + 
  geom_bar(stat = "identity") + 
  facet_grid(Productive~Language) +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Number queried", y = "Number of trials", title = "Memory checks by number in Unit Task")
```

###Raw performance by dataset

```{r}
sf.minus.2 <- sf.df %>%
  filter(correct != 2)%>%
  group_by(SID, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(sf.minus.2, aes(x = dataset, y = mean, fill = dataset)) + 
   theme_bw() + 
  geom_boxplot()+
   langcog::scale_fill_solarized("Dataset")
```

###By productivity and dataset
```{r}
sf.minus.2 <- sf.df %>%
  filter(correct != 2)%>%
  group_by(SID, productive, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(sf.minus.2, aes(x = productive, y = mean, fill = productive)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Dark2") + 
   facet_grid(~dataset) +
   guides(fill = FALSE)
```

###By productivity and count range
```{r}
sf.minus.2 <- sf.df %>%
  filter(correct != 2)%>%
  group_by(SID, productive, count_range, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(sf.minus.2, aes(x = count_range, y = mean, fill = productive)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Dark2") + 
   facet_grid(~dataset)
```

###SF performance by number and productivity
```{r}
sf.minus.2.num <- sf.df %>%
  filter(correct != 2)%>%
  mutate(starting_num = factor(starting_num))%>%
  group_by(productive, dataset, starting_num)%>%
  langcog::multi_boot_standard("correct", na.rm = TRUE)

 ggplot(sf.minus.2.num, aes(x = starting_num, y = mean, fill = productive)) + 
  geom_bar(stat = "identity", position= position_dodge()) + 
  geom_linerange(aes(ymin = ci_lower,
                      ymax = ci_upper),
                  size = .3,
                  show.legend = FALSE,
                 position=position_dodge(width = 0.9))+
   theme_bw() + 
  facet_grid(~dataset) + 
   scale_fill_brewer(palette = "Dark2") + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
   theme(legend.position = "bottom")

```

###By knower-level
```{r}
sf.know <- sf.df %>%
  filter(correct != 2)%>%
  group_by(SID, knower.level, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(sf.know, aes(x = knower.level, y = mean, fill = knower.level)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Paired") +
   facet_grid(~dataset) +
   guides(fill = FALSE)
```

---

##WCN
###Raw performance by dataset
```{r}
wcn.minus.2 <- wcn.df %>%
  filter(correct != 2)%>%
  group_by(SID, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(wcn.minus.2, aes(x = dataset, y = mean, fill = dataset)) + 
  geom_boxplot() + 
   theme_bw() + 
   langcog::scale_fill_solarized("Dataset")
```

###By productivity and dataset
```{r}
wcn.minus.2 <- wcn.df %>%
  filter(correct != 2)%>%
  group_by(SID, productive, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(wcn.minus.2, aes(x = productive, y = mean, fill = productive)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Dark2") +
   facet_grid(~dataset) +
   guides(fill = FALSE)
```

###WCN by productivity and count range
```{r}
wcn.minus.2 <- wcn.df %>%
  filter(correct != 2)%>%
  group_by(SID, productive, count_range, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(wcn.minus.2, aes(x = count_range, y = mean, fill = productive)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Dark2") + 
   facet_grid(~dataset)
```

###WCN performance by number and productivity
```{r}
wcn.minus.2.num <- wcn.df %>%
  filter(correct != 2)%>%
  mutate(starting_num = factor(starting_num))%>%
  group_by(productive, dataset, starting_num)%>%
  langcog::multi_boot_standard("correct", na.rm = TRUE)

 ggplot(wcn.minus.2.num, aes(x = starting_num, y = mean, fill = productive)) + 
  geom_bar(stat = "identity", position= position_dodge()) + 
  geom_linerange(aes(ymin = ci_lower,
                      ymax = ci_upper),
                  size = .3,
                  show.legend = FALSE,
                 position=position_dodge(width = 0.9))+
   theme_bw() + 
  facet_grid(~dataset) + 
   scale_fill_brewer(palette = "Dark2") + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
   theme(legend.position = "bottom")

```

###By knower level
```{r}
wcn.know <- wcn.df %>%
  filter(correct != 2)%>%
  group_by(SID, knower.level, dataset)%>%
  summarise(mean = mean(correct))

 ggplot(wcn.know, aes(x = knower.level, y = mean, fill = knower.level)) + 
  geom_boxplot() + 
   theme_bw() + 
   scale_fill_brewer(palette = "Paired") +
   facet_grid(~dataset) +
   guides(fill = FALSE)
```

---

##WPPSI
```{r}
#get score
wppsi.ms <- wppsi.df%>%
  mutate(trial = factor(trial))%>%
  filter(trial != "sample item A", 
         trial != "sample item B", 
         trial != "Sample item A", 
         trial != 1, 
         trial != 2, 
         trial != 7, 
         trial != 8)%>%
  mutate(trial = as.numeric(as.character(trial)))%>%
  group_by(SID, dataset)%>%
  summarise(sum_wppsi = sum(correct), 
            num_trials = n())

 ggplot(wppsi.ms, aes(x = dataset, y = sum_wppsi, fill = dataset)) + 
  geom_bar(stat = "identity", position = position_dodge())+
   theme_bw() + 
   guides(fill = FALSE)
 
 ggplot(wppsi.ms, aes(x = sum_wppsi, fill = dataset)) +
   geom_histogram(binwidth = 1, colour = "black") +
   theme_bw() + 
   facet_grid(~dataset)

```

---

#Main analyses
##Within-language analyses

###Make model analysis dfs
Note that there is a lot more variability in highest counts and highest contiguous NN than in categorical variables. I am centering age, and centering and scaling FHC, IHC, and highest contiguous NN (which has the most variability).
```{r}
##HK##
sf.hk.within <- sf.df%>%
  filter(dataset == "HK")%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(starting_num, center = TRUE, scale = TRUE)))
  
wcn.hk.within <- wcn.df%>%
  filter(dataset == "HK")%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)),
         starting_num.c = as.vector(scale(starting_num, center = TRUE, scale = TRUE)))

##SLO##
sf.slo.within <- sf.df%>%
  filter(dataset == "SLO")%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(starting_num, center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))

wcn.slo.within <- wcn.df%>%
  filter(dataset == "SLO")%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=TRUE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(starting_num, center = TRUE, scale = TRUE)))%>%
  filter(!is.na(highest_contig.c))
```

###Unit Task

This first set of analyses replicates, in Cantonese English and Slovenian speaking samples, analyses similar to those previously conducted on English-speaking subjects. To identify whether there is connection between counting experience and Unit Task performance for participants within particular language groups, we will conduct four initial analyses (plus the null model) within each language, predicting Unit Task performance from (1) Productivity (defined above); (2) Final Highest Count; (3) Initial Highest Count; and (4) Highest Contiguous Next Number.

All models will be logistic mixed effects models, predicting performance on the unit task (0 or 1) on a trial as a function of the following predictors, with a random intercept for subject. In R, the formula will be
glmer(predicted ~ (predictor) + age + within/outside range + (1|subject), family = binomial).

In each language, after running these first four models, any predictor that significantly (p &lt;.05) predicts Unit TaskPerformance (as assessed by running a likelihood ratio test on the Null Model (Model 0) and Models 1, 2, 3, and 4) will be added into Model 5, which will be our “Large” model. We will construct model 5 hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 5). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.


Model 0 (null model): Unit.Performance ~ Within/Outside range + Age + (1|subject)
Model 1: Unit.Performance ~ Productivity + Within/Outside range + Age + (1|subject)
Model 2: Unit.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
Model 3: Unit.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)
Model 4: Unit.Performance ~ Highest.Contiguous.Next.Number + Within/Outside range + Age + (1|subject)

####Hong Kong
Build the models

#####Model 0 (base)
```{r}
sf.hk.within.base <- glmer(correct ~ count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.base)


```


#####Model 1 (Productivity): Not a significant predictor of Unit Task performance (*p* = .69)
```{r}
sf.hk.within.model1 <- glmer(correct ~ productive + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model1)
anova(sf.hk.within.model1, sf.hk.within.base, test = 'LRT')
```

#####Model 2 (Final Highest Count): Significant predictor of Unit Task performance (*p* = .002)
```{r}
sf.hk.within.model2 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model2)
anova(sf.hk.within.model2, sf.hk.within.base, test = 'LRT')
```

#####Model 3 (Initial Highest Count): Significant predictor of Unit Task Performance (*p* < .0001)
```{r}
sf.hk.within.model3 <- glmer(correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model3)
anova(sf.hk.within.model3, sf.hk.within.base, test = 'LRT')
```

#####Model 4 (Highest Continguous Next Number): Significant predictor of Unit Task performance (*p* = .001)
```{r}
sf.hk.within.model4 <- glmer(correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.model4)
anova(sf.hk.within.model4, sf.hk.within.base, test = 'LRT')
```

#####Large model

We have three significant predictors of performance on the Unit task (FHC, IHC, and Highest Contiguous NN). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task.

######IHC and Highest Contiguous NN: Highest Contig. NN does not significantly explain additional variance (*p* = .13)
```{r}
##IHC and Highest Contig NN##
sf.hk.within.plus1 <- glmer(correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.hk.within)
sf.hk.within.plus2 <- glmer(correct ~ ihc.c + highest_contig.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)
anova(sf.hk.within.plus2, sf.hk.within.plus1, test = 'LRT') #highest contiguous does not significantly explain additional variance
```

######IHC and FHC: FHC does not significantly explain additional variance (*p* = .36)
```{r}
sf.hk.within.plus2 <- glmer(correct ~ ihc.c + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = sf.hk.within)
anova(sf.hk.within.plus2, sf.hk.within.plus1, test = 'LRT') #final highest count does not significantly explain additional variance
```

###HK Unit Task within-language results:
IHC emerges as best predictor of performance on this task

##EXPLORE-ATHON
```{r}
##EXPLORE
sf.hk.within.base1 <- glmer(correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.base1)
anova(sf.hk.within.base1, sf.hk.within.base, test = 'LRT')

sf.hk.within.prod <- glmer(correct ~ productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.prod)
anova(sf.hk.within.prod, sf.hk.within.model1, test = 'LRT')

sf.hk.within.fhc <- glmer(correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.fhc)
anova(sf.hk.within.fhc, sf.hk.within.model2, test = 'LRT')

sf.hk.within.ihc <- glmer(correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.ihc)
anova(sf.hk.within.ihc, sf.hk.within.model3, test = 'LRT')

sf.hk.within.highest_contig <- glmer(correct ~ highest_contig.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
summary(sf.hk.within.highest_contig)
anova(sf.hk.within.highest_contig, sf.hk.within.model4, test = 'LRT')

##compare
sf.hk.within.ihc.plus1 <- glmer(correct ~ ihc.c + fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.hk.within)
anova(sf.hk.within.ihc.plus1, sf.hk.within.ihc, test = 'LRT')
```

***

####SLO (Unit Task)
Build the models 

#####Model 0 (base)
```{r}
sf.slo.within.base <- glmer(correct ~ count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.base)


```

#####Model 1 (Productivity): Marginally significant (*p* = .065)
```{r}
sf.slo.within.model1 <- glmer(correct ~ productive + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model1)
anova(sf.slo.within.model1, sf.slo.within.base, test = 'LRT')
```

#####Model 2 (Final Highest Count): Barely significant (*p* = .044)
```{r}
sf.slo.within.model2 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model2)
anova(sf.slo.within.model2, sf.slo.within.base, test = 'LRT')
```

######Model 3 (Initial Highest Count): Marginally significant (*p* = .057)
```{r}
sf.slo.within.model3 <- glmer(correct ~ ihc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.model3)
anova(sf.slo.within.model3, sf.slo.within.base, test = 'LRT')
````

#####Model 4 (Highest contiguous NN): Significant predictor (*p* = .01)
```{r}
sf.slo.within.model4 <- glmer(correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = sf.slo.within) 
summary(sf.slo.within.model4)
anova(sf.slo.within.model4, sf.slo.within.base, test = 'LRT')
```

#####Large model: Comparison between FHC and Highest contiguous NN: FHC does not significantly explain additional variance in the model (*p* = .27)
Highest contiguous and Final Highest count best predictors - compare
```{r}
sf.slo.within.plus1 <- glmer(correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
sf.slo.within.plus2 <- glmer(correct ~ fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                             data = sf.slo.within, family = "binomial")
anova(sf.slo.within.plus2, sf.slo.within.plus1, test = 'LRT')
```

##EXPLORE-ATHON
###Starting number/magnitude
```{r}
##EXPLORE
sf.slo.within.base1 <- glmer(correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.base1)
anova(sf.slo.within.base1, sf.slo.within.base, test = 'LRT')

sf.slo.within.prod <- glmer(correct ~ productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.prod)
anova(sf.slo.within.prod, sf.slo.within.model1, test = 'LRT')

sf.slo.within.fhc <- glmer(correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.fhc)
anova(sf.slo.within.fhc, sf.slo.within.model2, test = 'LRT')

sf.slo.within.ihc <- glmer(correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.ihc)
anova(sf.slo.within.ihc, sf.slo.within.model3, test = 'LRT')

sf.slo.within.highest_contig <- glmer(correct ~ highest_contig.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
summary(sf.slo.within.highest_contig)
anova(sf.slo.within.highest_contig, sf.slo.within.model4, test = 'LRT')

##compare
sf.slo.within.highest_contig.plus1 <- glmer(correct ~ productive + highest_contig.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                           data = sf.slo.within)
anova(sf.slo.within.highest_contig.plus1, sf.slo.within.highest_contig, test = 'LRT')
```

***

##Productivity t-test of Unit Task performance
Using the Productive/Non-Productive categorical classification outlined above, we will compare performance
between both groups on the Unit task using t-tests. We may do this by considering average performance
(averaring the 0’s and 1’s on each task for each participant); should doing so provide greater precision, we may also compare Highest Contiguous Number.

###HK: Marginally significant difference between groups (*p* = .06)
```{r}
#with mean performance
sf.hk.mean.ms <- sf.hk.within %>%
  group_by(SID, productive)%>%
  summarise(mean = mean(correct))

t.test(subset(sf.hk.mean.ms, productive == "productive")$mean, 
       subset(sf.hk.mean.ms, productive == "nonproductive")$mean, var.equal = TRUE) #marginally significant difference between productive and nonproductive counters for performance on Unit Task
```

###SLO: Significant difference between groups (*p* = .0007)
```{r}
#with mean performance
sf.slo.mean.ms <- sf.slo.within %>%
  group_by(SID, productive)%>%
  summarise(mean = mean(correct))

t.test(subset(sf.slo.mean.ms, productive == "productive")$mean, 
       subset(sf.slo.mean.ms, productive == "nonproductive")$mean, var.equal = TRUE) #significant difference in performance between productive and nonproductive counters
```

##Productivity t-test of Highest contiguous NN
###HK: Significant difference between groups (*p* = .005)
```{r}
sf.hk.mean.nn <- sf.hk.within %>%
  group_by(SID, productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.hk.mean.nn, productive == "productive")$mean_nn, 
       subset(sf.hk.mean.nn, productive == "nonproductive")$mean_nn, var.equal = TRUE)
```

###SLO: Significant difference between groups
```{r}
sf.slo.mean.nn <- sf.slo.within %>%
  group_by(SID, productive)%>%
  summarise(mean_nn = mean(highest_contig))

t.test(subset(sf.slo.mean.nn, productive == "productive")$mean_nn, 
       subset(sf.slo.mean.nn, productive == "nonproductive")$mean_nn, var.equal = TRUE)
```

---
##WCN Task- within-language analyses, simple models

Model 0 (null model): NextNumber.Performance ~ Within/Outside range + Age + (1|subject)
Model 1: Next.Number.Performance ~ Productivity + Within/Outside range + Age + (1|subject)
Model 2: Next.Number.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
Model 3: Next.Number.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)

###HK
Build models

####Model 0 (base)
```{r}
wcn.hk.within.base <- glmer(correct ~ count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.base)


```

####Model 1 (Productivity): Not a significant predictor (*p* = .267)
```{r}
wcn.hk.within.model1 <- glmer(correct ~ productive + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model1)
anova(wcn.hk.within.model1, wcn.hk.within.base, test = 'LRT')
```

####Model 2 (Final Highest Count): Significant predictor (*p* < .0001)
````{r}
wcn.hk.within.model2 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model2)
anova(wcn.hk.within.model2, wcn.hk.within.base, test = 'LRT')
````

#####Model 3 (Initial Highest Count): Significant predictor (*p* < .0001)
```{r}
wcn.hk.within.model3 <- glmer(correct ~ ihc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.hk.within)
summary(wcn.hk.within.model3)
anova(wcn.hk.within.model3, wcn.hk.within.base, test = 'LRT')
```

#####Large Model - Comparison of FHC and IHC: Both predictors significantly explain unique variance (*p* < .0001)
We have two significant predictors of performance on the Unit task (FHC and IHC). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task. 
```{r}
##IHC and FHC##
wcn.hk.within.plus1 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.hk.within)
wcn.hk.within.plus2 <- glmer(correct ~ ihc.c + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.hk.within)
anova(wcn.hk.within.plus2, wcn.hk.within.plus1, test = 'LRT') #Initial Highest Count explains additional variance in WCN performance
```

##EXPLORE-ATHON
###Starting Number/Magnitude
```{r}
###EXPLORE
wcn.hk.within.base1 <- glmer(correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.base1)
anova(wcn.hk.within.base1, wcn.hk.within.base, test = 'LRT')
wcn.hk.within.prod <- glmer(correct ~ productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.prod)
anova(wcn.hk.within.prod, wcn.hk.within.model1, test = 'LRT')
wcn.hk.within.fhc <- glmer(correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.fhc)
anova(wcn.hk.within.fhc, wcn.hk.within.model2, test = 'LRT')
wcn.hk.within.ihc <- glmer(correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
summary(wcn.hk.within.ihc)
anova(wcn.hk.within.ihc, wcn.hk.within.model3, test = 'LRT')

#compare 
wcn.hk.within.fhc.plus <- glmer(correct ~ ihc.c + fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                             data = wcn.hk.within)
anova(wcn.hk.within.fhc.plus, wcn.hk.within.fhc, test = 'LRT')
```

***

###SLO - WCN (within-language)
Build the models

#####Model 0
```{r}
wcn.slo.within.base <- glmer(correct ~ count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.base)
```


####Model 1 (Productivity): Significant predictor (*p* < .0001)
```{r}
wcn.slo.within.model1 <- glmer(correct ~ productive + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model1)
anova(wcn.slo.within.model1, wcn.slo.within.base, test = 'LRT')
```

#####Model 2 (FHC): Significant predictor (*p* < .0001)
```{r}
wcn.slo.within.model2 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model2)
anova(wcn.slo.within.model2, wcn.slo.within.base, test = 'LRT')
```

#####Model 3 (IHC): Significant predictor (*p* < .0001)
```{r}
wcn.slo.within.model3 <- glmer(correct ~ ihc.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.model3)
anova(wcn.slo.within.model3, wcn.slo.within.base, test = 'LRT')
```

#####Large Model comparison: Productivity, FHC, and IHC
We have three significant predictors of performance on the Unit task (Productivity, FHC and IHC). Now, we need to create our 'large' Model 5 which will contain the best predictors of performance on the Unit Task. 

######Productivity and FHC: Productivity does not explain additional variance (*p* = .99)
```{r}
##Productive and FHC##
wcn.slo.within.plus1 <- glmer(correct ~ fhc.c + count_range + age.c + (1|SID), 
                             family = "binomial", 
                           data = wcn.slo.within)
wcn.slo.within.plus2 <- glmer(correct ~ productive + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)
anova(wcn.slo.within.plus2, wcn.slo.within.plus1, test = 'LRT') #Productivity does not explain additional variance
```

######IHC and FHC: IHC does not explain additional variance (*p* = .77)
```{r}
wcn.slo.within.plus2 <- glmer(correct ~ ihc.c + fhc.c + count_range + age.c + (1|SID), 
                            family = "binomial", data = wcn.slo.within)
anova(wcn.slo.within.plus2, wcn.slo.within.plus1, test = 'LRT') ##IHC does not explain additional variance
```

##EXPLORE-ATHON
###Starting number/magnitude
```{r}
###Explore

wcn.slo.within.base1 <- glmer(correct ~ starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.base1)
anova(wcn.slo.within.base1, wcn.slo.within.base, test = 'LRT')
wcn.slo.within.prod <- glmer(correct ~ productive + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.prod)
anova(wcn.slo.within.prod, wcn.slo.within.model1, test = 'LRT')
wcn.slo.within.fhc <- glmer(correct ~ fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.fhc)
anova(wcn.slo.within.fhc, wcn.slo.within.model2, test = 'LRT')
wcn.slo.within.ihc <- glmer(correct ~ ihc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
summary(wcn.slo.within.ihc)
anova(wcn.slo.within.ihc, wcn.slo.within.model3, test = 'LRT')

#compare
wcn.slo.within.fhc.plus <- glmer(correct ~ productive + fhc.c + starting_num.c + count_range + age.c + (1|SID), family = "binomial", 
                            data = wcn.slo.within)
anova(wcn.slo.within.fhc.plus, wcn.slo.within.fhc, test = 'LRT')
```

***

##Productivity t-test of WCN performance
Using the Productive/Non-Productive categorical classification outlined above, we will compare performance
between both groups on the Next Number task using t-tests. We may do this by considering average performance
(averaring the 0’s and 1’s on each task for each participant).

###HK: Significant difference between productive and nonproductive counters (*p* = .001)
```{r}
#with mean performance
wcn.hk.mean.ms <- wcn.hk.within %>%
  group_by(SID, productive)%>%
  summarise(mean = mean(correct))

t.test(subset(wcn.hk.mean.ms, productive == "productive")$mean, 
       subset(wcn.hk.mean.ms, productive == "nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

###SLO: Significant difference between groups (*p* < .0001)

```{r}
#with mean performance
wcn.slo.mean.ms <- wcn.slo.within %>%
  group_by(SID, productive)%>%
  summarise(mean = mean(correct))

t.test(subset(wcn.slo.mean.ms, productive == "productive")$mean, 
       subset(wcn.slo.mean.ms, productive == "nonproductive")$mean, var.equal = TRUE) #Significant difference in performance between productive and nonproductive counters
```

---

#Cross-linguistic comparisons
Our second set of analyses is aimed at understanding cross-linguistic differences in performance on the Unit Task. To do this, we will analyze all participants, from all language groups, in a single model. We will then construct our models from above, but will add (a) a measure of Working Memory and (b) the interaction of Initial Highest Count and Language group to each model. These models therefore allow us to test whether (a) language; (b) counting ability; or (c) some interaction between the two predict unit performance. We include Working Memory in all cross-linguistic models with the intention of taking into account baseline differences in processing across samples.

Cross-Linguistic Models:
Model 0a (the Null Model): Unit.Performance~ Language*IHC + Within/Outside range + Age + WM
+ (1|subject)
Model 1a: Unit.Performance ~ Productivity + Language*IHC + Within/Outside range + Age + WM + (1|subject)
Model 2a: Unit.Performance ~ Final.Count + Language*IHC + Within/Outside range + Age + WM + (1|subject)
Model 3a: Unit.Performance ~ Highest.Contiguous.Next.Number + Language*IHC + Within/Outside range +
Age + WM + (1|subject)
Make model dfs


We will then compare Model 0a (the Null Model) to each of the models containing measures of productivity (1a, 2a, and 3a) using a likelihood ratio test in testing whether these measures of productivity significantly explain variance in children’s performance. Should effects of Language emerge, we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects (e.g., Unit.Performance ~ Productivity + IHC + Within/Outside range + Age + WM + (1|subject)). After running the four models above, any predictor that significantly (p &lt;.05) predicted Unit Task Performance will be added into Model 6a, which will be our “Large” model (containing all predictors that significantly predicted Unit Task Performance in the simple models). We will construct model 6a hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 6a). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

###Make model dfs
```{r}
##HK##
sf.df.cross %<>%
  select(-dataset.x, -X)%>%
  dplyr::rename(dataset = dataset.y)%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)), 
         starting_num.c = as.vector(scale(starting_num, center = TRUE, scale = TRUE)))
  
wcn.df.cross %<>%
select(-dataset.x, -X)%>%
  dplyr::rename(dataset = dataset.y)%>%
  mutate(SID = factor(SID), 
         productive = factor(productive), 
         count_range = factor(count_range), 
         highest_contig = as.integer(highest_contig), 
         age.c = as.vector(scale(age, center = TRUE, scale=FALSE)), 
         fhc.c = as.vector(scale(final_highest, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(initial_highest_count, center = TRUE, scale = TRUE)), 
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale = TRUE)),
         starting_num.c = as.vector(scale(starting_num, center = TRUE, scale = TRUE)))

sf.df.cross %<>%
  mutate(Language = ifelse(dataset == "HK", "Cantonese", "Slovene"), 
         Language = factor(Language))

wcn.df.cross %<>%
  mutate(Language = ifelse(dataset == "HK", "Cantonese", "Slovene"), 
         Language = factor(Language))

sf.df.cross %<>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))

wcn.df.cross %<>%
  mutate(wppsi.c = as.vector(scale(sum_wppsi, center = TRUE, scale=TRUE)))
```

##Unit Task: Cross linguistic models

###Model 0 (base)
```{r}
sf.cross.base <- glmer(correct ~ Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.base)
```

###Model 1 (Productivity): Not a signficant predictor (*p* = .82)
```{r}
sf.cross.model1 <- glmer(correct ~ productive + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.model1)
anova(sf.cross.model1, sf.cross.base, test = 'LRT')
```

###Model 2 (Final Highest Count): Not a significant predictor (*p* = .88)
```{r}
sf.cross.model2 <- glmer(correct ~ fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.model2)
anova(sf.cross.model2, sf.cross.base, test = 'LRT')
```

###Model 3 (Highest Contiguous NN): Significant predictor (*p* = .03)
```{r}
sf.cross.model3 <- glmer(correct ~ highest_contig.c + Language*ihc.c + count_range + age.c + wppsi.c +
                           (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.model3)
anova(sf.cross.model3, sf.cross.base, test = 'LRT')
```

##EXPLORE-ATHON
###Starting Number/magnitude
```{r}
##Explore
sf.cross.base1 <- glmer(correct ~ starting_num.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.base1)
anova(sf.cross.base1, sf.cross.base, test = 'LRT')

sf.cross.prod <- glmer(correct ~ productive + starting_num.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.prod)
anova(sf.cross.prod, sf.cross.model1, test = 'LRT')

sf.cross.fhc <- glmer(correct ~ fhc.c + starting_num.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.fhc)
anova(sf.cross.fhc, sf.cross.model2, test = 'LRT')

sf.cross.highest_contig <- glmer(correct ~ highest_contig.c + starting_num.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                       family = "binomial", data = sf.df.cross)
summary(sf.cross.highest_contig)
anova(sf.cross.highest_contig, sf.cross.model3, test = 'LRT')
```

---

##WCN
Our third set of analyses is aimed at understanding cross-linguistic differences in performance on the next number task. To do this, we will analyze all participants, from all language groups, in a single model. As above, we add WM, and the language by IHC interaction.
C
ross-Linguistic Models
Model 0b (the null model): Next.Number.Performance ~ Language*IHC + Within/Outside range + Age + WM +
(1|subject)
Model 1b: Next.Number.Performance ~ Productivity + Language*IHC + Within/Outside range + Age + WM +
(1|subject)
Model 2b: Next.Number.Performance ~ Final.Count + Language*IHC + Within/Outside range + Age + WM +
(1|subject)

We will construct Model 7b hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 7b). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

###Model 0 (base)
```{r}
wcn.cross.base <- glmer(correct ~ Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross)
summary(wcn.cross.base)


```

###Model 1 (Productivity): Marginally significant (*p* = .06)
```{r}
wcn.cross.model1 <- glmer(correct ~ productive + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross, 
                        control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
summary(wcn.cross.model1)
anova(wcn.cross.model1, wcn.cross.base, test = 'LRT')
```

###Model 2 (Final Highest Count): Significant predictor (*p* = .002)
```{r}
wcn.cross.model2 <- glmer(correct ~ fhc.c + Language*ihc.c + count_range + age.c + wppsi.c + 
                            (1|SID), data = wcn.df.cross, family = "binomial")
summary(wcn.cross.model2)
anova(wcn.cross.model2, wcn.cross.base, test = 'LRT')
```

Should effects of Language emerge, we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects (e.g., Unit.Performance ~ Productivity + IHC + Within/Outside range + Age + WM + (1|subject)). After running these three models, any predictor that significantly (p &lt;.05) predicted Next Number Performance (as assessed by running a likelihood ratio test on the Null Model (Model 0b) and Models 1b and 2b) will be added into Model 7b, which will be our “Large” model (containing all predictors that significantly predicted Next Number Performance in the simple models).

###Model comparison: Removing effect of Language from FHC model: FHC still significant predictor (*p* = .03)
There is a significant effect of Language: we will also test these using a likelihood ratio test comparing models with significant Language effects to one excluding those effects (e.g., WCN.Performance ~ Productivity + IHC + Within/Outside range + Age + WM + (1|subject)).
```{r}
wcn.nolang.base <- glmer(correct ~ ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial")
wcn.nolang.model1 <- glmer(correct ~ fhc.c + ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                         data = wcn.df.cross, family = "binomial")
anova(wcn.nolang.model1, wcn.nolang.base, test = 'LRT') #FHC is still significant

```


##EXPLORE-ATHON
###Starting Number/Magnitude
```{r}
##EXPLORE
wcn.cross.base1 <- glmer(correct ~ starting_num.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross)
summary(wcn.cross.base1)
anova(wcn.cross.base1, wcn.cross.base, test = 'LRT')

wcn.cross.prod <- glmer(correct ~ productive + starting_num.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross, control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
summary(wcn.cross.prod)
anova(wcn.cross.prod, wcn.cross.model1, test = 'LRT')

wcn.cross.fhc <- glmer(correct ~ fhc.c + starting_num.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross)
summary(wcn.cross.fhc)
anova(wcn.cross.fhc, wcn.cross.model2, test = 'LRT')

#compare
wcn.cross.fhc.plus <- glmer(correct ~ productive + fhc.c + starting_num.c + Language*ihc.c + count_range + age.c + wppsi.c + (1|SID), 
                        family = "binomial", data = wcn.df.cross, control=glmerControl(optimizer="bobyqa",
                         optCtrl=list(maxfun=2e4)))
anova(wcn.cross.fhc.plus, wcn.cross.fhc, test = 'LRT')

```

---

#Counting distribution
We plan to conduct descriptive analyses to describe the ways in which Initial Highest Count differs across
languages.
```{r}
hc.df.cross <- right_join(hc.df, wppsi.sid, by = "SID")%>%
  distinct(SID, initial_highest, final_highest, dataset.x, productive, age, highest_contig, sum_wppsi)%>%
  mutate(Language = ifelse(dataset.x == "HK", "Cantonese", "Slovene"))

hc.df.cross %>%
  group_by(Language)%>%
  summarise(mean = mean(initial_highest), 
            sd = sd(initial_highest), 
            median = median(initial_highest))
```

In addition, we plan to test whether children in transparent languages can become productive with less counting experience. To test this, we will consider non-productive counters (those who were labeled as non-Productive). We will then ask whether IHC for these non-productive counters differs across languages. We will only conduct these analyses if we have at least 30 non-productive counters in each language. If count-list transparency allows children to converge on a productive count rule more quickly, then children who learn a system with a transparent-count list should move to the “productive counter” category on the basis of relatively less experience than children who learn a system with an opaque- count list. This predicts that, when considering non-Productive counters, initial highest count should be higher for opaque languages (like English) than for Slovenian, and higher for Slovenian than for Cantonese. The model would like this: 

Model 1: IHC ~ Language + Age + WM, data = NonProductiveCounters

###Model: Nonproductive Slovenians have significantly *lower* IHC than Cantonese speakers
```{r}
ihc.cross <- hc.df.cross%>%
  filter(productive == "nonproductive")%>%
  mutate(Language = factor(Language))

ihc.model.1 = lm(initial_highest ~ Language + age + sum_wppsi, data = ihc.cross)
summary(ihc.model.1)
```

In addition, we will test whether count-list transparency allows children to acquire some degree of productivity, even before they are labeled productive counters based on their overall counting performance. To test this, we will predict Highest Contiguous Next Number from Language. If transparent languages allow children to generate a productive counting rule, speakers of these transparent languages may perform better on the Next Number task than speakers of non- transparent languages, even when only considering non-productive counters. Model 2: Highest.Contiguous.NextNumber ~ Language + Age + WM + (1|subject), data = NonProductiveCounters

###Model: No effect of Language here
```{r}
highest_contig.model <- lm(highest_contig ~ Language + age + sum_wppsi, data = ihc.cross)
summary(highest_contig.model)
```